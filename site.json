{
  "site": {
    "title": "David Souther",
    "subtitle": "Craftsmanship - Software, Hardware, Art, Language",
    "author": "David Souther",
    "copyright": "2007 - 2014"
  },
  "files": {
    "/pages/about-me/index.markdown": {
      "front": {
        "author": "admin",
        "comments": true,
        "date": "2011-08-08T02:35:26.000Z",
        "layout": "page",
        "slug": "about-me",
        "title": "About Me",
        "wordpress_id": 26,
        "path": "/pages/about-me/index.markdown"
      },
      "body": "### I care about who you are today. I don't care about how old you are, where you've been, or what you've done, only that today you are a good person, and that you intend to keep being a good person in the future.\n\n\n**Adjectives that describe me, but my spellchecker doesn't like:**\n[Sapiosexual](http://www.okcupid.com/interests?i=Sapiosexual)\n[Meliorist](http://www.okcupid.com/interests?i=Meliorist)\n[Euclidean](http://www.okcupid.com/interests?i=Euclidean) (Damn, it likes the Greeks)\n[Extropianist](http://www.okcupid.com/interests?i=Extropianist)\n[Wikipede](http://www.okcupid.com/interests?i=Wikipede)\n[Poppernian](http://www.okcupid.com/interests?i=Poppernian) [Epistimologist](http://www.okcupid.com/interests?i=Epistimologist)\n\n\n\n\n  * hackerkey://v4sw7CJMY$hw4$ln6pr7FO$ck0ma8u7Lw4Xm5l7ALUiCe6t3DNSb7ADHMOPRTen5a20s6r1p-4/-\n\n\n  * 6g5GPR Linux User 475468 /. 909179\n\n\n  * Facebook: [david.souther](http://facebook.com/david.souther)\n\n\n  * Google+: [David Souther](https://plus.google.com/117815521555744502963/posts)\n\n\n\n[![Receiving my diploma](http://davidsouther.com/wp-content/uploads/2011/08/230955_10150292025434152_532279151_9649189_323959_n-240x300.jpg)](http://davidsouther.com/wp-content/uploads/2011/08/230955_10150292025434152_532279151_9649189_323959_n.jpg)\n\n### What I’m doing with my life\n\n\nI recently finished a BSc Computer Science and BSc Mathematics at Rocky Mountain College, a small liberal arts school in Billings, Montana. During my Senior year at Rocky, I joined Design Delegates, a software development start-up founded by a couple friends of mine from high school. I am the Chief Software Architect at Design Delegates, responsible for all our technical decisions and outcomes. During a typical week, I will spend a few hours as a sysad, setting up new platforms for our team to work on. I spend about half of my programming time architecting large-scale pieces of our software, and about half of my time implementing pieces of those designs. Working in a team environment means a lot of time in meetings with the team, and I spend a fair amount of time helping my programmers solve problems they come across.\n\n\n### I’m really good at\n\n\nFiguring things out, having a good time, being outdoors.\n\nI love to think through problems, and take great pleasure in figuring things out. I enjoy designing systems and planning operations. I try to take everything I do with a grain of salt, and hate taking my self (or others) too seriously. Things just flow better when everyone's happy!\n\n\n### The first things people usually notice about me\n\n\nI'm very thoughtful, and when deep in conversation, careful about what I say. Clear and concise language is a powerful aid to clear thinking, and an absolute necessity in successful conversation. That said, I do not mince words or hem-haw over their meaning. I have no respect for stated authority- I will only accept and respect a person's knowledge in a field as they demonstrate their abilities and capabilities therein.\n\n\n### Favorite books, movies, shows, music, and food\n\n\nFor movies, I enjoy smart and dark humor. Quentin Tarantino is an all-time favorite, as is Humphrey Bogart. I love action flicks, and cannot stand potty-humor alcoholic comedies. Drama, when done well, is fantastic, and I'm always ready to cuddle through any chick flick. I don't like horror and suspense- they are completely not my style, and I won't sit through them with anyone.\n\nMusic, pretty much every genre's represented in my Pandora stations. I seem to go through genres in about a 6-month period, until I switch to something different and the others stick around and get added to the collection. Right now, it's NewNormalMusic.com (indie rock). Most of last summer it was 70s and 80s arena rock. Country of the 80s through 2000s before that, and alternative rock 90s through 2000s before that. I listen to internet radio, and very selectively purchase albums. Specifically, there are four artists whose album I'd buy today: A Fine Frenzy, 30 Seconds to Mars, Sara Bareilles, and Brad Paisley.\n\nI read voraciously, mostly textbooks and technical writing (in many fields), as well as literature. Novels are my favorite, followed by Shakespeare's plays. I enjoy hard sci-fi, and some soft sci-fi and high fantasy. I usually put up with the classics, often for my pleasure, though sometimes only so I can despise them on their (de)merits.\n\nI enjoy eating anything I cook, and I enjoy cooking the animals I hunt. Deer, Antelope, anything from my grandmother's garden. Those are the staples of my diet, but I'm no slouch with a cookbook, either.\n\n\n### The six things I could never do without\n\n\n\n\n\n\n  * Thoughtful pursuits.\n\n\n  * Friendly people.\n\n\n  * Good food.\n\n\n  * Fine drink.\n\n\n  * Fun toys.\n\n\n  * Mother Nature.\n\n\n\n\n### I spend a lot of time thinking about\n\n\nAnything and everything.\n\nBy trade, I develop software for companies looking to improve their workflow, and their bottom line. This gives me the opportunity to work in nearly every area of today's business world, from construction firms to insurance trusts, the medical industry to law firms and video games. Outside the office, I have a wonderful time discussing politics on every level, social movements on every level, history, philosophy, theology- anything that uses my mind, I pursue. When I know enough about it, the real fun begins- the best part of being educated is the wider and subtler jokes to understand.\n\n[![](/about-me/DavidAndGrey.jpg)](DavidAndGrey.jpg)\n\n### On a typical Friday night I am\n\n\nSipping coffee sketching ideas of quantum physics, software development, and law, or camping a few miles into the back country.\n\nProbably my favorite Friday night last summer was on the Froze to Death plateau. We were attempting Granite peak. Got up in the middle of the night to use the restroom. It had been thundering when we went to bed, but when I got out of the tent, it was clear sky all around. The stars overhead were as numerous as the tales of the Cheyenne Braves of lore, the mountain goats were standing to one side. A perfect night in a perfect wilderness.\n\n\n### The most private thing I’m willing to admit\n\n\nI have a secret. A dark, terrible secret. A secret with scruff, brown hair, long claws, sharp teeth... less a secret, really, and more a bear.\n\n[gallery orderby=\"rand\"]\n"
    },
    "/pages/resume/index.md": {
      "front": {
        "title": "Resume",
        "path": "/pages/resume/index.md",
        "author": "David Souther",
        "date": null
      },
      "body": "### [Download](/assets/resume.pdf)\n\n<object data=\"/assets/resume.pdf\" type=\"application/pdf\" width=\"100%\" height=\"100%\">\n  <p>Alternative text - include a link <a href=\"myfile.pdf\">to the PDF!</a></p>\n</object>\n"
    },
    "/posts/2007/09/30/revenge-faith-and-science/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2007-09-30T16:00:58.000Z",
        "layout": "post",
        "slug": "revenge-faith-and-science",
        "title": "Revenge: Faith and Science",
        "wordpress_id": 423,
        "categories": [
          "Philosophy"
        ],
        "tags": [
          "English",
          "Faith",
          "Frankenstein",
          "Hamlet",
          "Revenge",
          "science",
          "Shakespeare"
        ],
        "path": "/posts/2007/09/30/revenge-faith-and-science/index.md"
      },
      "body": "### Dichotomy in modern tragedy\n\n\nMary Shelley's _Frankenstein_ and William Shakespeare's _Hamlet_ are two revenge stories which present a twist on classic Aristotelian tragedy. The dichotomy in the titular characters' tragic flights, one based on faith, the other on logic, especially emphasize that choices, not fate, which rule the modern tragic protagonist.\n\n\n\n\n\nFrankenstein's fall, and need for revenge, is seated firmly in his scientific reasoning. Natural science (where Alchemy may be called that) led Victor to animate his first creature. When confronted with the decision of animating a second creature, Victor' logic leads him to choose the proven needs of the many over the possible wants of the few.\n\n\n\n\n\nHamlet, on the other hand, focuses his logic entirely on faith and intuition. Without faith in the ghost, there would be no cause for undue suspicion against Claudius; without that suspicion, there would be no catalyst for the mousetrap play, the ranting madness, or the long spoken personal essays looking into himself. The distance between the two calls for revenge is immense, though both are grounded in the logic of what each character believes (after much consideration) to be the truth.\n\n\n\n<!-- more -->\n\n\n\nWilliam Shakespeare and Mary Shelly come at their works from very different angles. Shakespeare spent the autumn and winter of 1599 revising and putting new lines to a story that had already been in circulation for some 500 years, updating it to his times. One prominent aspect of his new take on the classic tale of revenge was the ghost of Hamlet's father. In all previous versions of the play, Claudius' betrayal was well known, and the folk hero Hamlet takes his vengeance for vengeance' sake. Shakespeare's Hamlet, however, is faced with a ghost representative of one of the great issues of Shakespeare's era: the tension between England's Catholic and Protestant churches. This adds an entirely new dimension to the character, and the basis for Hamlet's moral dilemma. In the first act, we hear the ghost comes from \"sulph'rous and tormenting flames,\" a specter calling to \"revenge his foul and most unnatural mur[d]er\" (Act I, Scene V). Hamlet must decide whether to trust this ghost (who might well be a protestant demon in a catholic disguise) or not, prompting him to stage the mousetrap play.\n\n\n\n\n\nIn the 17th and 18th centuries, the continual advances in science and mathematics led Shelley to pen a truly original work that captured the tremendous upheavals brought about by the scientific revolution of the time. Even so, the work of a scientist in her time was still often conducted by rich gentleman born into wealth playing with a hobby picked up in grammar school. Shelly continues this pattern with Victor, a rich boy whose \"ancestors had been for many years counsellors and syndics\" (Chapter 1, Paragraph 1). He is a man who attempts to find a solid, conclusive proof for every action and decision he makes, fascinated by \"the theory which to demonstrate and the wonderful facts which he relates\" (Chapter 2, Paragraph 6). Strong contemporary influences on both authors provide the grounding each has for their stories of tragedy.\n\n\n\n\n\nHamlet's journey into the recesses of his psyche is Shakespeare's breath of life into a beaten and overused plot, and the use of soliloquy, which closely follows the form of the personal essay, allowed Shakespeare to redefine the face of tragedy. What was for Aristotle a \"tragic flaw\" became a conduit for questions of the 'whys' in faith, honor, and duty, exemplified in the third act: \"Whether 'tis nobler in the mind to suffer/The slings and arrows of outrageous fortune/Or to take arms against a sea of troubles\" (Act III, Scene I). While this is indeed Hamlet's tragic flaw (he wouldn't be dead if he had just killed Claudius at prayer), it changed the focus of the drama onto the reasons for his choices, rather than his predestined fate.\n\n\n\n\n\nIn Frankenstein, Victor's single-minded pursuit of knowledge leads to the creation of the monster. Victor's flaw is his irresponsibility: \"Nor could I consider the magnitude and complexity of my plan\" (Chapter 4, Paragraph 7). Had he taken the time to consider his actions, and proceed with both caution and help from a fellow at the university, it is very possible that the monster's fall into savagery could have been avoided. The tragedy is proved more poignant by Shelley's use of Point of View. By switching from one storyteller to another, and then often telling yet another character's story, the point-of-view is only compounded by the additional texts, epistles, and so forth, presenting literally every passage in first person - while maintaining six separate Storytellers.\n\n\n\n\n\nThere are specific passages in each story that clearly show the titular characters' motives and reasons. In Hamlet, act III again illuminates his values and intentions. After the mousetrap play, Hamlet finds Claudius praying in the chapel. \"Now I could do it pat, now he is praying\" has Hamlet with his sword poised to strike. His next thought stops him cold- \"And now he would go to heavens.\" (Act III, Scene III). Faith in heaven and god above stop Hamlet's easy kill; to do so now would negate his revenge and leave Hamlet in a worse position than he was before. Hamlet is, through his faith, forced to wait for a more opportune time; his downfall in the making, as there comes no better time.\n\n\n\n\n\nFrankenstein makes a similar decision in the beginning of Chapter 20. All his logic and reasoning boil down to one thought, shaping his goals and motives for the rest of the novel. [...] one of the first results of those sympathies for which the demon thirsted would be children, and a race of devils would be propagated upon the Earth\" (Chapter 20, Paragraph 1). At this crux, Victor knows the monster will not be amused with his decision, and will as promised seek out to destroy Victor and his family. Yet still, his logic proves that good will prevail, and the monster will die bearing no progeny. Another interesting influence on both leads is their relationships with their families, and their insistence on secrecy in their designs. Neither Hamlet nor Frankenstein are comfortable in revealing their actions; Hamlet forces (with the Ghost's help) Marcellus and Horatio to \"Swear\" they \"never shall, to note that you know aught of me\" (Act l, Scene V). Victor, with no witnesses, makes the same promise to himself: \"I had a persuasion that I should be supposed mad, and this in itself would forever have chained my tongue.\"\n\n\n\n\n\nDreams are significant to both men, as is their symbolism of death and suicide. \"To die- to sleep. / To sleep- perchance to dream\" (Act Scene I) says Hamlet, speaking for both. \"My dreams presented a thousand objects that scared me\" (Chapter 21, Paragraph 35) finishes Victor. Suicide is an easy option, a way to cheat the fate Aristotle demands of their tragedies. Yet, where would that leave their goals? Both seem to think broken and dashed- \"For who would bear the whips and scorns of time, When he himself might his quietus make/ With a bare bodkin? But that the dread of something after death- The undiscover'd country, puzzles the will\" (Act Ill, Scene I). When asked if he was alright, Victor replies \"if indeed I did not dream, am sorry that I am still alive to feel this misery and horror\" (Chapter 21, Paragraph 12).\n\n\n\n\n\nYet again, both are seen through by their guiding forces. Victor, having heard the monster's promise, sets himself to destroy the foul creature on the promised night. With the aid of guards, arms, and his love shared with Elizabeth, only a slight miscalculation on his part sees the monster through, shatters Victor, and finally drives home the determination Victor must have in his endeavor. Hamlet's faith, also, sees him through. While thinking of an easy solution for himself, \"thus conscience does make cowards of us all, / [...] / And lose the name of action\" (Act III Scene I). His faith in his father, the ghost, and himself are too strong, support Hamlet's revenge, mask in his madness and revel in his machinations.\n\n\n\n\n\nThe tragedies see both men to the end of their revenge, but for both, a bittersweet ending. Hamlet's father is avenged. Victor's monster is destroyed. Hamlet is destroyed not by his faith, which saw him through, but by his trust in the gentleman's sport. Victor gives in to true madness, ignoring reason that the monster has fulfilled its desires, and wishes only to be left alone. Had both ended their journeys earlier, at a point where they may not have achieved all their goals, but would put an end to their problems, either character could have averted their drama from tragedy and lived with his companions to another adventure. It is not a single character flaw that defines these tragedies, or a predefined fate that we must see lived out. Shakespeare and Shelley both have characters who act for themselves, and taking their destinies in their own hands have plans that backfire, destroy them not through hubris or purpose, but through subtle points, missed connotations, and double entendres.\n\n\n\n\n\nBibliographical note: all quotations taken from Project Gutenberg e-texts; [Frankenstein](http://www.gutenberg.org/dirs/etext93/frank15.txt) and [Hamlet](http://www.gutenberg.org/dirs/etext97/1ws2610.txt).\n\n\n\n\n\nOriginally written and published September 2007 by David Souther for Linaya Leaf in Rocky's Eng119 course.\n",
      "intro": ""
    },
    "/posts/2008/04/09/435/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2008-04-09T18:00:28.000Z",
        "layout": "post",
        "slug": "435",
        "title": "Augmented Intelligence",
        "wordpress_id": 435,
        "categories": [
          "Technology"
        ],
        "path": "/posts/2008/04/09/435/index.md"
      },
      "body": "### Roadmap to Home Sapiens Coniunctus\n\n_Editor's note: I used to be a terrible writer. This is a paper I wrote for a course in Artificial Intelligence at Rocky._\n\n**David Souther** _4/9/2008_\n\nIn today's world, computers are tools to help humanity process information. Engineers design hardware and programs with the express purpose of helping humans communicate and think more efficiently, but not necessarily more creatively. Computers make it easier to deal with large amounts of information, but we still need people to decide rules on which analysis is possible. The field of artificial intelligence aims to destroy that by removing humans from the equation, so the machines alone can think, decide, and improve. In all science fiction, and most science fact, AI computers are either controlling overlords or degraded slaves. It seems, however, that modern pursuits and trends point towards a more harmonious, if not utopian, symbiosis between man and machine.\n\n<!-- more -->\n\nMachines and computers have always been a means to circumvent human deficiencies. While a team of men can pass buckets to move water uphill, Archimedes felt it was much easier to have one man operate a pump, which coincidentally had several times the water moving capacity as the team of men. The cost in time and effort to develop that one machine compared to the savings in the number of men working on it times the increased amount moved &emdash; doubling the capacity of a three-man team would be a six-fold increase in productivity, and two of the three men can spend their time doing other things (like pumping more water, for an even greater increase in overall productivity). This continues today in computer hardware, especially with Moore's law and Kurzweil's Law of Accelerating returns.\n\nAnother area of continual machine improvement, as mentioned earlier, is access to and distillation of information. With open formats and the Internet, humans have access to tremendous amounts of knowledge; for the past 40 years it is only feasible to absorb that knowledge with the help of computers. Social networking sites display this phenomenon especially well- with a site like Facebook, it is possible to explore incredibly detailed correlations and interactions among a someone's social group- tremendous connections about a person and the flow of information through society. In a business setting, computers provide data mining capabilities and business intelligence mechanisms which allow organizations the ability to forecast and predict trends that allow management and even low employees tremendous decision-making support and possibilities. All this information, however, must be analyzed by a human at the end of the day, when decisions are made. Computers can present information in an easy-to-use format, but people still direct and directly use that data.\n\nThe trends in technology and technological evolution, therefore, should not focus on some abstract, undefined goal of \"consciousness\" but rather incremental improvement over today's decision support capabilities. The field should ignore (for the moment) human creativity, abstraction, and \"consciousness\" and focus on augmenting human capabilities as they stand. This should come about through continued focus on interconnection in all things. This emphasis on connecting humanity brings many advantages. First, it alleviates the pressure of \"Why don't we have artificial intelligence yet\" (because we don't actually need or want it), and second it doesn't face the problem of humans designing something that obsoletes ourselves. Instead, we augment our weakest points with computers strongest, and we augment computer's weakest points with our strongest. in this symbiotic relationship, it becomes possible to take a much more active role in human evolution and progression.\n\nIn this framework, the responsibility of the Engineer is to develop the practices of using theoretical models developed by more traditional scientists. After physicists prove how quantum mechanics can be harnessed to build a computer, engineers are responsible for taking that science, and maturing it as a technology. The benefits of practical application of theory are immense, and could lead to any of dozens of \"science-fiction realities\"- but the actual fact will probably be weirder than anything expected or foreseen. The projections mentioned previously, in fact, face many difficulties when used inappropriately. Moore's Law only makes predictions on the physical size of transistors. It should be obvious that it is impossible to make predictions on how, exactly, those transistors will be used, only that they will be small and packed.\n\nMany fans of Moore's Law and Ray Kurzweil especially try to use these sizes as predictions of what is to come- and often fail. The Kurzweilian technology camp continues to say \"we'll build a brain because we can\" are operating under the belief that a brain is a Turing machine. If that hypothesis is correct, then they will probably succeed in their endeavor. If, however, the human brain is not a Turing machine, they are doomed to failure. The question, however, hasn't been answered. Theoretically, there is only so much information in a brain. That information is contained at some granularity between the molecules and the sub>>atomic particles, but eventually there is only so many possible ways to put those chemicals, or cells, or quarks together. While the Turing Brain hypothesis is probably correct in that light, the interactions of those parts and data is clearly more than capable to process at this time. Further, it is such an unknown quantity that without considerable research help from neurobiologists, and others studying the brain the engineers will never have enough information to approach this goal.\n\nIn the meantime, engineers can and should focus their efforts where the best effect will emerge- intercommunication and data analysis. Computers and the human brain both process information, but in very different ways. While today there is not enough information to accurately emulate how the brain does this task, there is more than enough research into how computers can assist the brain. From planning meetings to correlating atmospheric data, computers can crunch numeric computations accurately much faster than humans. Humans, as I said before, still need to tell the computers how to do so, but the field of artificial intelligence has come to help there- rather than describing the method, there has been much productive work in describing the problem. Instead of doing exactly what humans would do, AI research has developed many techniques to optimize solutions to problems, rather than optimize algorithms.\n\nGenetic engineering and neural networks are the two most prominent techniques in machine intelligence, but their development has brought about shifts in how programmers are able to describe problems, and the much more expressive techniques, while inspired by nature, provide mechanisms to tweak, improve, fiddle, and engineer to the heart\"s content. Allowing researches better ways to examine experimental data, as well as more accurate experimental techniques, lets humans focus their unique powers of abstraction and insight where it can be used best- the specific data computers have tagged as being probably the most important. With brilliant researches and programmers, the computers are usually right, but still have no concept of what that means.\n\nStepping from academia and research to business and personal enterprise, the modern World Wide Web provides access to a wealth of knowledge on every topic. Wikipedia as an acts as a gateway to nearly all humanity' knowledge. Real-time stock, news, and business information enhances decision support to an unprecedented level of accuracy and quality. information services available to augment the human brain are available to any one, for free, at any time. The increased availability of knowledge forces a paradigm shift from learning just in case to learning just in time. It is no longer important to memorize tangent and sine of every 5 degree angle, but it is very important to know the relationship between tangent and sine in order to use the computing resources effectively.\n\nSocial networking sites are changing the face of communities and how people interact. Web services like Facebook and MySpace are growing a collective of people interested in each other, and always in contact with one another. Two friends from high school 20 years ago would have a very difficult time remaining in contact through college and their professional careers; Facebook makes that trivial. These communication abilities are not limited geographically or temporally; these messages are especially low-latency and have the same benefits as traditional letters, but have faster delivery times, and generally make the world more interconnected.\n\nThis trend towards increasing use and integration of technology is where humanity should focus its efforts, and many of the \"science-fiction\" possibilities are only fiction because of a lack of economic interest and development. Following are several possibilities for combining technology and everyday life. While all are fictitious, their possibility should be clear.\n\n### **Example: The Personal**\n\nAll of these examples will revolve around a Personal. Every person has a Personal- the PDA of tomorrow. This device serves as a combination of today's cell-phone, credit card, and identification. This personal has access to a many paid services- the local gym's weight-loss program, Facebook Mobile, and many more. There are several design issues with a Personal. A basic cell phone design would work, and provide options and choices for a consumer. Each Personal works with a cell network, either publicly or privately run, that provide constant, real- time data streaming. Each Personal has a unique PIN, and works otherwise with a cell phone. Services would include GPS access, 911/Emergency support, calls, e-mail, internet, mp3 support, etc.\n\nSecurity concerns should jump to mind immediately. Unfortunately, as with any device, concept, or idea, it can be subverted for malicious purposes. Basic security features of a Personal would be a password to access sensitive data and functions, two-way for all communications, and lock-out features if they are reported stolen. Alternatively, the Personal could be keyed to a specific RFID chip- that is, they only function if held in the owner's hand (who of course has an RFID chip implanted into his thumb).\n\nThe paid services possible with this device are limited only by the number of applications developers (which, looking at the explosion of \"interactive websites\" and Facebook applications are in high numbers. In fact, Facebook would be an excellent proponent of this integration of technology (as well as Paypal, Amazon, and most other online providers). Better, there is actually an applications platform that seems to be very close to what is presented here- Google Android, the first complete, open, and free mobile platform.\n\n### **Example: Weight Watchers**\n\nThe first possible application on the Personal is for a hypothetical health- conscious person. This person goes to Subway for lunch, and orders a nice garden salad with oily, fatty dressing. The Personal swipes past the checkout and the transaction is logged in the person's account. The Personal mentions this to the gym's weight-program, who sends back \"Good choice of salad, but a little concerned about the dressing. You should come in after work and spend 15 minutes on the treadmill.\"\n\nWhile this may sound Sci-Fi, it isn't. Weightwatchers already supports this entire activity~ minus the automatic talking to the gym. Instead, it is left to the person to text or go to WeightWatcher's website, but the connectivity is in place and used today. improvements on this system are many- some obvious, some subtle. Most obvious between here and there is simply combining these services and devices into one system and have them talk to each other.\n\n### **Example: Facebook Collective**\n\nThe Facebook Collective is a group of approximately 60 million Facebook users. While today Facebook lets all these people sit and talk and learn about each other on the website, with the addition of the personal all these people would be instantly connected with one- another. Combined with basic but powerful data-mining techniques, anyone on the Facebook Collective will nearly instantly know of any changes in their social group- Tom and Suzy broke up, Jen has finally decided to spend another on her Education Major, John and Jill had a great time at the recital Adam had to miss. All this real~time and exact knowledge about people around the user results in several things- first, information and opinions travel much faster through the group.\n\nOut on the town, the Personal is a handy GPS device to coordinate with friends- Sandy and Sarah have been txting about drinks at Juervos, a large Carribean club downtown. Not only does the Personal take them to the correct subway line at the right time, it guides them straight to the booth the Personal already reserved for them. The ease of trivial things just happening with this device allow humans to be more productive at work, at play, and at any other activity.\n\n**Bibliography**\n\n[Aleksander, I. Machine Conciousness](http://cs.rocky.edu/~smithk/CSC480/pdf/Aleksander.pdf) Retrieved 4 24, 2008.\n\n[About Facebook](http://www.facebook.com/about.php) Retrieved 4 24, 2008\n\n[Kurzweil, R. The Law of Accelerating Returns](http://www.kurzweilai.net/articles/art0134.html?printable=1) Retrieved 4 24, 2008\n\n[SAMSUNG. (n.d.). Research and Development](http://www.samsung.com/us/aboutsamsung/companyprofile/researchanddevelopment/CompanyProfile_Overview.html) Retrieved 24 4, 2008\n\n[Tononi, G. An information integration theory of consciousness.](http://www.biomedcentral.com/1471-2202/5/42)\n\n[Weight Watchers. About Us. (Weight Watchers International, inc.)](http://www.weightwatchers.com/about/index.aspx) Retrieved 4 24, 2008\n\n",
      "intro": ""
    },
    "/posts/2010/08/30/captains-on-a-manifold/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2010-08-30T16:43:55.000Z",
        "layout": "post",
        "slug": "captains-on-a-manifold",
        "title": "Captains on a Manifold",
        "wordpress_id": 96,
        "categories": [
          "Humor"
        ],
        "path": "/posts/2010/08/30/captains-on-a-manifold/index.md"
      },
      "body": "One day, the two Captains were standing on a Reimann Surface. As they begin to explore their interesting predicament, they encounter a pan-dimensional being with projections into their space. Being explorers and men of science, they approach this pan-dimensional being, and make contact. After a few rounds of introductions, the pan-dimensional being reveals to them it is on a quest, to find a being in the universe able to hear and understand the funniest joke in the world, without dying. Being the villain of this vignette, he of course threatens them with death if they don't comply.\n\nSo, the two captains agree to hear the joke, and immediately, their ears are filled with the sound of German. \"Wenn ist das Nunstück git und Slotermeyer? Ja! … Beiherhund das Oder die Flipperwaldt gersput.\"\n\nInterestingly, neither the Iowan nor the Frenchman die upon hearing it. In fact, they both have a mildly puzzled expression. Then, after a moment's reflection, Picard begins to chuckle. Neither the pan-dimensional being nor Kirk understand quite how Picard sees this humorous, so Picard explains the irony to them. The pan-dimensional being has never been so astounded in its existence, and immediately returns the two captains to normal, every-day Euclidean spacetime on the bridge of the Enterprise. Kirk is still a bit confused (not the least because this is the Enterprise E), and asks Picard again for an explanation.\n\n\"It's simple, really- the proof Lies in group theory.\"\n"
    },
    "/posts/2010/12/07/crosslight/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2010-12-07T17:23:52.000Z",
        "layout": "post",
        "slug": "crosslight",
        "title": "Crosslight",
        "wordpress_id": 5,
        "categories": [
          "Technology"
        ],
        "path": "/posts/2010/12/07/crosslight/index.md"
      },
      "body": "Crosslight is a way to use web development practices to bring dynamic content to the desktop. Using lighttpd as a base, and putting PHP and SQLite on top, we have a full application development and delivery platform that lets web designers and developers deliver fully-functioning, cross-platform desktop applications without having to learn new technologies.\n\n[http://code.google.com/p/crosslight/](http://code.google.com/p/crosslight/)\n"
    },
    "/posts/2011/02/15/american-empire/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2011-02-15T01:56:11.000Z",
        "layout": "post",
        "slug": "american-empire",
        "title": "American Empire",
        "wordpress_id": 17,
        "categories": [
          "Politics"
        ],
        "path": "/posts/2011/02/15/american-empire/index.md"
      },
      "body": "_Note: I originally wrote this in February 2011, at the beginning of the Arab Spring. It goes on a little bit of a ramble, and I really should have tried to focus, but it's just a personal essay._\n\nTwenty-three years ago, the Soviet Empire collapsed. With the resignation of Hosni Mubarak and the continued protests and revolutions sweeping North Africa and the Middle East, the American empire is collapsing. As with the collapse of the Soviet Empire, the power vacuum created in the wake of social change in north Africa will rewrite the international political landscape. Alarmingly, the potential for disaster is much higher today than in 1988. America's empire has been the lightest-handed of empires as history goes. It levies no taxes in Egypt or South Korea or Iraq that return to the federal government, yet all international crude oil exchanges are based on the dollar-- this requires all foreign nations to continue to buy into the American economy, even as it approaches a $14.5 trillion debt. The amount of foreign aid the US gives each year to states with ``sympathetic governments\" in return for favorable trade policies and military support puts the United States in the same class as Rome and England. In return for the dollar being the baseline for international currency, the United States exports culture and brands to every corner of the globe, with more worldwide military presence than even England could muster in her prime. It is this size and might that makes America's potential fall so dangerous for the entire world economy.\n\n<!-- more -->\n\n### Revolutions\n\n\nHistory, especially since the 1700s, is littered with revolutions. Most failed. While nearly all were started by a disenfranchised citizenry, too many were ended not by an equitable restructuring of power but through a takeover by a hostile military presence which left the instigators even more powerless. Napoleon and the French Revolution, South Africa's Boer Wars followed by Apartheid, or Algeria and nearly 20 years of bloody civil war. America is an exception in overthrowing a government, and replacing it with something that was actually better for its people (neglecting the war over slavery 70 years later). Even so, look at the world today. France, after another 100 years of revolutions, did manage to emerge as a world leader in freedom and democracy. Germany, after the horrors of Nazism, has emerged as a country with one of the strongest economies world-wide. Germany's struggles after the second World War were not trivial - the separation amongst the super powers drew such disparity between East and West that it took the collapse of an empire to unite the country and make it possible to build that economy.\n\nRevolutions involving empires affect everyone. In 1988, when the Berlin Wall fell, it was not a celebration just for the people of Berlin and Germany. The cold war was at an end, and one by one after Germany all of Eastern Europe threw off the yoke of Soviet rule. None faired as well as Germany. Armenia and Azerbaijan continued infighting and warring over ethnic regions, Belarus appointed an authoritarian democracy, and Yugoslavia stole the world stage with ethnic cleansing. Even as the threat of mutually assured destruction retreated, the world has yet to come to grips with the tensions unleashed after the fall of the USSR. The history of revolt is a troubling one, and there is little historical evidence of a people's revolt ending in happiness and prosperity. It is this history that must be kept firmly in mind when examining the causes and fallout of today's protests.\n\n\n### Youth Leading Freedom\n\n\nOne striking difference between the revolutions in America in the 1770s and Germany in the late 1980s is a similarity between Germany and today's movements in north Africa. The revolutions of the past 30 years share a youthful and energetic leadership, which have used mass media in drastically new ways. The American Revolution was largely pushed by the landowners and the wealthy, whereas the revolutions in the last 25 years have been driven by the youth empowered with forms of communication their governments could not control. In East Germany, the allure of western culture and the prosperity of the free market, as well as the artistic freedom of western culture, drove artists and intellectuals to spark the revolution against censorship, Chancellor Honeker, and ultimately the entire Soviet regime. In Egypt, the youth movement utilize Twitter, Facebook, and other social networking services to organize massive protests, and organize those protests in the face of a government working with all its might to stop those outlets of communication.\n\nWith these channels of communication, it must be very difficult to miss the glaring differences in standards of living between countries with authoritarian regimes, and countries with true democracies and equitable free markets. Many in Egypt have lived under the same president for their entire lives. This should be unheard of in a healthy democracy. While Hosni Mubarak has claimed victories of 80% of the vote in polls for the last three decades, the most popular American presidential election only won 60% of the general vote. As the people of Egypt, Tunesia, Yemen, Iran, and elsewhere look around the governments of their countries, it seems apparent that the supposed power is held by relatively few - yet the number of disenfranchised populus is much larger. The victories of the past have often been popular uprisings. The labor unions of the late 19th century should be a prime example for how the many wield much greater power than the armed when standing shoulder to shoulder with their brothers and sisters. Seeing the protests of the people in history, and the protests of their neighbors today should be enough to give many the impetus to seize control of their governments. It has been said that when it becomes necessary to dissolve political bonds which have held men together, respect to the opinions of mankind requires that they should declare causes. For the people of these nations, the causes are self-evident.\n\nWhile it is right and just that the people of Egypt, Tunesia, Algeria, and others should dissolve the current governments, the rest of the world must watch and consider what this will mean to the future for the rest of the peoples of Earth. It is possible (indeed, historically probable) that many of these governments will be replaced with a more authoritarian ruler. This is something the nations of the world must fight against. Overpopulation and unemployment are certainly concerns to a healthy and self-actualized populace, but if a junta or all-out dictatorship is allowed to flourish in the wake of these protests, genocide seems inevitable. The people of Egypt, should immediately request and demand that the ruling military council be replaced with a United Nations peacekeeping force until democratic elections are carried out and the government transitions to a new civilian leadership. This request must come from inside Egypt- otherwise, it will merely be another unilateral intervention by the United States.\n\nAssuming the worst case scenario doesn't happen, it is very unlikely that any government that replaces Mubarak will be quite as open and friendly to American interests as Mubarak. This will not be a serious blow to US military power, or create a power vacuum filled by terrorist extremists. It has been pointed out many times already that the Egyptians have just as much interest as America, and every other modern state, to shun violent extremism and work to effectively combat it whenever possible. If the Muslim Brotherhood did win a majority leadership in Egypt, they would be foolish to take any serious actions contrary to the status quo. A serious military engagement with Israel would be catastrophic for Egypt. A change in posture pressuring Israel to change its policy regarding Palestine may actually help stabalize the region. Whatever happens, a gap will grow between Egypt and the United States.\n\nAs nations like Egypt become less tied to the United States, it becomes easier to look for alternative international currencies. If it were possible to buy a barrel of oil using the Euro, or the Yuan, there would no longer be a dependency on the US dollar for nations, especially African, Asian, and South American nations, to buy US dollars. With a stronger Muslim leadership in Egypt, treaties between Egypt and Saudi Arabia, or Egypt and Iran, could significantly change the balance of power in international money concerns. If a new Egyptian government pushes the Iranian Oil Bourse to start selling crude, the world currencies would open to more than just the dollar.\n\n\n### Internal Struggles\n\n\nThe importance of a strong currency for an empire's continued success cannot be understated. The cold war has been described, not unjustly, as a race between the United States and the Soviet Union of which nation could spend more faster. Just as the Soviet Union was reaching a budget and social crisis while the Berlin wall fell, so too is America facing similar problems. America's deficit spending as percentage of GDP is not unprecedented, but there seem to be very few who are comfortable with the US National Debt at $14.5 trillion. The first few months of 2011 have seen a shaping political battle over a budget that seems unfathomable by mere mortals. The midterm elections in 2010 saw a trail of campaign rhetoric and a swing in the political power base unprecedented in electoral history. In the wake of the 2008 housing crisis, the American people are deeply concerned with the state of the nation and the world, yet seem unable to find an appropriate outlet or leadership to emerge strong.\n\nOn a world scale, this debate and discussion the budget has sparked at all levels of US politics is much more important than the actual dollar amount of the US Federal Debt. With the rise of the Tea Party and their call for smaller government, the conservative bloc in the US is creating a frenzied and fervent political environment. This is an environment where solutions cannot be presented because they might be too difficult, when in fact they are not. Polls consistently show there is no area of the Federal budget that Americans want to see cut. All the services provided by the Federal government are seen as necessary and vital. All the services provided by the Federal government demand jobs. Cutting these services will put Americans out of work. There is only one conclusion: the Federal Government must increase its sources of revenue. In the globalized economy, tariffs are out of the question. This leaves two main sources of revenue, taxes and fines.\n\nMainstream conspiracy theorists like Fox News' Glenn Beck are presenting an irrational and inconsistent view of the realities of today's world. This is a dangerous way to discuss policy on any level. Glenn Beck's rhetoric when backed by a network as powerful and respected as Fox News opens the door for irrational and patently false propaganda to spread and influence decisions. The American electorate is called to support candidates whose policies will harken a throwback to a turn of the 20th century state, with the worst of free market abuses destroying the lives and livelihood of the very people who were coerced into voting to allow it.\n\n\n### The World Tomorrow\n\n\nIf America follows that path, revolutions will only serve to further weaken the United States. Whether they are replaced with a successful and peaceful democracy or with a new but different authoritarian regime, governments will not be as friendly to today's United States. An America guided by fear and irrationality will certainly not support any new Egyptian government. China will seize any opportunity it has to improve relations with African nations. If the United States were to be so pinheaded as to return to a gold standard, China will need countries to export to. An emerging Africa and an emerging South America fit that bill perfectly. The path advocated by the Tea Party and Fox News is the path of American isolationism and a nation that is irrelevant on the world stage. With no other nations to step in as strong humanitarian leaders, many revolutionary nations will not follow in the footsteps of the United States or Germany, but rather fall into yet another authoritarian government. The concept of human rights will be null and void, and the world will live under a state-sponsored anarchy, where the strong get stronger and the weak are destroyed and trampled. Humanity will fall to a second dark age.\n\nThis is not the only path available. One alternative is a shift in American foreign policy. The age of super powers is past. Shock and awe military tactics will not deter terrorism. Russia and China are not credible military threats. Both nations know that while there is no threat of mutually assured destruction, there is a promise of mutually assured destruction, which neither nation will risk. This leaves Pakistan, India, Iran, and North Korea as the only major nuclear threats. None of these nations would be so stupid as to attack the United States, China, or Russia directly, but an attack on South Korea, Israel, or India and Pakistan attacking each other is not out of the question. A strong American military will do nothing to deter these attacks, and US involvement will only make China's reaction stronger. In this scenario, western intervention is untenable.\n\nThe solution is two-fold. The United States must make drastic cuts to the Department of Defense, while simultaneously strengthening the United Nations as a body with actual peace-keeping possibilities. This is not unprecedented. After Shay's rebellion in 1787, a fledgling union of states saw their Articles of Confederation were not enough to keep that nation together. The wealthy landowners who had thrown off oppressive rule ten years earlier reconvened to rewrite the rules of their new nation. Chief amongst those was a strong federal military and a mechanism for funding the federal government. The arguments between the Federalists and Anti-Federalists are the same arguments that will happen around a strengthened (or rewritten) United Nations, but the conclusion is the same. There must be a strong international federal government that serves all of humanity. With such a government, we will guarantee a productive and healthy future for all. Without such a government, we will guarantee a future where our children struggle for the most basic of living necessities.\n",
      "intro": ""
    },
    "/posts/2011/06/10/jmtt-jquery-minimal-tree-table/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2011-06-10T22:01:54.000Z",
        "layout": "post",
        "slug": "jmtt-jquery-minimal-tree-table",
        "title": "jmtt - jQuery Minimal Tree Table",
        "wordpress_id": 57,
        "categories": [
          "Technology"
        ],
        "tags": [
          "jmtt",
          "jquery",
          "jquery ui"
        ],
        "path": "/posts/2011/06/10/jmtt-jquery-minimal-tree-table/index.md"
      },
      "body": "My dad mentioned an interesting project to me the other day, posing the challenge of coming up with an interface for examining deep rubrics for grading classes, or businesses, or anything that needs a grade. The idea is that you have a tree of different aspects that go into an overall grade. The interface needs to show this tree breakdown, while showing several controls with each item in the list. In short, the interface needs a [Tree Table](http://designinginterfaces.com/firstedition/index.php?page=Tree-Table).\n\n**[See jmtt in action!](http://davidsouther.com/projects/jmtt/tree.html)**\n\n<!-- more -->\n\nThere are a few treetable components out there ([Swing](http://java.sun.com/products/jfc/tsc/articles/treetable1/), [Qt](http://doc.qt.nokia.com/4.7-snapshot/qtreewidget.html), [ASP.NET](http://www.codeproject.com/KB/aspnet/ASPNET_TreeView_using_C_.aspx)), but I wanted to do this in jQuery. Because jQuery is the bees knees, and distributing apps purely in the browser is something I've been working towards. With that in mind, the design goal is that the application would be a single folder, completely self contained, and run by opening a .html file. Not being one to reinvent the wheel, I took a look at what plugins there were and found [treeTable](http://ludo.cubicphuse.nl/jquery-plugins/treeTable/doc/) and [JQTreeTable](http://www.hanpau.com/index.php?page=jqtreetable). Unfortunately, both are terrible. The HTML needed is horribly, disgustingly unsemantic. treeTable uses class and id attributes of the tr tags, and JQTreeTable has you pass in a map of child to parent ids. BLECH! Having to add an id to every row, and then ask a designer to follow that? NO!\n\nSo, I wrote my own. The guiding, number one goal was a semantic markup- the list hierarchy *MUST* be conveyed using a ul/li structure. Beyond that, the plugin should be as configurable as possible, while using as clean a plugin architecture as possible. Since this was my first trip around the jQuery ui block, I found bililite.com's [jQuery UI Widget tutorial](http://bililite.com/blog/understanding-jquery-ui-widgets-a-tutorial/) an invaluable resource.\n\n```html\n<ul id=\"tree\">\n    <li class=\"head\">\n        <span class=\"aspect\">Aspect</span><span class=\"weight\">Weight</span><span class=\"grade\">Grade</span><span class=\"cost\"/>Cost</span><span class=\"value\"/>G/$</span>\n    </li>\n    <li>\n        <span>Software Develoment</span><span>70%</span><span></span>\n        <ul>\n            <li>\n                <span>Design</span><span>30%</span><span></span>\n                <ul>\n                    <li>\n                        <span>Requirements</span><span>33%</span><span>85</span><span>30</span>\n                    </li>\n                    <li>\n                        <span>Mockups</span><span>33%</span><span>90</span><span>5</span>\n                    </li>\n                    <li>\n                        <span>Planning</span><span>33%</span><span>60</span><span>50</span>\n                    </li>\n                </ul>\n            </li>\n            <li>\n                <span>Development</span><span>50%</span><span>80</span><span>70</span>\n            </li>\n            <li>\n                <span>QA</span><span>20%</span><span>50</span><span>100</span>\n            </li>\n        </ul>\n    </li>\n    <li>\n        <span>Marketing</span><span>30%</span><span></span>\n        <ul>\n            <li>\n                <span>Online</span><span>45%</span><span>85</span><span>10</span>\n            </li>\n            <li>\n                <span>Print</span><span>35%</span><span>60</span><span>25</span>\n            </li>\n            <li>\n                <span>Radio</span><span>25%</span><span>75</span><span>15</span>\n            </li>\n        </ul>\n    </li>\n</ul>\n```\n\nPretty minimal, isn't it? The API is exposed through triggers, in a very functional way. Extending is easy, as show in the full demo. The code is available at [http://code.google.com/p/jmtt/](http://code.google.com/p/jmtt/) under an lgpl license. For bonus points, the columns are resizable.\n",
      "intro": ""
    },
    "/posts/2011/08/01/software-craftsmanship-workbooks/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2011-08-01T23:05:10.000Z",
        "layout": "post",
        "slug": "software-craftsmanship-workbooks",
        "title": "Software Craftsmanship Workbooks",
        "wordpress_id": 46,
        "categories": [
          "Software Craftsmanship",
          "Technology"
        ],
        "path": "/posts/2011/08/01/software-craftsmanship-workbooks/index.md"
      },
      "body": "Like any skill, software craftsmanship takes practice. Because there are so many programming languages available, and each has something unique to offer, I've broken the programming exercises in the book out into separate workbooks. Each workbook follows the main text, providing programming tutorials that cover the main concepts in a specific language. I am writing these workbooks in three languages, C, Javascript, and Python. \n*   Software Craftsmanship C Workbook (Coming soon!)\n*   [Software Craftsmanship Javascript Workbook (Draft)](http://davidsouther.com/wp-content/uploads/2012/07/software_craftsmanship_javascript.pdf)\n*   Software Craftsmanship Python Workbook (Coming soon!)\n\n\n\n"
    },
    "/posts/2011/08/01/software-craftsmanship/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2011-08-01T01:53:35.000Z",
        "layout": "post",
        "slug": "software-craftsmanship",
        "title": "Software Craftsmanship",
        "wordpress_id": 14,
        "categories": [
          "Software Craftsmanship",
          "Technology"
        ],
        "path": "/posts/2011/08/01/software-craftsmanship/index.md"
      },
      "body": "I'm writing a book! I have a degree in computer science, but that's really not what I do. I am a software developer, which focuses on a rather different aspect of computers and programming than what most computer science degrees offer. In my undergraduate work, there were maybe a half-dozen group assignments in the entire 4 year program. In the \"real world\", software is almost never developed in isolation. So, I want to write a textbook that introduces software craftsmanship to someone who has never programmed in their life. After working through this book, the reader will be able to go forth into the great realm of software development with an overview of the basic tools of both how to program, and how to collaborate with other programmers. I'll be posting PDFs of the book online as I work on drafts. \n*   [Software Craftsmanship](http://davidsouther.com/wp-content/uploads/2012/07/software_craftsmanship.pdf)\n*   [Software Craftsmanship Workbooks](http://davidsouther.com/2011/08/software-craftsmanship-workbooks/)\n\n\n\n"
    },
    "/posts/2011/08/05/verbal-shell/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2011-08-05T08:36:48.000Z",
        "layout": "post",
        "slug": "verbal-shell",
        "title": "Verbal Shell",
        "wordpress_id": 30,
        "categories": [
          "Technology"
        ],
        "tags": [
          "glados",
          "jarvis",
          "shell",
          "voice"
        ],
        "path": "/posts/2011/08/05/verbal-shell/index.md"
      },
      "body": "I think it's time for an attempt at an auditory shell, a la Star Trek: The Next Generation.\n\n\"Computer&lt;pause&gt;\" - The shell knows the next phrase is going to be a command for it, not background conversation\n\n\"What is the current accepted value of the gravitational constant?\"\n\"The value of the gravitational constant is six point six seven times ten to the negative eleventh Newton square meters per kilogram squared.\" ([http://www.wolframalpha.com/input/?i=+What+is+the+current+accepted+value+of+the+gravitational+constant%3F](http://www.wolframalpha.com/input/?i=+What+is+the+current+accepted+value+of+the+gravitational+constant%3F))\n\n<!-- more -->\n\n\"Computer, what is the current disk usage of my home folder?\"\n\"Your home folder, dev es dee aye four, is using forty-four percent of the available seven-hundred ninety-four gigabytes.\"\n(`$ df | grep /home\n/dev/sda4 ext4 794G 327G 428G 44% /home`)\n\nYes, a **lot** of work with NLP, but with the right suggestions library, I think it would be possible to create a wrapper that includes hooks to WolframAlpha, CoreUtils, and some of the open desktop specifications (notification tray? knowledge of .desktop files, so I can \"Computer, Open Skype), and an API for programs to supply their own hooks\n",
      "intro": ""
    },
    "/posts/2011/08/11/particle-indistinguishability-scale-limit/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2011-08-11T05:14:24.000Z",
        "layout": "post",
        "slug": "particle-indistinguishability-scale-limit",
        "title": "Particle Indistinguishability Scale Limit",
        "wordpress_id": 13,
        "categories": [
          "Science"
        ],
        "tags": [
          "indistinguishability",
          "quantum mechanics"
        ],
        "path": "/posts/2011/08/11/particle-indistinguishability-scale-limit/index.md"
      },
      "body": "[QFT](http://en.wikipedia.org/wiki/Quantum_field_theory) says that all particles are indistinguishable from one-another [1]. That is, take a proton from cosmic ray from a supernova a billion light-yeas away, and compare it to a proton that just got smashed out in the LHC, and they are indistinguishable from one-another. Replace either with the other, and nothing will change. (As I understand) this applies to all particles that arise from the standard model fields- fermions and bosons. So if I have an atom, all the electrons in the atom are indistinguishable from all the other electrons in the atom. Theoretically I then take that atom and interchange it with any other \"indistinguishable\" atom. Or can I?\n\n<!-- more -->\n\nObviously I can't replace hydrogen-1 with deuterium (their masses are different), so atoms are at least distinguishable to their isotopes. What about within isotopes? The volume of an orbital in an electron cloud is larger than the Compton length of the electron by a factor of about [latex]10^7[/latex], giving a tremendous volume that is vacuum, and the probability of getting the election clouds just right to have negligible effects on the quantum field seems unlikely. So, are two [latex]{}^2\\text{H}[/latex] atoms indistinguishable from one another? Let's say that does work, and we can say isotopes are indistinguishable. Now, I pose the same question for molecules. What do I need to know about two water molecules? In QFT and GR, there are the 4 spacetime dimensions. I clearly can't just take a water and replace it with another water by swapping their [latex](\\vec{x}, t)[/latex] properties, because they might be \"upside -down\" and then all the hydrogen bonds will get messed up and their dipole moments will be wacky (and let's not even think about ionic or superionic water). So, it seems I have at least answered my question at that scale - molecules are not indistinguishable from one another on their physical properties alone. For polar molecules in a \"normal\" form, we have at least 6 dimensions that must be swapped (assuming we can get away with calling the atoms themselves indistinguishable).\n\nThe final question, then, is what is the limit that systems are no longer indistinguishable based on just their physical properties?\n\n[1] [http://www.damtp.cam.ac.uk/user/tong/qft/qft.pdf](http://www.damtp.cam.ac.uk/user/tong/qft/qft.pdf) page 3.\n\n(Cross-posted at [http://physics.stackexchange.com/questions/13455/particle-indistinguishability-scale-limit](http://physics.stackexchange.com/questions/13455/particle-indistinguishability-scale-limit))\n",
      "intro": ""
    },
    "/posts/2011/08/12/why-is-time-special/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2011-08-12T15:17:50.000Z",
        "layout": "post",
        "slug": "why-is-time-special",
        "title": "Why is time special?",
        "wordpress_id": 76,
        "categories": [
          "Science"
        ],
        "tags": [
          "relativity",
          "spacetime",
          "special relativity",
          "time"
        ],
        "path": "/posts/2011/08/12/why-is-time-special/index.md"
      },
      "body": "In Special Relativity, the spacetime interval between two events is [latex]s^2 = -(c{\\Delta}t)^2+({\\Delta}x)^2+({\\Delta}y)^2+({\\Delta}z)^2[/latex] giving the Minkowski metric [latex]\\eta_{\\mu\\nu}=\\text{diag}(-1, 1, 1, 1)[/latex]. What is the justification for making time have a negative coefficient, and how closely is that related to the 2nd law of thermodynamics? Sure, by letting [latex]\\eta = \\text{diag}(1, 1, 1, 1)[/latex], we get a pretty boring spacetime, and the boosts in the Poincaré group become trig instead of hyperbolic functions, but what's the physical reasoning behind this?\n\n(Cross-posted at [http://physics.stackexchange.com/questions/13451/why-is-time-special](http://physics.stackexchange.com/questions/13451/why-is-time-special))\n"
    },
    "/posts/2011/08/14/coding-standards/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2011-08-14T04:46:48.000Z",
        "layout": "post",
        "slug": "coding-standards",
        "title": "Coding Standards",
        "wordpress_id": 105,
        "categories": [
          "Coding Standards",
          "Technology"
        ],
        "tags": [
          "coding",
          "standards",
          "style guidelines"
        ],
        "path": "/posts/2011/08/14/coding-standards/index.md"
      },
      "body": "Coding standards are a Good Thing™. When working in a team it is critically important to be able to read code written by other developers, immediately understand what is happening and how they are thinking. Coding standards facilitate this process in two critical ways. One, standards remove the uncertainty of reading a new piece of code. A unified, followed standard guarantees that similar blocks will be formatted the same. Two, standards allow an additional layer of semantics for the human readers of code on top of the language features recognized by the compiler. This technique is part of programming into a language. The criterion for a good standard is fourfold. First, it should visually highlight the “flow” of the code. Second, it should make common typographical errors become fatal code smells. Third, it should be flexible to adapt to new languages and technologies. Fourth, it should encourage programmers to write literate code. Above all, these requirements follow the guiding principle of making software better to use and easier to write. These are my standards for code, with explanations for how they fit in these goals.\n\n  * [Files](http://davidsouther.com/2011/08/general-rules-for-program-source-files/)\n  * [HTML](http://davidsouther.com/2011/08/html-coding-standards/)\n  * [CSS](http://davidsouther.com/2011/08/css-written-right/)\n  * [C-Style (Improved Allman)](http://davidsouther.com/2011/08/improved-allman-style/)\n  * [gedit](http://davidsouther.com/2011/08/gedit-tips-tricks/)\n"
    },
    "/posts/2011/08/14/css-written-right/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2011-08-14T04:10:47.000Z",
        "layout": "post",
        "slug": "css-written-right",
        "title": "CSS Written Right",
        "wordpress_id": 115,
        "categories": [
          "Coding Standards",
          "Technology"
        ],
        "tags": [
          "coding",
          "css",
          "standards",
          "style guidelines"
        ],
        "path": "/posts/2011/08/14/css-written-right/index.md"
      },
      "body": "I have never seen a large CSS file that I thought was maintainable. In programming languages, we use indentation exhaustively to provide visual cues of related blocks of code. Unfortunately, CSS is often a giant wall of text, with all selectors at col 0 and all properties starting 1 tab deep. Instead, CSS blocks should be indented based on their selector’s expressiveness. In the example, we have body, a, and .content-wrapper all at the same level. Then, we indent .content-wrapper h1 one extra level, visually demarcating it as subordinate to .content-wrapper. In large CSS files, not only does this make it much easier to quickly scroll code, it discourages excessively deep selectors, encouraging designers to be more descriptive and accurate.\n\n<!-- more -->\n\n### Example\n\n``css\nbody {\n\tfont:bold 12px Arial, Helvetica, sans-serif;\n\tcolor: #333;\t}\n\na {\n\ttext-decoration:none;\t}\n\n\ta:hover {\n\t\tcolor:#000;\t}\n\n.content-wrapper {\n\twidth:850px;\t}\n\n\t.content-wrapper h1 {\n\t\tpadding-left: 22px;\t}\n\n\t.content-wrapper p {\n\t\tbackground:none;\n\t\tcolor:#44b5df;\n\t\tfont-weight:normal;\n\t\tpadding-top:10px;\n\t\tpadding-left:0;\t}\n\n\t\t.content-wrapper p em {\n\t\t\tbackground-color: #ffffde\t}\n\n\t.content-wrapper > div {\n\t\tfloat:left;\n\t\tmargin: 0 0 0 5%;\n\t\twidth: 45%;\n\t\tpadding:0 0 20px 0;\n\t\tborder-bottom:dashed 1px #CCC;\t}\n```\n\n(There should be another new line between selector rule blocks- I'm not sure why the code view isn't working :()\n\n\n### Rules\n  * Dashes between words, NOT camel cased\n    * See section in HTML about ids for why.\n  * Reset style condensed as much as possible.\n    * [http://meyerweb.com/eric/tools/css/reset/](http://meyerweb.com/eric/tools/css/reset/)\n  * Eliminate redundancy\n    * Move inherited declarations up in the cascade\n  * Blocks indented by specificity\n    * .about-scanning has no indentation, .about-scanning h1 is one level deep\n  * Selectors on one line with brace { at end of line\n  * Properties one per line\n  * Closing brace } one tab past last property\n  * Always use short-hand properties (font, margin, padding)\n  * Layout sizes in em or %\n    * Creating flexible layouts is a good thing.\n  * px for specific images\n  * Use any [selectors](http://www.w3.org/TR/CSS2/selector.html)necessary, but know them all.\n    * [> for children](http://www.w3.org/TR/CSS2/selector.html#child-selectors)\n    * [+ for siblings](http://www.w3.org/TR/CSS2/selector.html#adjacent-selectors)\n    * etc\n  * Use comments /* ... */ liberally to describe the purpose of rules, or the intended effect\n",
      "intro": ""
    },
    "/posts/2011/08/14/gedit-tips-tricks/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2011-08-14T04:46:10.000Z",
        "layout": "post",
        "slug": "gedit-tips-tricks",
        "title": "gedit Tips & Tricks",
        "wordpress_id": 129,
        "categories": [
          "Coding Standards",
          "Technology"
        ],
        "tags": [
          "coding",
          "gedit",
          "standards",
          "style guidelines"
        ],
        "path": "/posts/2011/08/14/gedit-tips-tricks/index.md"
      },
      "body": "[gedit](http://projects.gnome.org/gedit/) is awesome. Lightweight, with an excellent plugin ecosystem. It is a text editor. Not an IDE. Not a programming environment. All it does it text. That is a Good Thing™. With a few small tweaks, gedit will do LaTeX, C, C#, Haskell, or any other text-based thing you want to do. It embodies the Unix principle of doing one thing only and one thing well, while providing all the modern conventions we expect text editors to follow today (sorry, but both Vi and Emacs are weird for anyone who's learned to type in the last 10 years). gedit provides plenty of configuration options. These are the tips and tricks to make gedit just that much more awesome to help developers (me) meet the style guidelines I have here.\n\n<!-- more -->\n\nAll of these settings are accessible form the Preferences menu (Edit -> Preferences)\n\t\n  * View\n    * Disable Text Wrapping\n    * Enable Line Numbers\n    * Highlight Current Line\n    * Display right margin at column 80\n    * Highlight Matching Bracket\t\n  * Editor\n    * Tab Width 4\n    * DO NOT insert spaces instead of tabs\n    * Enable Automatic Indentation\n  * Fonts and Colors\n    * Classic and Oblivion are excellent\n  * Plugins\n    * Some of these come from gedit-plugins-extra and the plugins gallery\n      * Change Case\n      * Character Map\n      * Code Comment\n        * ^m to comment, ^M to uncomment\n      * Document Statistics\n      * Draw Spaces\n        * Draw Tabs\n        * Draw non-breaking spaces\n        * Draw Leading Spaces\n        * Draw Trailing Spaces\n      * Embedded Terminal\n      * File Browser Pane\n      * Insert Date/Time\n      * Join/Split lines\n      * Python Console\n      * Sort\n      * Spell Checker\n",
      "intro": ""
    },
    "/posts/2011/08/14/general-rules-for-program-source-files/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2011-08-14T03:55:32.000Z",
        "layout": "post",
        "slug": "general-rules-for-program-source-files",
        "title": "General Rules for Program Source Files",
        "wordpress_id": 107,
        "categories": [
          "Coding Standards",
          "Technology"
        ],
        "tags": [
          "coding",
          "standards",
          "style guidelines"
        ],
        "path": "/posts/2011/08/14/general-rules-for-program-source-files/index.md"
      },
      "body": "### General\t\n  * Do not wrap lines of code.\n    * If a line starts getting longer than 79 characters, it should be refactored.\n      * Narrow screens are still not uncommon. Many programmers have toolbars and other windows taking up the sides of the screen. The human field of vision still needs to scan vertically. 80 is still the magic number for line width.\n  * Wrap lines of comments at the 79th column\n  * Always break comment lines on a space, don’t hyphenate by hand.\n\n### File Format\n  * Files should be saved with Unicode (UTF-8) encoding.\n    * It just works well, and most tools expect and handle UTF-8 well.\n    * The BOM should not be used.\n  * Unix line endings should be used (LF, \\n).\n    * Most source control tools expect, and greatly prefer, Unix line endings.\n"
    },
    "/posts/2011/08/14/html-coding-standards/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2011-08-14T04:03:45.000Z",
        "layout": "post",
        "slug": "html-coding-standards",
        "title": "HTML Coding Standards",
        "wordpress_id": 111,
        "categories": [
          "Coding Standards",
          "Technology"
        ],
        "tags": [
          "coding",
          "HTML",
          "standards",
          "style guidelines"
        ],
        "path": "/posts/2011/08/14/html-coding-standards/index.md"
      },
      "body": "### Doctype\n  * `<!DOCTYPE html>`\n    * In the age of HTML5, this is all you need, and it’s a full 2/3s the length of an html4 transitional DOCTYPE.\n\n### html\n  * No xmlns\n    * You’re writing html5. Even in xhtml, when’s the last time you needed to embed an alternative xmlns in your docs? (If you’re working on a project that actually does use namespacing, than you aren’t using HTML5)\n  * Specify `lang=\"en\"` (or whatever your page’s language is)\t\n    * It’s just good practice to tell everyone what you’re speaking before you start talking. Plus, Google Chrome will pop up the little “Want to translate this page?” bar for your foreign visitors!\n\n<!-- more -->\n\n### head\n  * `<meta charset=\"utf-8\" />` should be the first tag in the head, and must be in the first 512 bytes of the page.\n    * Always specify the encoding. It’s just good practice.\n  * No content-type meta tag (should be set in HTTP headers)\n    * If you don’t have control over this, and your host isn’t set up correctly, you should be having a conversation with your server.\n  * `<title>` MUST be present and have sensible text content.\n  * `<script>` and `<link rel=\"stylesheet\">` tags should be grouped together, separated by whitespace\t\n    * That is, put all your scripts, then a blank line, then all your stylesheets. Or vice versa. If they’re grouped, it’s just that much easier to find.\n  * `<script>` tags should only use the href attibute- they MUST NOT contain actual script code.\n    * MVC is a Good Thing. If your framework doesn’t make it trivially easy to add a new script to the page for a new feature, take a look at your framework.\n  * `<script>` and `<link>` tags should not specify a type.\t\n    * The type will be sent by the HTTP headers.\n  * `<style>` tags ARE NOT allowed.\n    * See MVC is Good above.\n### body\n  * Every block level opening tag must be on its own line.\n  * Every block-level closing tag must be on its own line.\n  * Exceptions for the first element inside the `<body>` tag.\n  * Every block level element should be indented the same tab level as its siblings, which is one more than its parent.\n  * One blank line when separating sibling block-level tags.\n    * Exception: when mixing `<h_x_>`, `<p>`, and `<div>` inside a block, do not separate with whitespace.\t\n    * Example:\n```html\n<h2>This Section</h2>\nParagraph 1\n\nParagraph 2\n<ul>\n\t<li>Some</li>\n\t<li>list</li>\n\t<li>stuff</li>\n</ul>\n```\n      * Be sensible with classes and ids.\t\n        * ids should be used on nodes that need to be uniquely and quickly identified\n          * eg. specific content blocks, `<a>` buttons, forms.\n        * Classes should be used to reduce or eliminate redundancy in CSS\n      * classes and ids must use dashes between words, NOT camel case\n        * eg. `about-scanning`, `content-left` instead of `aboutScanning`, `contentLeft`\n          * This guarantees html classes and IDs cannot conflict with javascript or php variables. This means when you forget quotes in selectors, like $(my-id), there’s a much higher chance of the JS interpreter throwing a syntax error, instead of making you wonder how my_id happened to get defined to “#other-thing” in a global block somewhere.\n      * Text must be inside `<p>` or `<h_x_>` tags.\n      * Content must be grammatically correct English.\n        * The web is a written medium. There are reasons grammar has formed the way it has. Please, as a content provider, take pride in what you write and pride in how it is communicated in this medium.\t\n      * `<p>` must contain complete sentences (capitalized, subject-verb-predicate, period)\t\n        * Semantically, `<p>` is a paragraph, which means blocks of text. Thesis sentence, three or four supporting arguments, conclusion sentence. No, not every page is an essay, but the semantic difference between `<p>` and `<h_x_>` makes all the difference to your readers, and should play a part in SEO.\n      * Largish blocks of text (blocks of content, not buttons or headings) can use a Lorem text if final content is not available.\n        * Use a good Lorem text generator\n          * [http://www.lipsum.com/ ](http://www.lipsum.com/%20)\n          * [http://hipsteripsum.me/](http://hipsteripsum.me/)\n",
      "intro": ""
    },
    "/posts/2011/08/14/improved-allman-style/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2011-08-14T04:35:38.000Z",
        "layout": "post",
        "slug": "improved-allman-style",
        "title": "Improved Allman Style",
        "wordpress_id": 121,
        "categories": [
          "Coding Standards",
          "Technology"
        ],
        "tags": [
          "allman",
          "c",
          "c-style",
          "coding",
          "java",
          "php",
          "standards",
          "style guidelines"
        ],
        "path": "/posts/2011/08/14/improved-allman-style/index.md"
      },
      "body": "C-Based languages are those with “Brace” syntax describing blocks. Since the first C programming texts, there has been something of a holy war between zealots of different standards. Being an exemplar of the programming virtue of hubris, I have my entry. Allman-style bracing is the correct, best form for indenting block level code, provided a single addition: the opening brace MUST BE FOLLOWED BY AN INLINE COMMENT. The control statement might tell what the program is doing, but by always including a one-line verbal explanation of the block, other programmers know why the control statement is important. The following is an example mildly complex algorithm from the [jmtt analysis demo](http://davidsouther.com/projects/jmtt/tree.js).\n\n<!-- more -->\n\n```javascript\nthis.calculate = function(li)\n/**\n * Recursive function to calculate all the scores for a row in our analysis.\n * Gets the weight, grade, and cost from the children, then calcs the weighted\n * average for each middle node. Finally, hands off the data for a second\n * pass determining the target values.\n *\n * Params:\n *\tli\tHTMLLiNode tree row to calculate for.\n *\n * Returns:\n *\t[weight, grade, cost]\tDetails for the current row.\n */\n{\n\tvar grade, weight, cost, children;\n\tif(undefined === li)\n\t{\t//Calcing the entire analysis.\n\t\tchildren = tree.treetable(\"body\");\n\t\tweight = 100;\n\t}\n\telse\n\t{\t//Just doing one branch\n\t\tchildren = $(li).children(\"ul\").children(\"li\");\n\t\tweight = parseFloat($(li).children(\"span.weight:first\").html().replace(\"%\", \"\"));\n\t}\n\n\tif(children.length === 0)\n\t{\t//A leaf, floating on the winds...\n\t\tvar span, input;\n\t\tspan = $(li).children(\"span.grade\");\n\t\tinput = span.find(\"input\")[0];\n\t\tgrade = parseInt((input && input.value) || span.html());\n\n\t\tspan = $(li).children(\"span.cost\");\n\t\tinput = span.find(\"input\")[0];\n\t\tcost = parseInt((input && input.value) || span.html());\n\t}\n\telse\n\t{\t//Weighted average the children.\n\t\tgrade = 0; cost = 0;\n\t\tchildren.each(function(){\n\t\t\tvar calc = self.calculate(this);\n\t\t\tgrade += (calc[0] * calc[1]);\n\t\t\tcost += calc[2];\n\t\t});\n\t\tgrade /= 100;\n\n\t\tgrade = Math.rounder(grade);\n\n\t\t//Fill in the node.\n\t\t((li && $(li).children(\"span.grade\")) || grade_total).html(grade).addClass(\"aggregate\");\n\t\t((li && $(li).children(\"span.cost\")) || cost_total).html(cost).addClass(\"aggregate\");\n\t}\n\n\tif(undefined === li)\n\t{\t//At the head, so go back to calculate cost/value\n\t\treturn _calculate_value();\n\t}\n\telse\n\t{\t// Pass the aggregate values back up the call chain.\n\t\treturn [weight, grade, cost];\n\t}\n}\n```\n\n```javascript\n_decorate_cells: function(li)\n/**\n * Private method to get the row in line with the rest of the table by\n * attaching any remaining cells and setting all the cell styles.\n *\n * Params:\n *\tli\tHTMLLiNode with s to apply classes to. */ { var cells, columns; columns = this.options.columns; cells = $(li).children(this.options.cell_tag); while(cells.length < columns.count) { //Add enough cells to make up for any missing cells in the body that are in the header. $(this.options.cell_tag_html).insertAfter($(li).children(this.options.cell_tag+\":last\")); cells = $(li).children(this.options.cell_tag); } for(i=0; i\n```\n\n### More guidelines    \n    There are a few other guidelines I follow for consistently readable code.\n\n### Variable Names\n    \n    Variables must be reasonably named to indicate their purpose and contents. Very short, non-word variables should only be used as iterators in for() loops. Projects should choose either lower-case underscore compound variables or camel case compound variables. Once a decision has been made, it must stay consistent throughout the project. In general, if using a framework, try to use whatever format the framework uses. That said, multi-word variable names should be discouraged. It is better to refactor variable visibility so that words don’t clash in a scope than try to juggle buffered_text, buffered_word, and buffered_reader.\n\n\n\n\n#### INCORRECT\n\n\n```c\n$j = 'foo'; // single letter variables should only be used in for() loops\nStr; // contains uppercase letters\nbufferedText; // Could be shortened without losing semantic meaning\ngroupid; // multiple words, needs underscore separator or camel casing\n$name_of_last_city_used; // too long\n```\n\n\n#### CORRECT\n\n\n```c\nfor ($j = 0; $j < 10; $j++)\n$str\nbuffer\ngroup_id, groupID\n$last_city\n```\n\n### Commenting\n\nIn general, code should be commented prolifically. It not only helps describe the flow and intent of the code for less experienced programmers, but can prove invaluable when returning to your own code months down the line. Functions and classes must always have a DocBlock style comment. This includes private members. Sure, your users might only need the API, but your maintainers will really appreciate a comment saying the private _expand method implements a hacked LL(1) parser because the COTS LALR parser was too slow. DocBlock style comments preceding class and method declarations so they can be picked up by IDEs in all languages:\n\n```c\n    /**\n    * Super Class\n    *\n    * @package Package Name\n    * @subpackage Subpackage\n    * @category Category\n    * @author Author Name\n    * @link http://example.com\n    */\n    class SuperClass\n    \n    /**\n    * Encodes string for use in XML\n    *\n    * @access public\n    * @param string\n    * @return string\n    */\n    function xml_encode($str)\n```\n\nJavascript Exception: In Javascript, the DocBlock should be placed BETWEEN the function declaration and the function’s opening brace. This makes the comment a syntactic part of the function, and when a developer passes the function to console.log, the comment will be included in the output.\n\n```c\nvar xml_encode = function($str)\n    /**\n    * Encodes string for use in XML\n    *\n    * @access public\n    * @param string\n    * @return string\n    */\n    {\n```\n\n    Use single line comments within code, leaving a blank line between large comment blocks and code.\n\n```c\n    // break up the string by newlines\n    $parts = explode(\"\\n\", $str);\n    \n    // A longer comment that needs to give greater detail on what is\n    // occurring and why can use multiple single-line comments.  Try to\n    // keep the width reasonable, around 70 characters is the easiest to\n    // read.  Don't hesitate to link to permanent external resources\n    // that may provide greater detail:\n    //\n    // http://example.com/information_about_something/in_particular/\n    \n    $parts = $this->foo($parts);\n```\n\nAs stated in the Indent Style section, control structures should always have a one-line comment on why they are necessary.\n\n### Constants\n\n\n\n    \n    Constants follow the same guidelines as do variables, except constants should always be fully uppercase and use underscores for spaces.\n\n\n\n\n#### INCORRECT\n\n\n```c\nmyConstant // missing underscore separator and not fully uppercase\nN // no single-letter constants\nS_C_VER // not descriptive\n```\n\n\n#### CORRECT\n\n\n```c\nMY_CONSTANT\nNEWLINE\nSUPER_CLASS_VERSION\n```\n\n\n### TRUE, FALSE, NULL, UNDEFINED\n\n\n\n    \n    TRUE, FALSE, NULL, and similar keywords should always be either fully uppercase or undercase as the language allows. This is another “choose at the beginning of the project, then be consistent” rules. INCORRECT\n\n    ```c\n    if ($foo == true)\n    $bar = false;\n    function foo($bar = null)\n    ```\n\n    CORRECT\n\n    ```c\n    if (TRUE === $foo)\n    $bar = FALSE;\n    function foo($bar = NULL)\n    Logical Operators\n    ```\n\nUse of || is discouraged as its clarity on some output devices is low (looking like the number 11 for instance). AND is preferred over && . A space should always precede and follow !. INCORRECT\n\n```c\n    if ($foo || $bar)\n    if ($foo && $bar)  // okay but not recommended for common syntax highlighting applications\n    if (!$foo)\n    if (! is_array($foo))\n```\n\n    CORRECT\n\n```c\n    if ($foo OR $bar)\n    if ($foo AND $bar) // recommended\n    if ( ! $foo)\n    if ( ! is_array($foo))\n```\n    \n    \n### Comparing Return Values and Typecasting\n\nSome PHP functions return FALSE on failure, but may also have a valid return value of \"\" or 0, which would evaluate to FALSE in loose comparisons. Be explicit by comparing the variable type when using these return values in conditionals to ensure the return value is indeed what you expect, and not a value that has an equivalent loose-type evaluation. Use the same stringency in returning and checking your own variables. Always use === and !==. INCORRECT\n    [php]\n    // If 'foo' is at the beginning of the string, strpos will return a 0,\n    // resulting in this conditional evaluating as TRUE\n    if (strpos($str, 'foo') == FALSE) ;\n    \n    function build_string($str = \"\") {\n    if ($str == \"\") // uh-oh!  What if FALSE or the integer 0 is passed as an argument?\n    {\n    }\n    }\n    [/php]\n    CORRECT\n    [php]\n    if (strpos($str, 'foo') === FALSE);\n    \n    function build_string($str = \"\") {\n    if (\"\" ===  $str)\n    {\n    }\n    }\n    [/php]\n    See also information regarding typecasting, which can be quite useful. Typecasting has a slightly different effect which may be desirable. When casting a variable as a string, for instance, NULL and boolean FALSE variables become empty strings, 0 (and other numbers) become strings of digits, and boolean TRUE becomes “1”.\n\n\n\n\n#### Example\n\n\n[php]\n$str = (string) $str; // cast $str as a string\n[/php]\n\n\n### One File per Class\n\n\n\n    \n    Use separate files for each class, unless the classes are very closely related. An example of Design Delegates files that contains multiple classes is the Datagrid class file, which contains both the Datagrid class and the Datagrid Template classes.\n\n\n\n\n### Whitespace\n\n\n\n    \n    Use tabs for leading whitespace, not spaces. This may seem like a small thing, but using tabs instead of whitespace allows the developer looking at your code to have indentation at levels that they prefer and customize in whatever application they use. And as a side benefit, it results in (slightly) more compact files, storing one tab character versus, say, four space characters. Use regular spaces inside text for ascii art. The exception is the tab preceding a closing } in CSS declarations, and a tab between a single-line { and its comment in a block of C-style code.\n\n\n\n\n### Condition Tests\n\n\n\n    \n    Condition Tests should be var op test, to avoid assigning the test to the variable.  Short circuit logical operators should use AND, OR, and ! instead of &&, ||, and NOT. Liberal use of parenthesis to guarantee order of operations is needed (no more than one operation in an expression block). INCORRECT\n    [php]\n    if($var == 0);\n    if(term == strpos(haytack, ‘needle’);\n    [/php]\n    CORRECT\n    [php]\n    if(0 === $var);\n    if(strpos(haytack, ‘needle’) > -1);\n    [/php]\n    \n    \n    <h3>Bracket and Parenthetic Spacing</h3>\n    \n    \n    In general, parenthesis and brackets should not use any additional spaces. The exception is that a space should always follow PHP control structures that accept arguments with parenthesis (declare, do-while, elseif, for, foreach, if, switch, while), to help distinguish them from functions and increase readability. INCORRECT\n    [php]\n    $arr[ $foo ] = 'foo';\n    function foo ( $bar ) {\n    }\n    foreach( $query->result() as $row )\n    [/php]\n    CORRECT\n    [php]\n    $arr[$foo] = 'foo'; // no spaces around array keys\n    \n    // no spaces around parenthesis in function declarations\n    function foo($bar) {\n    }\n    foreach ($query->result() as $row) // single space following PHP control structures, but not in interior parenthesis\n    [/php]\n    \n    \n    <h3>Localized Text</h3>\n    \n    \n    Any text that is output in the control panel should use the translation function __. The __ function will be defined in as many languages as possible. Check the language specific documentation as needed. INCORRECT\n    ```c\n    return \"Invalid Selection\";\n    ```\n    CORRECT\n    ```c\n    return __('Invalid Selection');\n    ```\n    \n    \n    <h3>Private Methods and Variables</h3>\n    \n    \n    Methods and variables that are only accessed internally by your class, such as utility and helper functions that your public methods use for code abstraction, should be prefixed with an underscore. Use language constructs as appropriate to enforce visibility constraints.\n\n\n\n\n#### Example\n\n\n```c\n class Some_Class {\n public function convert_text() {\n }\n private function _convert_text() {\n }\n }\n```\n\n\n### One Statement Per Line\n\n\n\n    \n    Never combine statements on one line. Exception: Variable declaration and initialization, which can be one per type and initial value. In this case, variables should be listed in alphabetical order.\n\n\n\n\n#### INCORRECT\n\n\n[php]\n$foo = 'this'; $bar = 'that'; $bat = str_replace($foo, $bar, $bag);\n[/php]\n```c\nint a = 0;\nfloat z = 1.0f;\nint c = count = 0;\nfloat r = z;\n```\n\n\n#### CORRECT\n\n\n[php]\n$foo = 'this';\n$bar = 'that';\n$bat = str_replace($foo, $bar, $bag);\n[/php]\n```c\nint a = b = count = 0;\nint m = n = max = 10;\nfloat r = ratio = z = 1.0f;\n```\n",
      "intro": ""
    },
    "/posts/2011/08/15/unified-augmented-reality/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2011-08-15T05:49:18.000Z",
        "layout": "post",
        "slug": "unified-augmented-reality",
        "title": "Unified Augmented Reality",
        "wordpress_id": 150,
        "categories": [
          "Science",
          "Technology"
        ],
        "tags": [
          "augmented reality",
          "bionics",
          "science"
        ],
        "path": "/posts/2011/08/15/unified-augmented-reality/index.md"
      },
      "body": "A group I'm active on in Facebook posted a link to a comment on the [possibilities of LED contact lenses](http://www.elementalled.com/leducation/blog/innovative-technology/led-lights-make-augmented-vision-a-reality/). Unfortunately, the post's author barely scratches the surface of what's possible with the potential applications. Also, the author calls this \"Freaky.\" Not cool. For a unified approach to augmented reality, I want all the research resources of my desktop integrated into a complete hands-free environment. While this could just be fancy glasses and a bluetooth headset, I'm going to take freaky to the extreme, and only consider approaches that require surgery. Also, I'm going to try to stay in the realm of things I can sketch on how to make a technical possibility, and try to highlight everything I know is still science fiction. So, how can I make myself better with technology?\n\n<!-- more -->\n\n### Hearing\n\nThis one's actually pretty close to reality. Take current [invisible in ear canal hearing aids](http://en.wikipedia.org/wiki/Hearing_aid#Invisible_In_canal_hearing_aids_.28IIC.29), make them a bit smaller, and surgically implant them in a way replacing some cartilage of the exterior acoustic meatus and some of the mastoid process (requiring reattaching some muscles to this new device. No one ever said Science was easy.). Power could be provided by extending a flap of skin around a battery access point near the base of the aricula, or even as a gauge earing in the lobule. Necessary components would be the speaker, a the power, and a local minicomputer handling incoming audio. Also possible would be a small microphone in the area, for recording what you hear.\n\n\n### Speech\n\n\nReplace the third molar with a microphone. This will be a bit tricky, since speech isn't fully formed until it hits the lips, but I conjecture with appropriate software the intended audio signal could be reconstituted correctly. Power could come from wires run to to the aricula battery.\n\n\n### Vision\n\n\nThe hardest, but coolest. Here, I want to replace the entire lens system with a camera/projector combo. This way, we don't need to reverse engineer the operation of the retina and optic nerve. Instead, we take advantage of our (relatively better) understanding of light and light hitting the retina. Power and transmitting data I could see being... difficult. Possibly taking advantage of EM inductance by placing a dielectric between the eye and the eyelid? The camera would capture image, then get composited with whatever we need to display from the control system.\n\n\n### Command and Control\n\n\nThe coolest part I see of the camera/projector combo is the potential to virtually overlay a keyboard on any surface. Similar to [Celluon's Magic Cube](http://www.celluon.com/products/laserkey1_3.htm?sm=2_1), I could use my arm as the \"surface\" for a right-handed Dvorak keyboard, or sit down at an empty table and type by tapping on the table, the motion picked up and translated by the camera, then overlayed onto the projected image. Combined with a [verbal shell](http://davidsouther.com/2011/08/verbal-shell/), I see a lot of possibilities software-wise that could run on this platform. Say, adding a USB port in your arm, that the system accesses, and displays on your eye overlay using the same window manager as your OS.\n\nTransmitting data has two possibilities. First, equipping every piece with a short-range wireless device (you'd need about 10cm for the ear, mouth, and eye). Or, running wires everywhere (following the nervous system, probably). Power could come from batteries at strategic locations, but there's also the turbines from a Swiss team that [fit inside arteries](http://spectrum.ieee.org/biomedical/devices/swiss-scientists-design-a-turbine-to-fit-in-human-arteries). With the levels of miniaturization I've described, I would target the system to 100 milliwatts. That would be enough to power 100 hearing aids.\n\n\n### Is it possible?\n\n\nSure, these bionic mods are more sci-fi than sci-fact at this point in time. Still, I think these are reasonable goals I've laid out for a system. Honestly, I think with 5 years and a couple billion in dedicated funding, serious progress could be made on this project. The question, then, is how many people would want something like this... I would, but a lot might call it \"freaky.\"\n\n\n#### Disclaimer\n\n\nI am WAY out of my field of computer science on this one, and sadly do not work with these parts of the body in this way on a daily basis. If I've said anything incredibly wrong (or even subtly stupid) please let me know in the comments. I really do think this project is possible, and want to keep thinking about it for some time (like, until it's a reality).\n\n\n### PS.\n\n\nI didn't even start on things like potential muscle enhancements. I'm a much more cerebral guy, but all the mods from [Deus Ex](http://en.wikipedia.org/wiki/Deus_Ex)... I think are closer than those game makers though.\n",
      "intro": ""
    },
    "/posts/2011/08/19/bkvs-bash-keyvalue-store/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2011-08-19T08:30:49.000Z",
        "layout": "post",
        "slug": "bkvs-bash-keyvalue-store",
        "title": "bkvs - Bash Key/Value Store",
        "wordpress_id": 163,
        "categories": [
          "Technology"
        ],
        "tags": [
          "bash",
          "key value store",
          "kvs",
          "nosql"
        ],
        "path": "/posts/2011/08/19/bkvs-bash-keyvalue-store/index.md"
      },
      "body": "I like me my associative arrays and key/value stores. They're really really useful. I wanted one in bash, and tada,\n\n```bash\ndeclare -A aa\naa[hello]=world\naa[ab]=cd\n```\n\n<!-- more -->\n\nWell, I wanted something that could be used between sessions. Tada, the filesystem is a great key/value store.\n\nI wrote a wrapper for the set ADT get(key), set(key, value) and delete(key) to the file system. It's available at [http://code.google.com/p/bkvs/](http://code.google.com/p/bkvs/) and makes for some pretty nice loops.\n\n```bash\n# get bkvs ready (http://code.google.com/p/bkvs/)\nexport PATH=\"$PATH:/home/southerd/devel/southerd/bkvs\"\nexport BKVS_ROOTDIR=./bkvs\n\n# Get and verify list of drives.\nls /media/project_drives/*raw | sed 's#/media/project_drives/##' | sed 's/.raw//' | bkvs set drives\n#bkvs get drives | while read drive ; do echo $drive ; done\n\n# Save the raw partition table for each drive\nbkvs get drives | while read drive ; do fdisk -l /media/project_drives/${drive}.raw | bkvs set ${drive}/table ; done\nsed -i 's/bkvs history notes //' bkvs/6HD*/table # Somehow the * for boot got expanded to \"bkvs history notes\"\n\n# Get lists of the partition offsets\nroot=/media/project_drives/\nfor drive in $(bkvs get drives) ; do bkvs get $drive/table | egrep \"^$root$drive\" | sed \"s#$root##\" | awk '{print \" \" $1 \" \" $2 \" \" $3 \" \" $6}' | bkvs set $drive/offsets ; done\n\n# Build the timelog of the headers\n{ for drive in $(bkvs get drives) ; do bkvs get $drive/offsets | awk \"{print \\\"icat -i raw -o \\\" \\$2 \\\" $root$drive.raw 0 | bkvs set $drive/\\\" \\$1 \\\".head\\\"}\" ; done } >| icat_heads.sh\n{ for drive in $(bkvs get drives) ; do bkvs get $drive/offsets | fgrep NTFS | awk \"{print \\\"log2timeline -f mft -m \\\" \\$1 \\\" bkvs/$drive/\\\" \\$1 \\\".head | bkvs set $drive/\\\" \\$1 \\\".log\\\"}\" ; done } >| head_timelines.sh\nsh icat_heads.sh >icat_heads.log 2>icat_heads.log.error\nsh head_timelines.sh >head_timelines.log 2>head_timelines.log.error\n```\n",
      "intro": ""
    },
    "/posts/2011/08/20/fun-with-bash/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2011-08-20T21:31:56.000Z",
        "layout": "post",
        "slug": "fun-with-bash",
        "title": "Fun with Bash",
        "wordpress_id": 172,
        "categories": [
          "Technology"
        ],
        "tags": [
          "bash",
          "bkvs",
          "forensics",
          "history",
          "Loccard's Principle",
          "unix"
        ],
        "path": "/posts/2011/08/20/fun-with-bash/index.md"
      },
      "body": "I freakin love bash. The thing's amazing, with some ridiculous language constructs that even perl can't dream of. If the unix philosophy is \"one task, one tool,\" Bash's task is glue.\n\nI've been using it over the past week on a digital forensics case. This is a project that involves examining a dozen production hard disks for any artifacts of inappropriate or malicious use (hacking, malware, unauthorized websites, breach of data policy, etc etc). The disks I'm analyzing are about 120GB a piece, dual-boot between Windows XP and various linux distros. After some initial analysis, we have 3 data partitions per disk, and somewhere between 300 and 400 thousand artifacts per partition. That's over 10 million artifacts to collect and analyse, from 12 different physical devices. This is for a court case, so rules of evidence and expert witness rules apply- notes. Lots and lots of meticulous notes. Guess what? Bash makes it easy.\n\n<!-- more -->\n\nTo start off, I only actually had two physical devices to work from. Following consequences of [Locard's principle](http://en.wikipedia.org/wiki/Locard's_exchange_principle), the original devices were raw copied (`dd`ed) to a pair of aggregate drives. These aggregates then had a single file system with a handful of .raw files each. That's where we start from. Here are the tools I've added to my belt (and `.bashrc`).\n\n\n### bkvs\n\n\n[bkvs](http://davidsouther.com/2011/08/bkvs-bash-keyvalue-store/) is a little script I wrote that abstracts the file system into a key/value pair. It handles directory creation, file management, and generally keeps things from breaking. You'll see me using it several times, so it might help to read the man page, but generally, it supports `get(key`), `set(key, value)`, `add(key, value)` and `delete(key)`.\n\n\n### history -a\n\n\n[history](http://ss64.com/bash/history.html) can append the current session to a file. Better yet, it only prints the history that's happened since the last time it was written. This makes it really easy to play around with a few commands, get the syntax right, save the history to your notes, clean it up, and then move on with the next step.\n\n\n### Intermediate Scripts\n\n\nBecause of the similarity in naming conventions and the tasks I'm doing on each individual drive, I'll need to run the same command on several different partitions. xargs is built exactly for this. Or so it thinks. Actually, xargs is for running a single command inside a pipeline. I need to run several different pipelines, and building those pipes in xargs would be tricky, I think. Further, xargs could have a subtly different invocation each time it gets put in a pipe, and I don't know exactly what the command line expanded to. xargs also can't easily build a pipeline of Instead, I've started using intermediate shell scripts. In general, I'll have a loop or pipeline that has variables bound and delimited fields in the pipe, and use awk to construct the command line I'd want to run. Then, instead of executing it immediately, I wrap the entire looped pip in braces, and redirect that output to an intermediate script.\n\n```bash\n{\nfor drive in $(bkvs get drives)\ndo\nbkvs get $drive/offsets | fgrep NTFS | awk \"{print \\\"log2timeline -p -r -f winxp bkvs/$drive/\\\" \\$1 \\\" | bkvs add $drive/\\\" \\$1 \\\".timeline\\\"}\"\ndone\n} >| mount_timelines.sh\n```\n\nThis builds a nice script that looks very regular:\n\n```bash\nlog2timeline -p -r -f winxp bkvs/6HD1/6HD1.raw2 | bkvs add 6HD1/6HD1.raw2.timeline\nlog2timeline -p -r -f winxp bkvs/6HD2/6HD2.raw2 | bkvs add 6HD2/6HD2.raw2.timeline\nlog2timeline -p -r -f winxp bkvs/6HD2/6HD2.raw5 | bkvs add 6HD2/6HD2.raw5.timeline\nlog2timeline -p -r -f winxp bkvs/6HD3/6HD3.raw2 | bkvs add 6HD3/6HD3.raw2.timeline\nlog2timeline -p -r -f winxp bkvs/6HD4/6HD4.raw1 | bkvs add 6HD4/6HD4.raw1.timeline\nlog2timeline -p -r -f winxp bkvs/6HD5/6HD5.raw1 | bkvs add 6HD5/6HD5.raw1.timeline\nlog2timeline -p -r -f winxp bkvs/6HD5/6HD5.raw2 | bkvs add 6HD5/6HD5.raw2.timeline\nlog2timeline -p -r -f winxp bkvs/6HD6/6HD6.raw2 | bkvs add 6HD6/6HD6.raw2.timeline\nlog2timeline -p -r -f winxp bkvs/6HD7/6HD7.raw2 | bkvs add 6HD7/6HD7.raw2.timeline\nlog2timeline -p -r -f winxp bkvs/6HD8/6HD8.raw2 | bkvs add 6HD8/6HD8.raw2.timeline\n```\n\n### Paralyze\n\n\nWhat I actually mean is parallelize, but I always miss a syllable. I want to run this script now, but log2timeline takes a significant chunk of time. I'm a guy who's proud of his quad-core processor, and who's done his share of OpenMP and parallelization, so it'd be nice to have a way to get my load up around 3.5, instead of the measly 0.1 it usually sits at. I've added this handy little function to my bashrc.\n\n```bash\nalias ding='echo \"Done\" | mail davidsouther@gmail.com'\nfunction paralyze() {\n\tfile=$1\n\ttmp=\"$file._tmp\"\n\tcat \"$file\" | awk '{print \"{ \" $0 \"} &\"}' | sed 'n;n;s/&$//' | sed '$s/&$//' >| $tmp\n\tnice -n 10 sh $tmp >$file.log 2>$file.log.error\n\trm $tmp\n\tding\n}\n```\n\nIt takes a single parameter, a bash script in a similar format (one command per line). It adds an ampersand (&) to the end of every line (to background it), and then removes the & from every 3rd line. (Experimentation might show a better number, but I chose p-1 as an ideal of every core having 1 perfect, non-blocking process just running on its own, leaving a core for my desktop). Last it removes the last line's &, so the last line will always block until the end. This gets put in a tmp file, since each line is supposed to be completely independent from every other line. Finally, we run the tmp file as a shell script, niced down low so it doesn't start thrashing, and redirect stdout and stderr to some log files. When it's done, it cleans up, and emails me.\n\nThere are a couple issues. First, there's no guarantee that every third line will finish after the lines above it, or that the last line will also finish last. But, without writing some accounting mechanism to watch the current process list, it does a pretty damned good job of letting me run a lot of parallel tasks in the background, without having to monitor them by hand.\n\n\n### That's all for now\n\n\nThose are the four little things I've picked up on using over the past couple days. Again, the requirements are meticulous notetaking, and automation of repetitive tasks. These little helpers have made my life tremendously easier (in fact, possible) compared to sitting around typing each `fdisk -l` and `mount` out by hand.\n\n\n### Bonus\n\n\nFrom Andrew Niemantsverdreit: (as root)\n\n`strings /dev/mem | more`\n",
      "intro": ""
    },
    "/posts/2011/08/26/goal-oriented-behavior-2009-0/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2011-08-26T04:38:03.000Z",
        "layout": "post",
        "slug": "goal-oriented-behavior-2009-0",
        "title": "Goal Oriented Behavior - July 2009",
        "wordpress_id": 197,
        "categories": [
          "Philosophy"
        ],
        "tags": [
          "agent",
          "goab"
        ],
        "path": "/posts/2011/08/26/goal-oriented-behavior-2009-0/index.md"
      },
      "body": "_I stumbled across this while going through old emails. It was originally addressed to Austin Brown. I have not edited it since I found it, it is posted as is from July 2009._\n\nHomo Sapiens is, to it's knowledge, only unique in it's ability to make value judgments on it's actions in the world. Many other animals show knowledge of their environment and an ability to carry out tasks of relative complexity (including rather complex computer algorithms like A* pathfinding), but the ability to evaluate how a goal was completed remains solely in the realm of Human comprehension.\n\n<!-- more -->\n\nThis presents many questions, and many answers in generations paced have placed a special prominence on the human race. Throughout western history, humans have always been special, separate from animals, plants, and gods. The Christian influence is not alone in the middle ages in presenting our race as coming with special providence from on-high, with a transcendent imperative making them simply better than everything else (with even the distinctions of what makes a human rather loosely defined). It is interesting that the scientific revolution of the renaissance represents a desire of christians to understand God and His Creation, but that that path leads directly to one inevitable conclusion: humanity is at best a chance occurence in the cosmos, at worst, humanity is just one of billions of ordinary races throughout the universe to have achieved intelligence.\n\n<!-- more -->\n\nThe questions presented are questions that have been asked and answered, directly or indirectly, through nearly every medium of expression in our recorded history well into prehistorical tales passed to us. What is the meaning of life? Why are we here? How did that happen? The sheer multitude of answers, much less the subtleties in nearly identical answers, raises a question of it's own: Is there an answer? It must be assumed that these are the right questions- if they're not, the problem is then with the capacity for human understanding and comprehension. Were that the problem, then the answer would most certainly be beyond comprehension, and not worth pursuing.\n\nSince humans have lived successfully as a species for the past several million years, having an answer to this question is clearly not a prerequisite to intelligence in the theory of natural selection, so it must be that the pursuit of these answers is a journey to be undertaken in and of itself- an definitive answer will never come, but the milestones on the journey itself are well worth the time. Looking at the most influential people to live, the lists generally put similar names at the top: Jesus Christ, Siddhartha Guatama (The Buddha), the Prophet Mohammed, Isaac Newton, and Albert Einstein often make the cut. Religious leaders and scientists- no politicians.\n\nThese two categories each tell something specific. The first tell morals, the second tell facts. The two don't have to be mutually exclusive, but often are. The reasoning for this has already been lain- science has done tremendously well at showing there is no universal \"good\" and \"evil\"- from the standpoint of biology or sociology, the only good and evil are what helps an intelligent society function. That said, science in no way precludes the possibility of a moral structure. In order for a code of morals, or more broadly, for an ethical framework, there has to be some consideration of what makes a human.\n\nThe physiological answer is straightforward: eyes, ears, mouth, bilateral symmetry, arms, legs, lungs, heart, brain, etc. Add the clinical definition of brain-dead, and there's a person. The religious answer is much simpler: a person has a soul. Both these answers leave something to be desired, though. Julius Caesar and Jesus Christ are no longer people because they both died two millenia ago. Julius Caesar was not a person (by Dante's account) because he was not able to have a soul, or at least not a soul capable of accepting Jesus Christ as his lord and saviour. More importantly for today's technological society, neither is a decent definition for a primary key in a database.\n\nThe task of finding a unique definition that works for all aspects of academic pursuit in defining a human may be impossible. The United States Social Security system assigns a unique number to every person who receives Social Security benefits (that is, every US citizen and many foreigners who are able to claim benefits). This system, developed in the 1930s, is prone to many problems, the least of which being fraud. This is, then, not a good system- two (or many more) distinct human beings can be identified by the same number. There is a similar problem with passports, birth certificates, and even DNA sequences, fingerprints, and retinal scans. As fast as technology can find a new \"unique\" identifier, there is a technological way to circumvent that method of identification.\n\nIdentification of humans is, to be fair, only necessary in a society based on trust- which is every society. There is an implicit trust occurring every time two or more people engage in conversation- trust that the information conveyed is the information that is wanted, and that it is received as intended. Without this trust, communication would have no meaning as a medium for the exchange of ideas. This trust can of course be bent and broken in many ways, but it must be seen that as a whole, the concept of trust works. Solving the problem of identification is not the goal, but it is important as a springboard for many other questions, including one posed already: what makes a human?\n\nIn the Descartian view of mind-body duality, expressed in every mainstream religion, the soul and thoughts of a human are distinctly separate from the body of the person. If this is the case, then only our thoughts are important. If this is not that case, then the human simply ends at the skin. However, both views are simplistic, though the second seems to have more sway in modern (especially legal) thought. If the first answer is correct, then what is a thought, or the soul? There is no physiological evidence of a \"soul\" as separate from a body, so for the scientific mind the separation of thought must be the deciding factor. Neuroscience has a rough sketch of what makes a thought- electrochemical impulses focused in the cortex but effecting the rest of the body.\n\nIf thoughts are as simple as this biological view presents, then it should be possible, in theory, to re-create the physiological functioning of the nervous system in a working model different from the model provided by a creature's DNA. Where, then, does the \"person\" end, or begin? Many sci-fi authors have tackled this problem, to varying degrees. Most hold the view that sentience can indeed be emulated, though in every case there is a tremendous conflict between these \"artificial\" life forms and their \"organic\" or \"natural\" creators.\n\nThe question also works in the opposite direction, and is rather more pressing in the context of replacing parts of the human body with \"artificial\" or \"mechanical\" replacements. The case of amputees with specially designed running limbs allows these people, who have the full rights of any other human being, the ability to run much faster and easier\nthen their completely \"natural\" counterparts. These devices are of course not allowed in today's competitive events, but if they were, many world records would be shattered. Were they allowed, there would also be a population of athletes who deliberately amputate limbs in order to use these devices.\n\nIf that sounds preposterous, it is already happening. The issue of steroids and doping is a tremendous issue in many sports, most visibly the Olympics, the Tour de France, and US Major League Baseball. The subculture of body mutilation for artistic purposes is also an example of the field emerging as \"transhumanism\" - in that case, using the body as a canvas for expression of creativity. The entire field raises the fundamental question of what it means to be human, a much larger and more complex question that simply answering \"Homo sapien\". The issue grows larger when considering what technology will enable.\n\nAlready the Internet, and Wikipedia especially, has begun to shift the focus from \"Just In case\" knowledge to \"just in time\" knowledge. As computing technology gives people the ability to work faster, so to does every other technology increase the rate of growth of the body of human knowledge. This body of knowledge may be what makes humanity as a whole a special race, and worth doing everything possible to preserve it's continued existence.\n\nThe most interesting issue for transhumanism, however, lies in its intrinsic connection with technology and the pace of technological innovations. Assuming the concept behind Moore's Law and the \"Law of Accelerating Returns\" is correct, then the continued increase in the pace of technological development, as well as information processing capabilities, presents a future that, without preemptive consideration and considerable foresight, will be left to a moral, ethical, and philosophical view of human's existence that is only capable of being reactionary to the course of history (if it is not already).\n\nSuch a philosophical view of the world will have to attempt to answer the fundamental question of what it means to be human. The answer must be specific enough to be flexible long after the evolution of \"artificial intelligence\", any transhuman activities, and be applicable for potential contact with, if not applicable directly for, any extra-terrestrial contact. At the same time, it must be specific enough to provided a basis on which to build both an ethical code and a legal code of living. In short, the best theory will work for any intelligence.\n\nThis is probably impossible. It is, if not the holy grail of philosophical work, at very least a far enough goal to be pursuable from today's view. Of course, the reply is nothing is impossible, so it's pursuit alone will be beneficial to future endeavours.\n\nThe first task is, as stated, to define what it means to be \"human\", or more generally, \"intelligent\". There is no accepted or complete definition, but a good starting point is goal-oriented and capable of learning. This is a good starting point because it covers a wide variety of examples, and each example is well-ordered against other examples. That is, it is capable to measure capabilities to carry out goals of various complexities, as well as measure learning ability. The \"well\" part of \"well-ordered\" will be left to future psychologists with better tools. To the philosopher, however, the purpose isn't to grant the ability to define one specimen as better than another, but rather to start to recognize what others are capable of.\n\nWith the ordering of the intelligence of creatures comes both a hierarchy inherent in the biosphere, as well as a responsibility for higher animals, especially those with human-level faculty, to recognize the effects of their actions on their surroundings. It is in the capability of sentient beings to direct their actions to be, at very least, not detrimental to the environment around them. This is nearly a common sense survival argument- it is not easy, or all that possible, to survive in a post-apocolyptic world. Therefore, sentient creatures should ensure they take the best care of their environment as possible.\n\nWith preservation as a fundamental tenant for good living, the second goal is democracy, in the liberal sense that all beings are ensured a good quality of life. The criterion for quality of life, however, is much harder to measure. Many views today have similar tenants health, freedom, happiness. The first is directly measurable. The second is harder to measure empirically, but organizations such as Reporters without Borders have made great strides in providing such tools. The final question can only be answered by one person- the person the knowledge is needed from. There is no external measure for a person's happiness. It seems, then, to be very difficult to approach from a scientific view.\n\nThe difficulty lies not in the mechanics of thought, but the myriad of subtle varieties within thought, each leading to different conclusions about the \"known\" world. Every sentient being is working toward some goal. Most critters have simple goals, and probably don't realize they're working at a task- bees are just doing what bees do. More creative creatures, like humans, have much more complex goals, and often many goals, generally working at cross purposes both against themselves and especially against others. Even complex goals with many sub-goals will often have conflicts and cross-purposes before its completion.\n\nThe encounters of goals working at cross purposes (which is every encounter, even when the purpose is generally the same) is a conflict. Every time two or more sentient being interact, the resolution of that conflict has a tremendous influence on how each being will act in the future. What is truly amazing is that there is so little violence in conflict resolution. The general dislike of violence as a tool for conflict resolution is evidence better than any other for the evolution of complex societal structures in any social creature (that is, every creature). Looking at human history, it seems these social rules fall into one fundamental rule: don't hurt people, but if you have to, it's better to hurt people outside the tribe.\n\nThe desire to completely rid society of violence is probably another impossible task. In fact, it is probably very difficult to arbitrarily impose any specific sort of rule on a group of people, or even one person. It seems that rules must be accepted by each and every individual person of their own accord- even such extreme measures as those employed by Big Brother in Orwell's 1984 would not be perfect. People are finicky creatures, and the ability for abstract thought seems to have given humans the need for the freedom to exercise that thought. That freedom can only be given up willingly, and can be reclaimed at any time.\n\nWith the ability to decide whether an action is good or bad comes the imperative to use those faculties.\n",
      "intro": ""
    },
    "/posts/2011/08/27/php-stack-trace/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2011-08-27T02:57:57.000Z",
        "layout": "post",
        "slug": "php-stack-trace",
        "title": "PHP Stack Trace",
        "wordpress_id": 200,
        "categories": [
          "Technology"
        ],
        "tags": [
          "php",
          "stack trace"
        ],
        "path": "/posts/2011/08/27/php-stack-trace/index.md"
      },
      "body": "With the lack of an easy PHP debugger, it seems a lot of web developers think the best way to debug PHP is excessive print and log statements. I am one of those. I plod along with var_dumps and echos. I wanted a stack trace, and so I put this little guy together.\n\n<!-- more -->\n\n```php\n/**\n * Print a quick stack trace.\n */\npublic static function trace() {\n\tob_start();//Buffer output. Output buffers work on a stack, so this OB will be specific to our debug routine.\necho \"\\n\";\n\techo \"<div class=debug>\\n\";\n\techo \"\\t<div class=trace>\\n\";\n\n\t$trace = debug_backtrace();//Get a stack trace to this point. Includes the current frame so we know where Debug() was called.\n\tforeach($trace as $id => $frame)\n\t{\t//Let's pull the data for each frame.\n\t\tif(isset($frame['file']) AND !empty($scope) AND !stristr($frame['file'], $scope))\n\t\t{\t// Not enough data?\n\t\t\tcontinue;\n\t\t}\n\n\t\t$function = \"{$frame['function']}()\";\n\t\tif(isset($frame['class']))\n\t\t{\t//Grab the class\n\t\t\t$function = \"{$frame['class']}{$frame['type']}{$function}\";\n\t\t}\n\t\t$at = \" at unknown\";\n\t\tif(isset($frame['file']))\n\t\t{\t//The filename\n\t\t\t$at = \" at {$frame['file']}\";\n\t\t}\n\n\t\tif(isset($frame['line']))\n\t\t{\t//And the line number\n\t\t\t$at .= \"::{$frame['line']}\";\n\t\t}\n\n\t\techo \"\\t\\t<div class=frame>#{$id}: {$function}{$at}</div>\\n\";\n\t}\n\techo \"\\t</div>\\n\";//class=trace\n\n\techo \"</div>\\n\";//class=debug\n\treturn ob_get_clean();\n}\t//trace\n```\n\nI have seen DBG and xdebug, but have been dissuaded by their seeming complexity. If anyone has a good reference, please share it!\n",
      "intro": ""
    },
    "/posts/2011/08/31/bash-strcmp-builtin/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2011-08-31T14:46:24.000Z",
        "layout": "post",
        "slug": "bash-strcmp-builtin",
        "title": "Bash strcmp builtin",
        "wordpress_id": 204,
        "path": "/posts/2011/08/31/bash-strcmp-builtin/index.md"
      },
      "body": "I needed a way to lexicographically compare strings in a bash script. Unfortunately, test only test string equality. C's strcmp returns 0 if two strings are equal, or the index of where the strings differ (positive if the character is greater in the first string, negative if the character at that position is greater in the second string). For my purposes, I only needed to know which one was greater, not where it was greater at. I whipped up a quick version of the program in straight C, but immediately had problems with loading times being drastically heavier than computation times. This seemed like the perfect case for a bash loadable builtin. I hadn't worked with bash builtins before, but [bash cookbook](http://oreilly.com/catalog/9780596526788)'s recipe 16.15 is a guide on loadable builtins. This is one place where preparation is the larger part of luck. With that, here's a quick walkthrough of the code and compile process.\n\n<!-- more -->\n\nStart by donwloading and extracting the bash [source](http://ftp.gnu.org/gnu/bash/) ([latest is 4.2](http://ftp.gnu.org/gnu/bash/bash-4.2.tar.gz)). Extract the tarball. We are going to be working in a small part of the bash source tree, in the examples/loadables/ folder. cd there, then run the following commands:\n\n```bash\ncp template.c strcmp.c\nsed -i 's/template/strcmp/g' strcmp.c\n```\n\nBefore we run configure, we need to add strcmp to Makefile.in\n\n```\n--- a/examples/loadables/Makefile.in\t2009-01-04 12:32:27.000000000 -0700\n+++ b/examples/loadables/Makefile.in\t2011-08-31 08:39:01.707126956 -0600\n@@ -85,7 +85,7 @@\n\n ALLPROG = print truefalse sleep pushd finfo logname basename dirname \\\n \t  tty pathchk tee head mkdir rmdir printenv id whoami \\\n-\t  uname sync push ln unlink cut realpath getconf strftime mypid\n+\t  uname sync push ln unlink cut realpath getconf strftime mypid strcmp\n OTHERPROG = necho hello cat\n\n all:\t$(SHOBJ_STATUS)\n@@ -191,6 +191,9 @@\n mypid:\tmypid.o\n \t$(SHOBJ_LD) $(SHOBJ_LDFLAGS) $(SHOBJ_XLDFLAGS) -o $@ mypid.o $(SHOBJ_LIBS)\n\n+strcmp:\tstrcmp.o\n+\t$(SHOBJ_LD) $(SHOBJ_LDFLAGS) $(SHOBJ_XLDFLAGS) -o $@ strcmp.o $(SHOBJ_LIBS)\n+\n # pushd is a special case.  We use the same source that the builtin version\n # uses, with special compilation options.\n #\n@@ -242,3 +245,4 @@\n realpath.o: realpath.c\n strftime.o: strftime.c\n mypid.o: mypid.c\n+strcmp.o: strcmp.c\n```\n\nFirst, take a moment to look at the bare strcmp.c - it has a lot of good stuff in it. That said, we're going to get rid of most of it.\n\n```c\n#include <config.h>\n#include <stdio.h>\n#include <string.h>\n\n#include \"builtins.h\"\n#include \"shell.h\"\n\n#define EXIT_GREATER 1\n#define EXIT_EQUAL 0\n#define EXIT_LESS 2\n\nstrcmp_builtin (list)\nWORD_LIST *list;\n{\n\tchar **v;\n\tint c, rval;\n\n\tv = (char**)make_builtin_argv(list, &c);\n\n\tif(c < 3)\n\t\treturn (EX_USAGE);\n\n\tint q = strcmp(v[1], v[2]);\n#ifdef DEBUG\n\tprintf(\"q is %d\\n\", q);\n#endif\n\tif(q > 0)\n\t\trval = EXIT_GREATER;\n\telse if (q < 0)\n\t\trval = EXIT_LESS;\n\telse\n\t\trval = EXIT_EQUAL;\n\n\treturn (rval);\n}\n\nchar *strcmp_doc[] = {\n\t\"strcmp compares two strings lexicographically. It returns\",\n\t\"0 if the strings are equal, 1 if the first string is greater\",\n\t\"2 if the second string is greater.\",\n\t(char *)NULL\n};\n\nstruct builtin strcmp_struct = {\n\t\"strcmp\", /* builtin name */\n\tstrcmp_builtin, /* function implementing the builtin */\n\tBUILTIN_ENABLED, /* initial flags for builtin */\n\tstrcmp_doc, /* array of long documentation strings. */\n\t\"strcmp 'string 1' 'string 2'\", /* usage synopsis; becomes short_doc */\n\t0 /* reserved for internal use */\n};\n```\n\nThere is one flag we might use, -DDEBUG to print debug info. Otherwise, we define our three exit statuses. Every builtin takes a WORD_LIST* as its arguments. I want a regular old argv array. Bash handily includes the make_builtin_argv for just that purpose. Now, argv[0] has the builtin name, and the rest of argv has the args. Make sure we have 3 args, run the strcmp, and set the appropriate return code. The rest is the support that bash needs to load everything.\n\nAssuming the Makefile.in was edited correctly, cd to the root of the bash source tree and run ./configure. Then, cd back to examples/loadables, and run the following session:\n\n```bash\n$ rm strcmp{,.o} ; make strcmp\ngcc -fPIC -DHAVE_CONFIG_H -DSHELL  -g -O2 -I. -I.. -I../.. -I../../lib -I../../builtins -I../../include -I/home/southerd/devel/random/bash-4.2 -I/home/southerd/devel/random/bash-4.2/lib -I/home/southerd/devel/random/bash-4.2/builtins  -c -o strcmp.o strcmp.c\ngcc -shared -Wl,-soname,strcmp  -L./lib/termcap  -o strcmp strcmp.o \n$ enable -f ./strcmp strcmp\n$ strcmp hi ho ; echo $?\n2\n$ strcmp hi ha ; echo $?\n1\n$ strcmp hi hi ; echo $?\n0\n```\n\nIf you didn't get any errors, you're a-ok! That's all there is to writing a bash builtin. Now, the shell is even more powerful!\n",
      "intro": ""
    },
    "/posts/2011/08/31/troubleshooting-gcc/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2011-08-31T16:13:58.000Z",
        "layout": "post",
        "slug": "troubleshooting-gcc",
        "title": "Troubleshooting GCC",
        "wordpress_id": 208,
        "categories": [
          "Technology"
        ],
        "tags": [
          "bash",
          "builtin",
          "c",
          "gcc"
        ],
        "path": "/posts/2011/08/31/troubleshooting-gcc/index.md"
      },
      "body": "As I was working on my [strcmp bash builtin](http://davidsouther.com/2011/08/bash-strcmp-builtin/), I ran into a few issues with GCC. They should have been obvious fixes, but it seems I needed a lesson in troubleshooting GCC. I posted a question and follow up on [Stack Overflow](http://stackoverflow.com/questions/7252550/loadable-bash-builtin).\n"
    },
    "/posts/2011/09/01/interview_with_a_conspiracy_theorist/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2011-09-01T03:27:41.000Z",
        "layout": "post",
        "slug": "interview_with_a_conspiracy_theorist",
        "title": "Interview with a Conspiracy Theorist",
        "wordpress_id": 213,
        "categories": [
          "Humor",
          "Politics"
        ],
        "tags": [
          "conspiracy theory",
          "imf",
          "irs"
        ],
        "path": "/posts/2011/09/01/interview_with_a_conspiracy_theorist/index.md"
      },
      "body": "What follows is a conversation I had with a conspiracy theorist on Facebook today.\n\n**Jen Gross**\nseriously.\n[ Tell Eric Cantor: Release the hostages and stop blocking funds for urgently needed disaster relief](http://act.credoaction.com)\nIt's outrageous to take advantage of the urgent needs of hurricane survivors in order to cut Medicare, Medicaid & Social Security. But that's what Eric Cantor is doing by refusing to allocate money to disaster relief unless Congress first offsets that money with cuts to vital government programs.\n\n**Josh Carey** Why do we only worry about these little issues ?\n\n**Jen Gross** because lots of people are flooded out of their homes and dealing w/ some pretty heavy damage. meanwhile eric cantor is putting up red tape, preventing the federal government from taking decisive action to help real people.\n\n**Josh Carey** My point is that this happens everyday in third world countries ! Poverty , war , disease and we do nothing ! We are taxed to death illegally and all that money goes to shit ! We could change this world so this stuff doesn't happen ! We must first change the system !\n\n<!-- more -->\n\n**David Souther** And how, exactly, do you propose to do that, @Josh Carey?\n\n**Josh Carey** Very simple !Stop supporting the failed system, stop giving them power ! A revolution if u will , they happen all the time throughout history to better the people :)\n\n**David Souther** That doesn't sound simple at all. First, what are the broken systems? Second, how are they broken? How does the current popular movements in the Arab Spring effect your rabblerousing revolutionarianism?\n\n**Josh Carey** ‎@ David ! I'm at work , let me get home and I will elaborate!\n\n**David Souther** Sure, I look forward to reading what you have.\n\n**Josh Carey** ‎@ David, I'll give u 2 examples of this broken system as u call it . First lets start with the IRS. The IRS has been an illegal system since its unlawful inception in the early 1900's. It is nothing more than a criminal organization. If you do not know this story, you should. Second how about the Federal Reserve. In 1913 the Federal Reserve Act was fraudulently pushed through Congress. In the united States we have, in effect, two governments....We have the duly constituted Government....Then we have an independent, uncontrolled and uncoordinated government in the Federal Reserve System, operating the money powers which are reserved to Congress by the Constitution. Unelected people run this planet, the government is a front for the Inertnational Bankers ! The world is not as it seems, it is how it is presented to us . As for the uprising in the arab world ! I'm not sure, I don't care to comment .\n\n**David Souther** Last I checked, the IRS was started with the position of the Commissioner of Internal Revenue under Lincoln in 1862. That agency was renamed in the 1950s as the Internal Revenue Service. The commissioner and chief counsel are appointed by the President with the advice and consent of the Senate. The event I think you're referring to in the \"early 1900s\" would be the 16th amendment to the constitution in 1916 authorizing an income tax. Now, I'm not a JD, but I do believe that there is no higher law in this nation than the constitution. Actually, I don't need to be a JD for that- the document spends most of Article 6 saying just that.\n\nThe Federal Reserve was founded in 1913, and does not, in fact, have oversight by the executive branch. However, the Fed is directly responsibly to congress, and thus does have indirect oversight by the people. I will use my \"I am not a JD\" line again and say, while not studied in this area of constitutional law, it seems the first 3 enumerated powers of congress in Article 1 Section 8 speak precisely to this issue of finding some mechanism to regulate the monetary proceedings of this nation. Whether the fed is the best such mechanism would, I think, be a good debate, but calling its passage fraudulent, while then stating it is anti-constitutional, seems a bit of a stretch.\n\n**Josh Carey** Not only is there no law that requires most Americans to file an individual tax return, but the Internal Revenue Service (IRS) wasn't even created by an act of Congress! As for the federal Reserve, Woodrow Wilson put it best ! \"I am a most unhappy man. I have unwittingly ruined my country. A great industrial nation is controlled by its system of credit. Our system of credit is concentrated. The growth of the nation, therefore, and all our activities are in the hands of a few men. We have come to be one of the worst ruled, one of the most completely controlled and dominated Governments in the civilized world -- no longer a Government by free opinion, no longer a Government by conviction and the vote of the majority, but a Government by the opinion and duress of a small group of dominant men. \"\n\n**David Souther** Credit is an interesting beast, but by no means illegal. I'm going to need more than the words of a cranky old President to convince me the entire system is illegal.\n\nAs for the founding of the IRS:\nThe Revenue Act of 1862\nInternal Revenue Service Restructuring and Reform Act of 1998\n\nStill not a lawyer, but [25 U.S.C. § 6012](http://www.law.cornell.edu/uscode/html/uscode26/usc_sec_26_00006012----000-.html) Persons required to make returns of income looks like a few laws requiring most Americans to file tax returns.\n\n**Josh Carey** The IRS is not a U.S. Government Agency. It is an Agency of the IMF. The IMF is an Agency of the UN.\n\n**David Souther** ‎..............\n\nWhat the FUCK!? Ok, I was playing along, but now you're just going batshit crazy. Or trolling. Please, tell me you're trolling, and not serious?\n\n**Josh Carey** I'm serious ! google it !\n\n**David Souther** No. I will let you post links to that particular ball of mental fuck-upedness.\n\n**Josh Carey** It's not some giant seceret , Ron Paul talks about it !\n\n**Josh Carey** [http://truth11.com/2011/02/02/thirty-little-known-facts-about-america/](http://truth11.com/2011/02/02/thirty-little-known-facts-about-america/)\n\n**David Souther** I... buh... I don't even know what to say to that crockery...\nOk, I'll choose a couple of the easier ones, and then let you move back in with... whatever it is you keep yourself crazy with. (If there were a God, he would reveal himself in this moment by having you tell me you're just joking with all this. On the other hand, at least I'm getting good reading out of it. The laws, not you or your fellow... whatever the hells you are.)\n\n\"5. The U.S. does not have any employees because there is no longer a United States. No more reorganizations. After 200 years of bankruptcy it is finally over. [Executive Order 12803]( http://waterindustry.org/12803.htm)\"\n\nSection 1. Definitions. For purposes of this order: (a) Privatization means the disposition or transfer of an infrastructure asset, such as by sale or by long-term lease, from a State or local government to a private party.\n\n‎\"Sec. 3. Privatization initiative. To the extent permitted by law, the head of each executive department and agency shall undertake the following actions: (a) Review those procedures affecting the management and disposition of federally financed infrastructure\"\n\nEtc. Generally, this XO calls for privatizing *SOME* infrastructure (roads, bridges, trains, electrical lines, etc). Hardly, \"No longer a united states\"\n\n‎\"1. The IRS is NOT a U.S. Government Agency. It is an Agency of the IMF.\"\n\nI can't find CV-93-405E-EJE U.S.D.C.I.\n\nPublic Law 94-564 provides a mechanism for Bretton Woods system, an international monetary treaty, but no indication of handing the IRS over to the IMF.\n\nPublic Law 102-391 is an appropriations law for foreign financing. There is a large section stating that the US shall have a representative at the IMF. It does not mean the IRS is an agent of the IMF.\n\nFuck it, I'm done. Go... go be crazy. I'm done.\n\n**Josh Carey** International Bankers founded the UN! The same that privately own the Federal reserve! They own all the centeral banks of the countries of this world with the exception of a few !\n\n**Josh Carey** This is why we get no where in this world :( just blow it off!\n\n**David Souther** Yes, and 9/11 was a missile planted by Cheney, the moon landing happened in a roswell sound stage, the middle ages never actually happened, and you forgot, those UN bankers are actually dinosaurs.\n\n**Josh Carey** Well I thought we were having a mature conversation, obviously not.\n\n**David Souther** No, we stopped having a mature conversation when you spouted the IRS is part of the IMF conspiracy.\n\n**Josh Carey** it's not a conspiracy lol\n\n**David Souther** Yes, and Rick Santorum is not a bigot.\n\n‎\"A conspiracy theory is a belief which explains an event as the result of a secret plot by exceptionally powerful and cunning conspirators to achieve a malevolent end.\" How is what you've been presenting not a conspiracy theory?\n\n**Josh Carey** This world is run in secret by shadow governments! You might want to look into \"human farming\" . Maybe this may help u understand the world better !\n\n[http://www.thelawthatneverwas.com/](http://www.thelawthatneverwas.com/)\n\n**David Souther** Fuck it, sure, here's another link.\n[http://docs.law.gwu.edu/facweb/jsiegel/Personal/taxes/IRSrefuses.htm#show](http://docs.law.gwu.edu/facweb/jsiegel/Personal/taxes/IRSrefuses.htm#show)\n\n**Josh Carey** Why are people beating the IRS law then ?\n\n**David Souther** Citation, please. Also, define \"beating\"\n\n**Josh Carey** Have u even looked into the cases? Do you think that 3/4 of the states would say income tax is ok ?\n\n**David Souther** Please, PLEASE, stop crossing your arguments. It's worse than the Ghostbusters' proton streams.\n\nYou link to Bill Benson's site. He links to no corroborating evidence, just \"Buy my book!\" A quick google search for \"Bill Benson\" has [http://www.quatloos.com/bill_benson_debunked.htm](http://www.quatloos.com/bill_benson_debunked.htm) as the second hit. The 3rd link is in support, 4th and 5th in opp, and the 6, about a Canadian hockey player. I can't find links to the actual court case Benson bitches about.\n\nNow, back to two questions ago. What do you mean by \"Beating\" the IRS? Neither Benson, nor those using his arguments, seem to be \"Beating\" the IRS. They are soundly defeated in court.\n\n**Josh Carey** ok! you're offically brainwashed. Popular public opinion does not mean it's a fact . later !\\\n\n**David Souther** Try using the Benson argument in court. See how far you get.\n\n**Josh Carey** Try keeping a open mind and see how much u learn better yet !\n\n**David Souther** Ok, let's back up a ways. At the beginning of this discussion, you state we are \"taxed to death\" and complain that we could be doing something to help third-world countries. You imply a revolution of some form is what we need. Let us, for the sake of me \"keeping an open mind\" assume, purely for the sake of argument, the IRS is illegal/the IMF/etc. How would you propose such a revolution occur?\n\n**Josh Carey** first we have to sway public opinion I guess ! People dub it \"awakening \".\n\n**David Souther** Ok. How will you do that? And what would you do then?\n\n**Josh Carey** I think it eventually unfolds, I can't say what will happen! some people think we become more intune with the universe in a holistic sense! Much knownledge the government has hidden from us in order to keep us productive and them in control I believe !\n\n**David Souther** So... you don't actually have anything pragmatically constructive to add to the conversation?\n\n**Josh Carey** A shift is taking place, we're becoming aware ! don't get me started on UFO's\n\n**David Souther** No, you're right. Please, don't start on UFOs. You've shed enough crazy tears for the day.\n\n**Josh Carey** thats the problem why more people not speak out ! they ridicule others! I don't care anymore becasuse i know as do many other people that this life need to be seen with a open mind ! it's amazing what passes for adulthood in this world !\n\n**David Souther** It's also amazing what passes as acceptable typing skills in this world.\n\n**Josh Carey** It's not acceptable to question life, this is not in accordance with popular public opinion ! I seek a better world at my very heart, if that's wrong then I don't wanna be right !\n\n**David Souther** I believe you seek that better wold in your heart. At your heart would imply a proximity precariously close to the metaphorical world revolving around you. Also, what's with the spaces before the exclamation marks? It adds yet another difficulty to reading what you write.\n\n**Josh Carey** Maybe u could stay focused on the issues instead of grammar ?\n\n**David Souther** Dude, you're long past talking about issues. You have discredited yourself in so many ways, it's kinda... whatever. Yes, questioning the world is a good thing. That said, presenting answers that are factually wrong has moved long past questioning and into lala land.\n\n**Josh Carey** well I'm sorry u feel that way ! so foreign it must be for you. I guess when I was your age I thought much the same way you do.\n\n**David Souther** What way do I feel? I've never been psychoanalyzed over the internet by a conspiracy theorist before!\n\n**Josh Carey** lol very cute ! good night !\n\n**David Souther** Night. Sweet dreams! I hope the aliens don't anal probe you!\n",
      "intro": ""
    },
    "/posts/2011/11/06/jquery-icons/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2011-11-06T18:06:26.000Z",
        "layout": "post",
        "slug": "jquery-icons",
        "title": "jQuery Icons",
        "wordpress_id": 243,
        "categories": [
          "Technology"
        ],
        "tags": [
          "icons",
          "jquery",
          "jquery ui",
          "jquery ui icon"
        ],
        "path": "/posts/2011/11/06/jquery-icons/index.md"
      },
      "body": "I'm playing around with jQuery UI themes. I need to get icon packs, and it's a long process to set the colors in themeroller, download the entire theme, extract the icons from the zip file, and put them in the site. wget to the rescue.\n\n```bash\nCOLOR=\"000000\"\nwget -O \"ui-icons_${COLOR}_256x240.png\" \"http://jqueryui.com/themeroller/images/?new=${COLOR}&w=256&h=240&f=png&fltr[]=rcd|256&fltr[]=mask|icons/icons.png\"\n```\n"
    },
    "/posts/2011/11/08/jquery-ui-glight/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2011-11-08T16:10:13.000Z",
        "layout": "post",
        "slug": "jquery-ui-glight",
        "title": "jQuery UI glight",
        "wordpress_id": 250,
        "categories": [
          "Technology"
        ],
        "tags": [
          "glight",
          "jquery",
          "jquery ui",
          "jquery ui theme",
          "theme"
        ],
        "path": "/posts/2011/11/08/jquery-ui-glight/index.md"
      },
      "body": "I've wanted a different theme than most of what jQuery UI provides for some time. I don't like the overly rounded corners, the glass effects, and egregious whitespace. I have really liked the recent Light themes Google has been working on, as well as the Wordpress Admin theme. I had some time over the weekend, and migrated most of the big pieces of the Google Light theme to jQuery UI. The code is available at [http://code.google.com/p/jquery-ui-glight/](http://davidsouther.com/2011/11/jquery-ui-glight/) with a standalone demo [http://davidsouther.com/projects/glight/jquery-ui.html](http://davidsouther.com/projects/glight/jquery-ui.html) (though this isn't on a continuous integration setup, so it might lag a bit behind the code). The demo is iframed below.\n"
    },
    "/posts/2011/11/14/skyrim-alchemy/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2011-11-14T19:16:53.000Z",
        "layout": "post",
        "slug": "skyrim-alchemy",
        "title": "Skyrim Alchemy",
        "wordpress_id": 258,
        "categories": [
          "Technology"
        ],
        "path": "/posts/2011/11/14/skyrim-alchemy/index.md"
      },
      "body": "Skyrim is the shit. The game is friggin amazing. Crafting alone is a worthwhile pursuit- go mine ore, smelt ore, hunt animals, tan hides, build weapons and armor, study enchantments, and enchant weapons and armor, improve enchanted weapons. Full cycle, and when you're done, you have exactly the gear *you* want. Alchemy? Please, I'll make my own potions. How do I know what ingredients do? Eat them, of course. Or, use this handy tool.\n"
    },
    "/posts/2011/12/20/leap/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2011-12-20T19:57:11.000Z",
        "layout": "post",
        "slug": "leap",
        "title": "Leap!",
        "wordpress_id": 261,
        "categories": [
          "Humor"
        ],
        "path": "/posts/2011/12/20/leap/index.md"
      },
      "body": "![](http://icanhascheezburger.files.wordpress.com/2011/12/gif.gif)\n\nThis is what I think of [Kierkegaard's](http://en.wikipedia.org/wiki/S%C3%B8ren_Kierkegaard) [Leap of Faith](http://en.wikipedia.org/wiki/Leap_of_faith)\n"
    },
    "/posts/2011/12/24/javascript-convert-string-to-number/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2011-12-24T19:21:14.000Z",
        "layout": "post",
        "slug": "javascript-convert-string-to-number",
        "title": "Javascript convert string to number",
        "wordpress_id": 266,
        "categories": [
          "Technology"
        ],
        "path": "/posts/2011/12/24/javascript-convert-string-to-number/index.md"
      },
      "body": "Most javascript guides recommend the generally standard `parseInt` and `parseFloat` methods to convert from a string to a number. Multiplying by 1 works as well, eg `1 * \"54\"`\n"
    },
    "/posts/2012/01/11/dont-blink/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2012-01-11T19:35:52.000Z",
        "layout": "post",
        "slug": "dont-blink",
        "title": "Don't Blink!",
        "wordpress_id": 271,
        "categories": [
          "Technology"
        ],
        "path": "/posts/2012/01/11/dont-blink/index.md"
      },
      "body": "Since `<blink>` and `text-decoration: blink;` don't work in Webkit or IE9...\n\n```css\n.invisible {\n    visibility: hidden;    }\n```\n\n```javascript\n$.fn.blink = function(){\n    setInterval($.proxy(function() {\n        this.each(function() {\n            $(this).toggleClass('invisible');\n        });\n    }, this), 500);\n};\n```\n```javascript\n$('a').blink();\n```\n"
    },
    "/posts/2012/02/22/jquery-ui-accordionnext/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2012-02-22T20:24:19.000Z",
        "layout": "post",
        "slug": "jquery-ui-accordionnext",
        "title": "jQuery UI: Accordion::next()",
        "wordpress_id": 280,
        "categories": [
          "Technology"
        ],
        "tags": [
          "accordion",
          "jquery",
          "jquery ui"
        ],
        "path": "/posts/2012/02/22/jquery-ui-accordionnext/index.md"
      },
      "body": "I needed a \"next\" function to cycle between accordion panels in jQuery. The relevant [Stack Overflow question](http://stackoverflow.com/questions/1418202/jquery-accordion-next-and-previous-wizard-how-to-get-previous-and-next-section/) is a couple years old... :(\n\n<!-- more -->\n\n```javascript\n$.extend($.ui.accordion.prototype, {\n    next: function(){\n        var index = this.option('active') || 0,\n            next = index + 1,\n        nodes = $(this.element).children('h3').length;\n        if(next <= nodes && this.option('loopOnNext') === true) {\n            next = 0;\n        }\n\n        return this.activate(next);\n    }\n});\n```\n",
      "intro": ""
    },
    "/posts/2012/02/24/jquery-the-best-parts/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2012-02-24T21:46:04.000Z",
        "layout": "post",
        "slug": "jquery-the-best-parts",
        "title": "jQuery: The Best Parts",
        "wordpress_id": 288,
        "categories": [
          "Technology"
        ],
        "path": "/posts/2012/02/24/jquery-the-best-parts/index.md"
      },
      "body": "jQuery is the javascript library I've come to know and love. It just makes web development easy. I had an opportunity to give a presentation outlining the best features of jQuery to the company I work for, and it went over quite well. The audience was a technical audience of java-turned-web developers who have predominantly seen Dojo and Ext, but are still on the whole more comfortable with the pure Java technologies. The full presentation is [available online](http://davidsouther.github.com/jQuery-Best-Parts-presentation/), and the [code is on github](https://github.com/DavidSouther/jQuery-Best-Parts-presentation). There will be a pop-up the first time you visit the page to show the speaker notes. This is the transcript I presented from, and has the full descriptions of the code examples. You will want to use chrome to view the presentation, but fallback mode works for other browsers.\n"
    },
    "/posts/2012/03/19/so-close/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2012-03-19T18:08:03.000Z",
        "layout": "post",
        "slug": "so-close",
        "title": "So close!",
        "wordpress_id": 315,
        "categories": [
          "Humor"
        ],
        "path": "/posts/2012/03/19/so-close/index.md"
      },
      "body": "![So close!](http://i.minus.com/ibwsWyQ4cuk0rf.gif)\n"
    },
    "/posts/2012/03/20/mass-effect-3-how-it-could-have-ended/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2012-03-20T18:03:01.000Z",
        "layout": "post",
        "slug": "mass-effect-3-how-it-could-have-ended",
        "title": "Mass Effect 3: How It Could Have Ended",
        "wordpress_id": 317,
        "categories": [
          "Technology"
        ],
        "tags": [
          "Endings",
          "HICHE",
          "Mass Effect 3",
          "ME3"
        ],
        "path": "/posts/2012/03/20/mass-effect-3-how-it-could-have-ended/index.md"
      },
      "body": "I've played through Mass Effect 3 three times now, and I will play through a couple more. The ending, by which I mean the last 10 minutes, is atrocious, as documented many places. Now, most of these inconsistencies are not huge issues in and of themselves, but taken together have a very negative impact on the experience as a whole. Even then, for all those weaknesses leading up to the (anti)climactic final decision of the series, the ending material is mostly forgivable. What cannot be forgiven are the broken promises Casey Hudson and the Bioware team have been making since [before ME2 was released.](http://au.xbox360.ign.com/articles/105/1055366p2.html) \"[T]ake all of the things you've done in Mass Effect 1 and Mass Effect 2 and then just let it go. Let it diverge into wildly different conclusions.\" And yet, I have had the exact same ending in three different playthroughs, across the reputation spectrum, a range of Military Strength, with wildly different decisions in ME1 and 2. The only difference? Red, Blue, or Green explosions. Why are fans let down? Bioware and Casey Hudson lied to us. Even worse than lying to us, it would not have been difficult to make the game wildly divergent, using the same assets already in the game, and minor tweaks in mechanics. Here's how.\n\n<!-- more -->\n\n## Side Missions\n\n\nThe artifact gathering missions are presented very poorly. I'm more than willing to suspend disbelief as to why Shep will run around [doing chores](http://penny-arcade.com/comic/2012/03/07) for everyone in the middle of the war. The dialog overheard when getting these quests is top-notch. I really do understand why a doctor needs samples of a Cerberus poison to help a Turian general. I'm more than happy to bring that sample back to the Citadel after Shep happens across it in a Cerberus base, and the war assets are really nice. What I am not happy about is that I have no idea where in the Hades Nexus this Obelisk of Karza is, because I happened to miss the bit of background noise as I was going shopping on the Presidium! In and of itself, not a big deal- I'll just go back and listen to him again, right? Since every quest giver in the history of RPGs is more than happy to repeat the same line about their missing relic over and over, right? Not this time! Would it have been terribly difficult to put an interaction circle over quest givers once you have the quest, and just make them repeat that line? It doesn't have to be interactive, and yes it will kill a tiny bit of the immersion listening to characters repeat themselves over and over, but Anderson does it when you talk to him on VidCon. Slightly more immersive: spend some time giving the quest givers three or four lines to cycle through. Takes time, but makes the side missions not suck.\n\n\n## Priority: Turians and Quarians\n\n\nThe Turian and Quarian story arcs should happen simultaneously. For a relatively guided divergent storyline in the first two games, ME3 is terribly linear. Priority mission, do sidequests, priorty mission, do all sidequests, etc, etc. There is only one way to work through the priority missions. Even doing the least possible amount of work, the \"Minimum Strength\" bar is full half way through the game. This is bullshit- if I have the minimum strength, I should be able to use it, and suffer the consequences! As with the side missions, a minor rearrangement of events would make it Divergent with a capital D, fulfilling Casey Hudsons' promise. Add the Quarians to the war counsel in the Annos Basin. It takes only another dozen or two lines of dialog, and gives the player the option of deciding whom to help first- the Turians, under attack from the Reapers, or the Quarians, in their war with the Geth. Of course, choosing one means the other is weakened when they finally join (with a little fancy arithmetic, there is a symmetric loss, so overall players aren't punished for choosing one over the other). Add another few lines of dialog depending on which is done first when finally starting the others' missions, and move the story forward a bit by putting the attack on the Citadel after completing one or the other of these priority missions.\n\n\n## Priority: Asari and Salarians\n\n\nThe Asari and Salarians feel like they were more cut than Javik. Getting full Salarian support is stupidly hard, and essentially requires Sheperd stabbing one of his closes allies, not to mention the entire Krogan race, in the back. Yet, there's a perfect alternative: Salarians are already at odds within their government. Add a small side-mission after the Cerberus attack on the Citadel, made much easier if the Salarian counselor survived the attack, working with an STG group somewhere in the galaxy. Completing that mission will add several Salarian war assets, piss off the Delatross a bit, but overall gaining Salarian popular support. With the Asari, the attack on Thessia should start earlier, ideally offered during the aftermath of the Cerberus attack. Shep of course still gets to choose what order to tackle things in, but having more Priority missions active at any one time would, I think, increase the narrative tension in the game. The player needs to decide the right balance between pushing forward with the assault on Earth, knowing the fleets are not at their full potential, while simultaneously knowing that the longer it takes to bring a fleet into the war, the weaker that fleet is. In this scenario, in the middle game Shep will have a timed mission to complete (Tuchanka: Bomb, Grissom Academy, and maybe one more), one or two N7 missions to tie in to the multiplayer, and three priority missions (Sur'Kesh/Tuchanka OR Rannoch, Sur'Kesh 2, and Thessia/Horizon/Cerberus) to choose from. Starting Cerberus can start the end game just as it does now, with the possibility of assaulting Earth with a very weak fleet.\n\n\n## Priority: Earth\n\n\nThe majority of the Earth mission needs just a touch more work, and mostly from the CGI Video department. While the text blurbs about the different assets add tremendous wealth and texture to the narrative, actually seeing some of those units in play would be worth every dollar put in to their creation. To this end, the initial \"Checking In\" shots are not enough. Each of the major assets (the race's fleets, eg all the top-level war asset categories) should have a unique role to play in the battle for Earth. This is the climax of the entire series. It needs the most thought of all the parts of this franchise. Spend time to sketch out exactly, in all the details, what would happen in this battle. The Sword fleet and Hammer force approach through the Charon relay. The Reapers take position around Earth, between the Allied fleets and the Citadel. The Allied fleets fire the opening volleys (highlighting Alliance, Turian and Asari dreadnaughts), limiting their fire to conservative targeting solutions, not wanting to hit Earth. As the distance closes, the fighter units join combat. When the Reapers are appropriately engaged with broadside fleet operations, and the fighters have set up an appropriate screen, Hammer slips through to land in London. So far, no changes from what's actually shown on screen. Now, with support from the various special ops war assets, we could have a few 5 or 10 second shots of these different groups in action on Earth. About half way through the mission (when Shep reaches the Forward Operations Base), we get another couple of special CGI scenes. If the fleets have the support of the Geth, Quarians, or Salarians, those fleets can be shown providing relief for Sword (call them Shield). If not... well, we see more Sword ships getting demolished by the Reapers.\n\nPart two, the push to the conduit, again plays out as it is now. We have a final change, though- when Harbinger breaks off, if Shep has a second fleet in Shield, that fleet breaks off and harasses Harbinger enough to let Shep get to the Citadel without that obnoxious laser. If Shep doesn't have that asset, Harbinger beats Shep to the Conduit, shoots Shep, and proceeds to destroy the fleets in Earth orbit. Yes, if a player chooses to have a Shep with this few assets, the Reapers should win. If there were two fleets in Shield, Harbinger ties Shep to the Conduit, kills Shep still, but Anderson manages to get through. Anderson sets off the Crucible, destroys the Reapers, but the Galaxy is left in shambles. If Shep has enough assets, Shield slows Harbinger enough to give Shep time to make it to the Citadel. This time, Shep meets The Illusive Man, and the player is given one last choice: Destroy or Control. Not in a red/blue explosion way, but TIM has spent time studying the Crucible in ways the Allied scientists would not, and has a plausible reason for how to re-purpose the Crucible's output. Shep then chooses- destroy the Reapers, uniting the galactic races, or use the Reapers to destroy the other races, ensuring Human dominance. Four endings, one possible choice, and each is dictated by how the player has gotten assets through the first games with any final choices here. Finally, we earn a 5 minute cut scene wrapping up all our choices. Remember how Fallout 3 has the montage of 10 or 20 second clips of all the people The Vault Dweller runs into? Same thing, 10 - 20 second clips for a reasonable number of important plot points throughout the first few games. One longer video for the Reapers winning, then one or two for the major Allied races who survived, and two or three for each squad mate who survived, depending on how they interacted with Shep through the series.\n\n\n## Reaper Motives\n\n\nThe Star Child is stupid. The Star Child is completely unnecessary. The Star Child's dialog and writing are worse than the trash that made it into Mass Effect: Deception. Really, Bioware could have done almost anything with the Reapers' motives, and had a better ending. I see two obvious choices. Have the Reapers truly be a Lovecraftian horror. Humanity is nothing in the galaxy. Not only is Humanity nothing in the galaxy, literally all Humanity's companions are nothing. Harbinger can continue the line that Sovereign starts: the Reapers are unknowable, incomprehensible, and utterly powerful. For that to work, however, the Reapers must win, and will if Shep can't rally enough forces. Otherwise, come to the realization that ascension for other species is reproduction for the Reapers. The Reapers come through every cycle and harvest the current best DNA to create new Reapers. This cycle business is another form of Natural Selection, well within the confines of today's science mixed with the sci-fi of Mass Effect. Why, then, would Sovereign and Harbinger tell Shep the Reapers are incomprehensible? They're arrogant sons of bitches, and Shep's just put a boot in their face to prove them wrong. In the ending scenarios I described above, have a final conversation between Harbinger and Shep at one of two points- either in person, in the endings where Shep dies, of Harbinger gloating, or via hologram when Shep's on the Citadel, of Shep gloating, when Shep wins. The series is so profound in its presentation of a myriad of philosophical issues, with Cosmicism in nearly everyone's mind since the first sight of Sovereign on Eden Prime. Embrace that! \n\n\n## The End\n\n\nYes, we will see DLC. I would love an Aria/Omega DLC, adding a mission to route Cerberus from the Anti-Citadel. I would pay for that DLC, and a myriad of other stories from this universe. There is so much potential in this Galaxy at War, and I do not begrudge Bioware and their evil overlords, EA, the desire to charge for more content. What I do have a problem with is how horribly Casey Hudson and Bioware mishandled this climax of the greatest Sci Fi story to appear in a video game. I begrudge the fact that we, the fans, were lied to, repeatedly. The ending that shipped with Mass Effect 3 was not wildly divergent. The story of ME3 was not particularly divergent. Each small arc did an excellent job at closing all the stories we, the fans, have grown to love and cherish. Why, then, were we told Sheperd's arc wasn't important enough for that same closing?\n\n\n## Addendum\n\n\nMore Elcor.\n",
      "intro": ""
    },
    "/posts/2012/03/28/double-mapper/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2012-03-28T20:30:07.000Z",
        "layout": "post",
        "slug": "double-mapper",
        "title": "Double Mapper!",
        "wordpress_id": 326,
        "categories": [
          "Technology"
        ],
        "path": "/posts/2012/03/28/double-mapper/index.md"
      },
      "body": "I've always loved places, and in loving places, have always loved maps. I've always been curious as to the relative size of places, as well. I'm decent at estimating some things, but lengths, not so much. To get a better understanding of the comparative sizes of places around the world, I put together these pair of Google Maps, superimposed over one-another to see exactly how these sizes work. Note that because of using two maps in a Mercator projection, the sizes technically only line up when the map centers are on the same latitude. \n\n[Full Size](http://davidsouther.com/projects/doublemap/)  \n\n\n"
    },
    "/posts/2012/04/10/335/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2012-04-10T02:12:24.000Z",
        "layout": "post",
        "slug": "335",
        "title": "That is all",
        "wordpress_id": 335,
        "categories": [
          "Humor"
        ],
        "path": "/posts/2012/04/10/335/index.md"
      },
      "body": "[![](http://davidsouther.com/wp-content/uploads/2012/04/1241100353_anchorman-kicking-the-dog.gif)](http://davidsouther.com/wp-content/uploads/2012/04/1241100353_anchorman-kicking-the-dog.gif)\n"
    },
    "/posts/2012/04/13/agile-development-consulting/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2012-04-13T13:03:39.000Z",
        "layout": "post",
        "slug": "agile-development-consulting",
        "title": "Agile Development Consulting",
        "wordpress_id": 248,
        "categories": [
          "Technology"
        ],
        "tags": [
          "agile",
          "client relations",
          "consulting",
          "continuous integration"
        ],
        "path": "/posts/2012/04/13/agile-development-consulting/index.md"
      },
      "body": "_This is an open letter from me to nearly any potential client. The client and I have talked for a few emails, and I have just read an email asking me to spend 4 to 8 hours in a meeting working to detail every single piece of their software project for the next 6 months, with the expectation that in 6 months we would get back together and they will have a complete, perfect piece of software. In my reply, I try to convince them of an agile approach to development._\n\nLet's take a moment to talk about software development projects. In your email, you describe the Big Design Up Front (BDUF) approach to building projects. Everyone gets together for a meeting or two at the beginning of the project, sits down, and writes a document that describes in excruciating detail what every person in the implementation team will be doing for the rest of the project. This is necessary for buildings, for two reasons. First, it is very expensive to get half way through a project and realize that instead of a skyscraper, the owner actually needs a factory. This is even more exacerbated in software, because the medium is so abstract. Second, it is really hard to predict the future, which is what BDUF does. How can I say, \"On the 3rd of January, 2012, David will spend exactly 2 hours building form 34-A\"? We can't.\n\n<!-- more -->\n\nThe alternative is Just Enough Design Up Front (JEDUF). This approach says \"We don't know exactly what's going to happen in two months, but we actually do have a pretty good idea of where we want to be.\" In this alternative, we embrace and expect flexibility. In the \"Scope, Resources, Schedule\" triple constraint, we fix the resources and schedule, and allow the scope to change as needed. This sounds troubling in theory, but in fact turns out to work very well in practice. There is a wealth of literature showing Agile projects have better productivity, lower costs, and overall higher stakeholder satisfaction than their traditional counterparts. Let me walk you through the overall approach to agile project management, and I think you'll see how this is achieved.\n\nAt the start of the project, we get together and create user stories. User stories describe the features we need in the project, irrespective of how those are actually achieved. Once we have these user stories, you, the product owner, prioritize them. This becomes what we call the Product Backlog. These are all the things you want the software to do, but it doesn't yet do. At any time, you can add things to the product backlog, re-prioritize the backlog, take things off, whatever. It's your list, describing your vision of the completed project. Notice that there is no specific plan on how to achieve the vision- just what you want done, listed in the order of importance. \"As a registered user, I can expect my account to be locked after three failed logins so that my account remains secure\" and \"As a Teller I want to be able to find clients by last name, so that I can find their profile faster\" are good examples of user stories. A user story has a well-defined format: \"As a (type of user), I want to (overview of a feature), so that I can (why the feature is needed).\" This gives us the scope details we can use later in the project.\n\nOnce we have these user stories, the development team (me, in this case) assigns each user story an estimate in story points. This estimate is very abstract- it is not a time estimate, nor is it a commitment. It is just a number that describes roughly how big each story is, relative to other user stories. If a user story is too large, we will go back through and break it into smaller user stories grouped as a theme, until we have a rich collection of discrete user stories. Once we have this collection, and it's time to start a sprint, the development team will take some of those stories for the sprint backlog. The sprint backlog is the list of things we expect to be able to complete in a sprint. To choose which stories to do in a sprint, we start at the top of the product backlog and pull user stories until the total estimate for those stories is the same as we estimate our ability to complete in a sprint. This number is not set willie-nillie, but is calculated as a velocity based on what was completed during previous sprints. At the end of the sprint, we look at all the stories we completed, add that number up, and calculate a velocity in story points per sprint. This number becomes a highly accurate descriptor of what the team will achieve in each sprint.\n\nAt the end of the sprint, every user story is either completed or not. There is no 30% done, nor \"almost there\" - it either works, or it doesn't. To do this, we need well-defined acceptance criteria at the beginning of each sprint. This ensures you know exactly what to expect at the end of the sprint, and I know exactly what I'm building. As much as possible we want these acceptance criteria to be automatically testable, or at least up to as little debate as possible. At the end of the sprint, we also look at how much was promised (story points from the product backlog) and how much was delivered. That ratio describes the percentage of possible discount. This continual delivery is a key benefit of an agile approach vs the more traditional approach, when the development team goes away for a month or three, and you have no idea what will come out. Instead, we have continual communication to make sure we are on the same page, and you can see the software as it is created in order to meet changing requirements, changing business goals, and in order to have more flexibility in general.\n\nI cannot stress enough how important continual delivery is in this practice. I have seen too many software projects start with the best intentions, only for their development teams to disappear for days, weeks, or even months before coming back with a piece of software that not only doesn't function, but no longer has any similarity to what the client envisioned. Instead, with continuous integration, the client always knows exactly where their project is. There is never a misunderstanding of what is currently on the table- the software is available and speaks for itself. With continuous integration, you can walk away at any time. If (and this will not happen with me) you ever feel the project is not going in the direction you want, you can cut your losses and take the current working software and take it to any other developer you want to continue your project. That is just some of the value of an agile approach with continuous integration.\n\nI've gone on for a thousand words now, but I'd like to say one last thing. I am so convinced of the quality of this approach to software that I will give you the first sprint's work for free, and the second sprint for half price. I want to do this project with you, and I know you will like my work so much that I am willing to give 3 weeks of my time to prove how well this process works, and to prove the quality of my work.\n\nSincerely Yours,\n\nDavid Souther\n",
      "intro": ""
    },
    "/posts/2012/04/13/git-svn-dcommit-hooks/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2012-04-13T20:47:34.000Z",
        "layout": "post",
        "slug": "git-svn-dcommit-hooks",
        "title": "git svn dcommit hooks",
        "wordpress_id": 341,
        "categories": [
          "Technology"
        ],
        "tags": [
          "git",
          "git hooks",
          "git-svn-dcommit",
          "svn"
        ],
        "path": "/posts/2012/04/13/git-svn-dcommit-hooks/index.md"
      },
      "body": "Working with git and svn is as easy as `git svn init ; git svn rebase ; git svn dcommit`. What is slightly less trivial is adding hooks to enforce certain project behavior when working with git-svn. Specifically, I want to ensure and enforce that the build (locally, at least) is successful before I push to Subversion. In this case, I don't have access to the Subversion server, so adding the hooks server-side is impossible. The [recommended approach](http://stackoverflow.com/questions/2014422/hooks-for-git-svn) is to use an intermediate bare repository, but that presents problems with running build scripts on the repository, since there is no working directory to build in. There is [some discussion](http://git.661346.n2.nabble.com/PATCH-v2-git-svn-hook-before-git-svn-dcommit-td6688978.html) on adding svn-dcommit hooks, but that does not look like it will be landing in git any time soon. The  solution I have is to have a repository with split heads. Most of the time, the intermediate repository will have an empty working directory. When a push happens, it will check out master, verify the build, and push to svn, before returning to the empty branch. Let's look at this in practice.\n<!-- more -->\n\nIf you want to follow along, the script is [available as a gist](https://gist.github.com/8dfc6575f4d3a293be7c).\n\n\n\n### Step 0: Upstream SVN\n\n\n\nThis is just so we have an SVN repo to look at. This step requires svn, svnadmin, and ssh. Having keys configured for ssh on localhost will make life easier.\n\n[bash]\nROOT=~/devel/$USER/git-experiments/svnhooks\nmkdir $ROOT ; cd $ROOT\nsvnadmin create svn\n\ncd svn\ncat >| conf/svnserve.conf <<SVN\n[general]\nanon-access = write\nSVN\ncd ..\n\nsvn mkdir --parents file://$ROOT/svn/experiments/{trunk,branches,tags} -m 'Initial structure'\nsvnserve -d -r $ROOT/svn\n\nsvn co svn://localhost/experiments/ svnwork\ncd svnwork/trunk\necho \"Mashed Potatoes\" >> recipe\nsvn add recipe\nsvn commit -m 'Added recipe.'\n[/bash]\n\n\n\n### Step 1: Interim git Repo\n\n\nWe're going to set up an intermediate git repo with two branches. master will still point to the SVN repo, and the new branch stage will let us keep the working directory clean and in sync with downstream changes.\n[bash]\ncd $ROOT\ngit svn clone -s svn://localhost/experiments/ upstream\ncd upstream\nrm .git/hooks/*\ngit symbolic-ref HEAD refs/heads/stage\nrm .git/index\ngit clean -fdx\ntouch .empty\ngit add .empty\ngit ci -am 'Empty stage.'\n[/bash]\n\n\n\n### Step 2: Working git Repo\n\n\nWe now want to create a normal git repo, whose remote/origin is the intermediate repo.\n\n[bash]\ncd $ROOT\ngit clone upstream/ work\ncd work\ngit checkout master #Get up to date\n[/bash]\n\n\n\n### Step 3.0: Build script\n\n\nBefore we delve too deep into the hooks, we need a build script. This \"build\" script just checks if the file passes our \"test\" - the recipe has a 'Servings:' list\n[bash]\ncat >|$ROOT/build <<BUILD\n#!/bin/sh\ngrep 'Servings:' recipe >/dev/null 2>&1\nBUILD\nchmod a+x $ROOT/build\n[/bash]\n\n\n\n### Step 3: Intermediate Repo hooks\n\n\nNow, the heart of this. We are going to set up two hooks. The pre-receive hook is going to verify there are no upstream changes. The post-update hook is going to ensure the build passes, and if so push the changes to SVN.\n\n\n\n#### pre-receive\n\n\n[bash]\ncat >| $ROOT/upstream/.git/hooks/pre-receive <<PRE\n#!/bin/bash\n\necho \"pre-receive\"\nDIR=\"\\$(pwd)\"\n\nexport GIT_DIR=\"\\$DIR\"\nexport GIT_WORK_TREE=\"\\${DIR%/.git}\"\n\nCUR=\\$(git rev-list master | wc -l)\n\necho \"Before rebase, had \\$CUR commits\"\n\ncd \\$GIT_WORK_TREE\ngit checkout master\ngit svn rebase\nREBASED=\\$?\ngit checkout stage >/dev/null 2>&1\n\nif [ -not \\$REBASED -eq 0 ]\nthen\n\techo \"Rebase failed\"\n\texit $REBASED\nfi\n\nPOST=\\$(git rev-list master | wc -l)\necho \"After rebase, have \\$POST commits\"\n\necho \"Object counts were \\$CUR::\\$POST\"\nif [ ! \\$CUR = \\$POST ]\nthen\n\techo \"New changes from SVN, please merge.\"\n\texit 1\nfi\necho \"pre-receive found SVN is up to date.\"\nexit 0\nPRE\nchmod a+x $ROOT/upstream/.git/hooks/pre-receive\n[/bash]\n\n\n\n#### post-update\n\n\n[bash]\ncat >| $ROOT/upstream/.git/hooks/post-update <<POST\n#!/bin/bash\n\necho \"post-update\"\n\nDIR=\\$(pwd)\necho \"In \\$DIR\"\nexport GIT_DIR=\"\\$DIR\"\nexport GIT_WORK_TREE=\"\\${DIR%/.git}\"\n\necho \"GIT: \\$GIT_DIR; in \\$GIT_WORK_TREE (\\`pwd\\`)\"\n\ncd \\$GIT_WORK_TREE\n\ngit checkout master\n\n$ROOT/build #CHANGE THIS TO YOUR BUILD LINE\nBUILT=\\$?\n\necho \"Build finished with \\$BUILT\"\n\nif [ \\$BUILT -eq 0 ]\nthen\n\tgit svn dcommit\nelse\n\techo \"Could not build, not pushing to SVN.\"\nfi\n\ngit checkout stage >/dev/null 2>&1\nPOST\nchmod a+x $ROOT/upstream/.git/hooks/post-update\n[/bash]\n\n\n\n### Step 4: Test\n\n\n\n\n\n#### Push -> Break\n\n\nIn our first test, we want to try and commit code that will break the build. After this operation, the Intermediate repo and the working repo will have consistent code, but those commits will not have been passed to the upstream SVN server.\n\n[bash]\ncd $ROOT/work\ncat >> recipe <<ing\n4 Potatoes, diced\nsalt, 4 cups\nwater, 1 tablespoon\ning\ngit ci -am 'Added ingredients list.'\ngit push 2>&1 | tee $ROOT/tmp\nfgrep \"remote: Could not build, not pushing to SVN.\" $ROOT/tmp || echo \"Couldn't find fail line\"\n[/bash]\n\n\n\n#### Push -> dcommit\n\n\nIn our second test, we want to make sure we see a push to SVN.\n\n[bash]\ncd $ROOT/work\ncat >> recipe <<ing\nServings: 3\ning\ngit ci -am 'Added Serving size.'\ngit push 2>&1 | tee $ROOT/tmp\nfgrep \"remote: Resetting to the latest\" $ROOT/tmp || echo \"Couldn't find fail line\"\n[/bash]\n\n\n\n#### Push -> Rebase\n\n\nWhat happens when other developers commit to the upstream svn? If the commits don't conflict, ideally we'd like the hooks to pull down the upstream changes, rebase the new changes on top, and check if the build has broken. Assuming it hasn't, it should push the new tree, and politely inform us that there are new changes we need to rebase our working repo onto.\n\n[bash]\ncd $ROOT/svnwork/trunk\nsvn update\ncat >| shopping <<LIST\nPotatoes\nLIST\nsvn add shopping\nsvn commit -m 'Started a shopping list.'\n\ncd $ROOT/work\ncat >> recipe <<INST\nBegin by adding salt to the water and bringing it to a boil.\nINST\ngit ci -am \"Added step 1\"\ngit pull --rebase #Get upstream changes\ngit push 2>&1 | tee $ROOT/tmp\nfgrep \"New changes from SVN, please merge.\" $ROOT/tmp || echo \"SVN Should be more recent\"\ngit pull --rebase\ngit push 2>&1 | tee $ROOT/tmp\nfgrep \"pre-receive found SVN is up to date\" $ROOT/tmp || echo \"SVN Should be up to date\"\n[/bash]\n\n\n\n#### Push -> Conflict\n\n\nThe last test of our script is what happens when there is a conflicting upstream commit. Here, the pre-commit will fail after pulling the change, warn of the commit, and recommend a pull --rebase. After completing the rebase in work, we push it back up and the project is healthy again.\n\n[bash]\ncd $ROOT/svnwork/trunk\nsvn update\nsed -i 's/salt, 4 cups/Salt, 4 tablespoons/' recipe \nsvn commit -m 'Reduced the salt level.'\n\ncd $ROOT/work\ngit pull --rebase\nsed -i 's/salt, 4 cups/Salt, 1 tablespoon/' recipe \nsed -i 's/water, 1 tablespoon/Water, 1 cup/' recipe\ngit ci -am 'Fixed salt/water qty mismatch'\ngit push 2>&1 | tee $ROOT/tmp\ngit pull --rebase\n\ned -s recipe <<ED\n3d\n4,6d\n4s/1/4/\n5d\nw\nq\nED\n\ngit add recipe\ngit rebase --continue\ngit push\n[/bash]\n\nThat's it. Work flows in the normal branch/hack/commit/merge approach git emphasizes, and git push works upstream with no difficulties. Frequent use of `git pull --rebase` is always recommended, and works here as expected. The full script for all these blocks of code is [available as a gist](https://gist.github.com/8dfc6575f4d3a293be7c).\n",
      "intro": ""
    },
    "/posts/2012/04/14/boink/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2012-04-14T14:44:41.000Z",
        "layout": "post",
        "slug": "boink",
        "title": "*boink*",
        "wordpress_id": 368,
        "categories": [
          "Humor"
        ],
        "path": "/posts/2012/04/14/boink/index.md"
      },
      "body": "[![](http://davidsouther.com/wp-content/uploads/2012/04/funny-animal-gifs-animal-gifs-boink.gif)](http://davidsouther.com/wp-content/uploads/2012/04/funny-animal-gifs-animal-gifs-boink.gif)\n\n[via](http://icanhascheezburger.com/2012/04/12/funny-animal-gifs-boink/)\n"
    },
    "/posts/2012/04/29/need-firefox-have-bash/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2012-04-29T13:56:48.000Z",
        "layout": "post",
        "slug": "need-firefox-have-bash",
        "title": "Need Firefox, have bash",
        "wordpress_id": 373,
        "categories": [
          "Technology"
        ],
        "path": "/posts/2012/04/29/need-firefox-have-bash/index.md"
      },
      "body": "For web development, we often need to test our code on multiple browsers. Firefox makes it really easy to run multiple versions side-by-side, so long as we take some care to not clobber profiles. This is a quick script to download and install the production versions of Firefox from 4 through 12 (13 is in beta1 as of this writing; 3.6 has no x86_64 support)\n\n\n"
    },
    "/posts/2012/05/06/its-a-spetus/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2012-05-06T16:11:00.000Z",
        "layout": "post",
        "slug": "its-a-spetus",
        "title": "It's a spetus!",
        "wordpress_id": 376,
        "categories": [
          "Technology"
        ],
        "path": "/posts/2012/05/06/its-a-spetus/index.md"
      },
      "body": "[2008 August 25's NASA Astronomy Picture of the Day](http://apod.nasa.gov/apod/ap080825.html)\n\nNASA makes a joke about this not being a planetary forming nebula. While they are correct in that this nebula is not a fetus, it looks like a fetus. Ergo, spetus.\n\n[![The Spetus!](http://apod.nasa.gov/apod/image/0808/ngc7008_hagercollab_c800.jpg)](http://apod.nasa.gov/apod/ap080825.html)\n"
    },
    "/posts/2012/06/16/fedora-chrome-installer/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2012-06-16T14:26:33.000Z",
        "layout": "post",
        "slug": "fedora-chrome-installer",
        "title": "Fedora Chrome Installer",
        "wordpress_id": 380,
        "categories": [
          "Technology"
        ],
        "path": "/posts/2012/06/16/fedora-chrome-installer/index.md"
      },
      "body": "[This gist](https://raw.github.com/gist/81046a9002616bbfab54/14b3a3be6def4bb25a880513cbf052e853d8f6f9/fedora-16-x86_64-chrome) saves the Chrome repo block and installs latest stable.\n\n```sh\nsudo su -c 'curl https://raw.github.com/gist/81046a9002616bbfab54/14b3a3be6def4bb25a880513cbf052e853d8f6f9/fedora-16-x86_64-chrome 2>/dev/null | sh'\n```\n"
    },
    "/posts/2012/06/16/superscore/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2012-06-16T14:27:06.000Z",
        "layout": "post",
        "slug": "superscore",
        "title": "Superscore",
        "wordpress_id": 379,
        "categories": [
          "Technology"
        ],
        "tags": [
          "javascript",
          "superscore",
          "underscore"
        ],
        "path": "/posts/2012/06/16/superscore/index.md"
      },
      "body": "[Underscore.js](http://underscorejs.org/) is a fantastic tool, something that nearly every javascript project will probably want to pull in at some point. Underscore is the collections framework for Javascript. It does all the collectiony things, in a functional way, very quickly and efficiently. There are still a couple other every-day things that JS libraries need, that don't quite touch the DOM, making jQuery a bit too heavy. To that end, I've put those features in a library called Superscore, a few additions to the underscore library. Many of these stand on their own, but since you should already be using underscore, it makes sense to namespace them there.\n\nThe project is available on [github](https://github.com/DavidSouther/superscore), along with all the [documentation](http://davidsouther.github.com/superscore/). Take a look and see if there's a place for it in your projects!\n"
    },
    "/posts/2012/06/27/mass-effect-3-the-actual-ending/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2012-06-27T04:38:01.000Z",
        "layout": "post",
        "slug": "mass-effect-3-the-actual-ending",
        "title": "Mass Effect 3: The Actual Ending",
        "wordpress_id": 383,
        "categories": [
          "Technology"
        ],
        "tags": [
          "ending",
          "Mass Effect 3",
          "ME3",
          "scotch"
        ],
        "path": "/posts/2012/06/27/mass-effect-3-the-actual-ending/index.md"
      },
      "body": "Oh look ME3 has a real ending! You know, the kind of ending that has resolution to a storyline! Still not as good an ending as I could have written, but oh well. More tomorrow, when I've played more than one of the endings and am not buzzed. PS Scotch Parties FTW!\n"
    },
    "/posts/2012/07/09/html5-form-validation/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2012-07-09T13:23:43.000Z",
        "layout": "post",
        "slug": "html5-form-validation",
        "title": "HTML5 Form Validation",
        "wordpress_id": 411,
        "categories": [
          "Technology"
        ],
        "tags": [
          "forms",
          "HTML",
          "html forms",
          "html5",
          "jquery",
          "validation"
        ],
        "path": "/posts/2012/07/09/html5-form-validation/index.md"
      },
      "body": "Client-side form validation is a cross-cutting concern helping users get the most correct data into a form as quickly as possible. Good form validation will tell users what fields are most important in your form and exactly what is expected of their input. Form validation is not concerned with guaranteeing correct data gets sent from the user agent to the service backing the form -- the service should define its own data ingestion and validation concerns. This discussion is only concerned with client-side form validation and helping users input acceptable data.\n\n<!-- more -->\n\nIn this view, the form itself is an entire application, independent of any other piece of software. The form, rendered in the browser DOM, provides visual elements for a user to provide input. As the user provides input, the form will indicate whether that data is correct, perhaps by highlighting the field in green, or provide warnings that the data is invalid, perhaps by highlighting the field in red and displaying a light-weight pop-up with a polite message describing what, exactly, is wrong with the input. When the user tells the form to submit data, the form can decide if the input is appropriate, and if so pass that data on to some other service. Generally, this will be an HTTP POST, but could occur as a full page redirect or an AJAX request. In a more exotic workflow, the form could aggregate the input and generate an event to some other element, or publish a message to a web-worker.\n\n\n\n\n\nTo achieve this view of form validation, a single library must meet a variety of concerns.\n\n\n\n\n\n\n\n## Semantic\n\n\n\n\n\nValidation markup should describe the expected data as fully as possible. Semantic descriptions of data should be as consistent as possible, ensuring a consistent and quality experience across the forms on the domain.\n\n\n\n\n\n  ### HTML5 Native\n\n\n\n\n\nThe HTML5 specification provides a wealth of expressive form and validation features. HTML4 forms not served as strict XHTML are able to access these attributes programmatically. Any implementation should at least look to the design decisions made by the HTML5 working group.\n\n\n\n  ### Settings in markup\n\n\n\n\n\nAny validation settings, including rules and error behavior, should be described as close to the input field as possible, preferably as an attribute directly. Localization and internationalization may require settings stored in alternative locations, in which case the l10n and i18n keys should be as close to the element as possible.\n\n\n\n  ### Error markup\n\n\n\n\n\nThe markup rendering errors and notifications should have semantic descriptions, probably achieved with specific classes. Browser support for pseudo-selectors would also be an excellent hook for designers to use.\n\n\n\n  ### Form & field\n\n\n\n\n\nValidation rules will apply both to input fields individually, as well as to groups of input fields and forms as a whole. The library needs a mechanism to support business logic at any level of field aggregation. For instance, a form may need to ask for multiple email addresses. A component could be built around a `<ul>` and adding `<li><input type=\"email\" name=\"to[]\" class=\"distinct\" />` for every new email address the user wishes to add. Each input must contain a valid email address, and the `<ul>` as a whole should guarantee that each address in the `to[]` array is unique.\n\n\n\n\n\n## Aspect\n\n\n\n\n\nForm validation is a cross-cutting concern. Form code should not need to take any actions beyond describing the validation rules (in as little code as possible). The validation tools should apply without further intervention to any form and form element available.\n\n\n\n\n\n  ### Applies with no intervention\n\n\n\n\n\nIncluding the code on a page should be the most intervention necessary by client code. If the validation library is part of the browser itself, purely semantic html/css forms will work with no developer intervention (though library extensions may still be necessary to bridge incompatible or incomplete implementations).\n\n\n\n  ### Hooks to sensible events\n\n\n\n\n\nThere are places where forms' business logic will need additional or non-standard logic given its data descriptions. While the validation library should attach to forms automatically, it should also provide appropriate events and hooks for forms to extend additional behaviors. Further, some forms libraries may attempt to make disparate user agents behave consistently; in this case, the library must provide a common event interface across implementations.\n\n\n\n\n\n## Non-invasive\n\n\n\n\n\nAs validation logic gets applied cross-cuttingly, it is imperative the library not cause render, layout, page-reflow, and other errors.\n\n\n\n\n\n  ### Doesn't change page flow\n\n\n\n\n\nUnder no circumstances can the validation library cause a page reflow under normal CSS conditions. Any elements added to the page must be given a default style removing them from page flow. Any classes added should be well-described, and chosen to minimize the chance of conflicting with other common class names.\n\n\n\n\n\n    ### Float with arrow\n\n\n\n\n\nHTML5 browsers have independently adopted the convention of a floating div with an arrow pointing at the input element.\n\n\n\n\n\n  ### Doesn't interupt the user\n\n\n\n\n\nValidation should not occur while the user is actively providing input. In particular, if an element has focus validation should wait until absolutely certain the user is done inputting data to display validation errors. In a similar vein, if a user is rapidly jumping between fields, validation should not display errors in a way allowing users to miss the prompts.\n\n\n\n  ### Page data must remain visible\n\n\n\n\n\nValidation error messages should not cover page content, unless the validation message explicitly replaces that information.\n\n\n\n\n\n## Extensible\n\n\n\n\n\nForms will need to have business logic that does not fit in the default configuration of any particular validation library. The default error messages may not correctly describe the validation concern with the form.\n\n\n\n\n\n  ### Add, override validator functions\n\n\n\n\n\nSome validation functions may be incorrect. Forms may wish to constrain a URL to only accept `ftp:` connections. Emails may want to restrict to a certain mail domain. In any of these cases, the form will need to either add additional rules, or override the default rules.\n\n\n\n  ### Configure errors\n\n\n\n\n\nThe default errors will not describe every error of some class. A form may wish to tell a user that not only is the email invalid, it must be in a certain domain.\n\n\n\n  ### Markup, messages, settings\n\n\n\n\n\nForm designers demand as much control as possible. Business analysts will want to tweak and localize error messages. Developers will need to edit some default settings at some point. These should all be trivially easy to override piecemeal, as needed.\n\n\n\n\n\n\n\n\n## Current solutions\n\n\n\n\n\nThere are several libraries and tools today meeting some of these concerns.\n\n\n\n\n\n### HTML5 Form Validation\n\n\n\n\n\nHTML5 has a variety of validation features in place and implemented by the newer browsers. The specification covers what is likely to be 90% of the validation criteria in a fully standards compliant way (no more need to implement a grammar recognizing RFCs 5321 and 5322). Any additional rules can be added by a javascript library, focused on adding only the small subset of features a particular forms application needs.\n\n\n\n\n\n_[Usage](http://www.alistapart.com/articles/forward-thinking-form-validation/)_\n\n\n\n\n\nThis article from A List Apart is a fantastic discussion of ways to control validation using almost purely CSS.\n\n\n\n\n\n_[Shim](https://github.com/ryanseddon/H5F)_\n\n\n\n\n\nA shim for HTML4 browsers adding most of the utilities now provided by HTML5 browsers. Has some flaws:\n\n\n\n\n\n\n\n  * Doesn't fall back on native implementation\n\n\n  * Pseudo-selectors don't work for CSS2.\n\n\n\n\n\n_[More discussion](http://stephenwalther.com/archive/2012/03/13/html5-form-validation.aspx)_\n\n\n\n\n\nAnother article, with some intriguing uses of `title` and `x-moz-errormessage` attributes.\n\n\n\n\n\n### jQuery plugin\n\n\n\n\n\nThe bassistance jQuery plugin has become the de-facto standard jQuery validation library. It provides nearly every feature and meets all the concerns mentioned here, though is not as strictly focused as a pure HTML5 solution might be.\n\n\n\n\n\n_[Article](http://bassistance.de/jquery-plugins/jquery-plugin-validation/)_\n\n\n\n\n\nThe original discussion, highlighting its usefulness at meeting the criteria for a robust validation library. Claims \"Most used validation library.\"\n\n\n\n\n\n_[GitHub](https://github.com/jzaefferer/jquery-validation)_\n\n\n\n\n\nGithub repo for the project.\n\n\n\n\n\n_[jQuery Plugin](http://docs.jquery.com/Plugins/Validation)_\n\n\n\n\n\njQuery.com plugin page.\n\n\n\n",
      "intro": ""
    },
    "/posts/2012/07/21/lazy-ass-gourmet/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2012-07-21T18:00:51.000Z",
        "layout": "post",
        "slug": "lazy-ass-gourmet",
        "title": "Lazy-Ass Gourmet",
        "wordpress_id": 454,
        "categories": [
          "Lazy-Ass Gourmet"
        ],
        "tags": [
          "gourmet",
          "lazy"
        ],
        "path": "/posts/2012/07/21/lazy-ass-gourmet/index.md"
      },
      "body": "## The art of cooking Fast, Cheap, Clean\n\nWhy aren't you cooking for yourself? Do you think it's too expensive? Do you think you don't know how to cook? Or do you just think you don't have enough time in the day? If any of those are your excuse, you're about to lose them. Cooking great food isn't that difficult once you have a few basic dishes, and with the right recipes, you can be cooking great dinners for yourself or your family in half an hour. This is lazy-ass gourmet, and we're going to cook the most fantastic meals in no time at all.\n\n<!-- more -->\n\n\n\nI'm a busy guy, but man, I love to cook. I've yet to find a restaurant that can consistently satisfy me with their cooking more than I can do on my own. My secret is finding recipes, and ways to cook those recipes, that take as long to cook as it takes me to watch an episode of the Daily Show (then I watch Colbert while I eat!). Here at lazy-ass gourmet, I'll share a bunch of these recipes, and ways to cook them so that we have a wide combination of things to do with our dishes that we'll always have great food at home, and never get bored with what we're eating.\n\n\n\n\n\nThis isn't [Broke-ass Gourmet](http://www.brokeassgourmet.com) (I absolutely recommend her recipes, they are fantastic), but you'll find that while the ingredients for a meal are about the same as a plate would be if you went out, you'll several plates worth, and it will definitely come out much cheaper in the long run. The ingredients I recommend are a step up from college dorm food, but you can have fun shopping around for the best prices on what you find are your favorite things. On the other hand, this isn't Iron Chef. I don't use that many ingredients, I just play with what I have in slightly different ways.\n\n\n\n\n\nThere are a lot of techniques in cooking. It takes some time to get comfortable with a knife. There are a lot of spices and flavors to discover and find out how they work together. These all take your time and experimentation, and frankly half the fun of cooking is trying new things, especially when they go wrong! These are things you really can't learn in a book (though you can make good headway), but just have to try on your own.\n\n\n\n\n\nThere is one thing, however, that I can tell you in the spirit of Lazy-Ass Gourmet. Clean up immediately. As in, before you go on to the next step, wipe off your utensils you just used and the surface you just used. It takes 10 seconds, but saves so much time from the daunting task of cleaning everything at once after you've cooked. Also, do things that make it easier to keep clean. When you're chopping and peeling onions, keep the trash can right there for the peelings. When you're working at the stove, put a splash guard over your pan and a lid on your pots. These little things make it a hundred times easier to keep your kitchen clean, and yourself happy and lazy.\n\n\n\n",
      "intro": ""
    },
    "/posts/2012/07/21/steak-potatoes/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2012-07-21T18:00:14.000Z",
        "layout": "post",
        "slug": "steak-potatoes",
        "title": "Steak & Potatoes",
        "wordpress_id": 457,
        "categories": [
          "Lazy-Ass Gourmet"
        ],
        "tags": [
          "onion",
          "onions",
          "potatoes",
          "steak",
          "veggies"
        ],
        "path": "/posts/2012/07/21/steak-potatoes/index.md"
      },
      "body": "Nothing says good eating like a steaming plate of steaks, mashed potatoes, and country veggies. The best part? It's one of the easiest things you can cook. Follow along, and in half an hour you'll be having better steaks than they server at Morton's.\n\n<!-- more -->\n\n  * 2 to 4 Fillets, 1-2\" thick.\n  * 1 can whole kernel corn\n  * 1 can sliced carrots\n  * 1 can french-cut green beans\n  * 1 white onion\n  * 4-6 red potatoes\n  * 2 tblsp butter\n  * 1/4 quart half-and-half\n  * Salt\n  * Lawry's\n  * Olive oil\n\nQuarter the potatoes. We're doing mashed potatoes, so go fast and dirty here. Find the longest, thinnest part of the potato, cut in half, find the next thinnest side, cut in half, then cut the last side two or three times. At this point you'll have <1\" cubes of potato. Put those potatoes & some salt in pot. Add water to ~1\" above the potatoes. Add a dash (~1 teaspoon) of oil (this stops the water from boiling over. Place the pot over high heat.\n\n\n\n\n\nChop the onion. Start by cutting off the ends. I like larger chunks of onion, so I usually slice once through the thickest part of the onion, once through each half, then slice one of the quarters the long way and the other quarter radially. That gives a good combination of fat slices and long slices. Pour a couple dashes of oil into pan (not too much, just enough to start searing the onion). Bring oil to temperature. Over high heat this should take less than a minute; you'll know its ready when the oil starts to have rivulets when it flows over itself. Add the onions, stirring regularly until the onions are lightly cooked. Add some Lawry's. Clear out an area of the pan moving the onions to the side. Add steaks in the clearing, let them cook for about a minute, dash the uncooked side  with Lawry's, turn them over. Drain veggies from the can. Add veggies to the pan, add Lawry's to taste, stir, and cover. Wait about 15 minutes, stirring occasionally.\n\n\n\n\n\nWhen potatoes are done (easily pierced by fork), drain in colander and put back in pot. Rinse colander and place on drying rack. Add butter, half-and- half, and salt to potatoes. Mash. This makes the consistency I like; for thicker use more potatoes or less half-and-half; for thinner use less potatoes or thinner milk (whole, skim).\n\n\n\n\n\nSteaks will take about 5 minutes / level: 5 minutes rare, 10 minutes medium rare, 15 minutes medium well, 20 minutes well done. Test by cutting open; after a few times, you'll get a feel for your stove and know when they're done without needing to check.\n\n\n\n\n\nWipe off counter, serve, & enjoy!\n\n\n\n\n\n### Alternatives:\n\n  1. Add clove, then onion.\n  2. Use fresh veggies (adds ~5 minutes to dice).\n  3. Use different meat: different steak cuts, pork, chicken, etc.\n",
      "intro": ""
    },
    "/posts/2012/07/23/chili/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2012-07-23T18:00:06.000Z",
        "layout": "post",
        "slug": "chili",
        "title": "Chili",
        "wordpress_id": 459,
        "categories": [
          "Lazy-Ass Gourmet"
        ],
        "tags": [
          "beer",
          "chili",
          "ground beef",
          "salsa"
        ],
        "path": "/posts/2012/07/23/chili/index.md"
      },
      "body": "Cold day or hot, nothing quite says tasty like a bowl of home-made chili. Probably the easiest dish to take and make your own, so many easy things go into the flavors of a pot of easy chili, you can't help but not experiment with this recipe!\n\n<!-- more -->\n\n  * 1/2 lbs ground beef\n  * 1 12oz can salsa (your choice, determines spicy level)\n  * 1 8oz can refried beans\n  * 1 12oz bottle beer (your choice, determines secondary flavors)\n  * Olive Oil\n\n\nThis recipe goes easy by trusting the brewer and salsa-er (one who makes salsa?) for the flavors in the chili. With that in mind, choose your favorite salsa and a beer you think would go with that salsa, and start your burners!\n\n\n\n\n\nBrown the beef. Put a bit of oil in the pan, let it get nice and hot, add the beef, stir until well cooked. Seriously, don't fuck around with ground beef, cook it all the way through.\n\n\n\n\n\nAdd salsa the refried beans. Stir, let beans melt.\n\n\n\n\n\nAdd beer, more beer for thinner, less for thicker. Let simmer, while drinking second beer. Stir occasionally. Simmer at least 10 minutes, longer for more flavor but less stock.\n\n\n\n\n\nWipe off counter, serve with beer! You'll be delighted how well the\n\n\n\n\n\n### Alternatives:\n\n  1. Cube cheddar and mozzarella cheese, and replace for beer. Stir _constantly_, but only until heated. Serve with chips (and beer). Cubing the cheeses into 1/4 inch chunks is important, otherwise they melt weird and you get a really odd texture. Don't use shredded cheese.\n\n  2. Different salsas, different beers. For the true chef, cook your own salsa and brew your own beer. Brewing is not Lazy-Ass Gourmet, and I don't brew myself, but it is a noble hobby.\n\n\n\n\n",
      "intro": ""
    },
    "/posts/2012/07/25/spaghetti/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2012-07-25T18:00:50.000Z",
        "layout": "post",
        "slug": "spaghetti",
        "title": "Spaghetti",
        "wordpress_id": 462,
        "categories": [
          "Lazy-Ass Gourmet"
        ],
        "tags": [
          "ground beef",
          "pasta",
          "sauce",
          "spaghetti"
        ],
        "path": "/posts/2012/07/25/spaghetti/index.md"
      },
      "body": "The quickest Italian dish ever. If you can't cook this, you shouldn't cook. (Actually, you should try it a few more times and figure out how to cook.) If you can't make this tasty, try a couple more times.\n\n<!-- more -->\n\n  * Spaghetti noodles\n  * 1 lbs ground beef\n  * 1 can Classico spaghetti sauce\n  * Salt\n  * Olive Oil\n\nYou're probably cooking your pasta wrong. Don't add pasta to boiling water. There's a weird reaction the outer pasta has that makes it sticky when you do that (and no, oil doesn't help much). Instead, put your dry pasta in a pan, cover with cold water (maybe a 1/4 inch above the pasta), and then turn on the heat. This lets the pasta get all wet and cooked before it starts to get soggy and clump. Add a dash of oil to keep the water from foaming and boiling over. You know now how to cook awesome pasta, of any kind. The only difference is thicker pastas will take longer.\n\n\n\n\n\nFor the sauce, brown the beef. Put a bit of oil in the pan, let it get nice and hot, add the beef, stir until well cooked. Again, don't fuck around with ground beef. Add the sauce, and let it simmer until hot. Depending on the noodles, it should be just the right temperature when the noodles finish.\n\n\n\n\n\n### Alternatives\n\n\n\n\n\n\n\n  1. Different pastas. There are so many friggin pastas. Use the same cold water on top approach, and they'll come out well every time. Except rice noodles, I still can't figure out how to cook those fuckers.\n\n  2. Make your own sauce! (Guest post, coming soon!) There are probably as many sauce options than there are noodle options, so this is another great place to play around. Even with just the store-bought sauces, try adding different things to your beef when you fry it. I personally like diced onions, bell peppers, and olives.\n\n\n\n\n",
      "intro": ""
    },
    "/posts/2012/07/27/salmon-bake/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2012-07-27T18:00:05.000Z",
        "layout": "post",
        "slug": "salmon-bake",
        "title": "Salmon Bake",
        "wordpress_id": 465,
        "categories": [
          "Lazy-Ass Gourmet"
        ],
        "tags": [
          "asparagus",
          "bell peppers",
          "potatoes",
          "salmon"
        ],
        "path": "/posts/2012/07/27/salmon-bake/index.md"
      },
      "body": "Fresh fish feels fantastically filling. This salmon bake is great year round, but an especially nice light summer dish.\n\n<!-- more -->\n\n  * Salmon Fillets\n  * 1 Bell Pepper\n  * half-dozen spears asparagus\n  * 4 medium red potatoes\n  * Olive Oil\n  * Lemon juice\n\nPre-heat oven to 350.\n\n\n\n\n\nCover your baking sheet with aluminum foil (makes cleanup much easier, just throw the foil away). Drizzle light oil over the baking sheet.\n\n\n\n\n\nScallop potatoes, slicing them between an eighth and a quarter inch, and place the slices on an oiled baking sheet. Add a light dash salt and splash of lemon juice.\n\n\n\n\n\nSlice pepper. To slice a bell pepper, cut from the top, near the stem, radially down. Rip out the seeds, throw out the stem, and keep slicing along the length of the bell until you have the thickness you want. Alternate pepper slices and asparagus spears in a layer on top of the potatoes. Add a light dash of salt and splash of lemon juice.\n\n\n\n\n\nPlace salmon fillet skin-down on the veggies, and add a splash of lemon juice.\n\n\n\n\n\nBake 15 minutes, or until salmon is nice and white.\n\n\n\n",
      "intro": ""
    },
    "/posts/2012/08/31/election-2012-referendum-on-war/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2012-08-31T18:06:52.000Z",
        "layout": "post",
        "slug": "election-2012-referendum-on-war",
        "title": "Election 2012: Referendum on War",
        "wordpress_id": 475,
        "categories": [
          "Politics"
        ],
        "tags": [
          "2012",
          "election",
          "iran",
          "israel",
          "obama",
          "romney",
          "war"
        ],
        "path": "/posts/2012/08/31/election-2012-referendum-on-war/index.md"
      },
      "body": "All domestic policies will be for nothing if [Israel starts a war with Iran](http://www.nytimes.com/2012/08/31/world/middleeast/report-on-iran-nuclear-work-puts-israel-in-a-box.html).\n\n\n\n\n\nThe Economy is on everyone's mind, but the economy's not going to change overnight (so says Ryan, and I can agree on that point). The Environment is in serious danger of long-term damage that will make it materially more difficult for us as a species to prosper. Our Education system has many calling for a complete overhaul, but that will take years before our best and brightest children are able to make positive changes from such changes.\n\n\n\n\n\nThese are all long-term issues which are critical to building a bright future, and require serious thought in the mid-term.\n\n\n\n\n\nThese will be for nothing if Israel attacks Iran.\n\n\n\n<!-- more -->\n\n\n\nIsrael's sabre-rattling over the past decade has convinced Iran of the need for nuclear weapons to act as a deterrent in defending their sovereign self-interests. US-Israeli espionage has been wildly successful in tempering and mitigating this threat in the short-term, but Iran was never playing a \"let's get nukes fast\" game. They saw what happened to the Hussein regime, and are smart enough to not fall into that trap.\n\n\n\n\n\nSo now, we have an [Iran with full scale uranium enrichment facilities](http://www.bbc.co.uk/news/world-middle-east-19424097), built into a hardened bunker that only the United States has the technological capability to pose a feasible threat.\n\n\n\n\n\nWe have an Israel that has repeatedly demonstrated they are more than willing to prefer force to diplomacy.\n\n\n\n\n\nThe Israeli leadership has every intention of launching a unilateral military strike against the sovereign Islamic Republic of Iran, and the Israeli leadership full expects the United States to provide unconditional military support if it takes such actions. Such an attack would be the worst possible action to take against Iran. Iran is currently experiencing political turmoil inside its borders; attacking now would provide solidarity around the Ahmadinejad regime. Iran has already moved its nuclear production underground; [attacking now would prove to Iran how necessary those plans truly were](http://www.newyorker.com/reporting/2012/09/03/120903fa_fact_remnick).\n\n\n\n\n\nDomestically, we have a sitting president who has a checkered record of handling situations in the middle east, though many observers and commentators on the world scene tend to credit President Obama with having learned from his earlier mistakes, and [think he's doing much better now than at the beginning of his presidency](http://www.thedailybeast.com/articles/2012/07/16/how-obama-s-middle-east-policy-has-worked.html). He is surrounded by advisers who argue against conflict, and supported by a base who also oppose those conflicts.\n\n\n\n\n\nMr. Romney's foreign policy is guided by an [archaic view of Russia as a credible military threat](http://cnnpressroom.blogs.cnn.com/2012/03/26/romney-russia-is-our-number-one-geopolitical-foe/), who begs financial support from the most wealthy and powerful of the Israeli right-wing, and has hinted he agrees with the assessment of Iran as a religious threat. He is surrounded by supporters who call for direct support of Israel in such a conflict with Iran, and who do not see diplomacy as a viable option.\n\n\n\n\n\nIsrael intends to attack Iran. They intend to attack within the next six months. [Mr. Romney has stated he will encourage that attack](http://www.telegraph.co.uk/news/worldnews/mitt-romney/9436624/Mitt-Romney-backs-Israeli-military-action-against-Iran.html), and would likely commit US forces to such an engagement. President Obama's rhetoric is less transparent, and does include support for Israel, but at least stops short of pushing for war with Iran and instead includes continued pushes for a diplomatic solution to the situation.\n\n\n\n\n\nThe three Es and Health Care are issues this nation will need to grapple with, and are serious issues. They are not the pressing issue that will come to a head in the next six months, defining the next decade of international conflict.\n\n\n\n\n\nThis election will be a referendum on US policy in Israel. Will that be a policy of war?\n\n\n\n\n\n**Update Monday, September 2nd:**\n\n\n\n\n\nIt seems the Obama administration is [increasingly vocal in opposing](http://www.timesofisrael.com/us-to-iran-in-case-of-israeli-strike-dont-fire-on-our-bases/) a unilateral Israeli strike. I'm very interested in what Senator Kerry has in his speech at the DNC, and in what Obama will say at the UN on the 25th.\n\n\n\n",
      "intro": ""
    },
    "/posts/2012/12/07/observers-in-my-syntax/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2012-12-07T15:13:24.000Z",
        "layout": "post",
        "slug": "observers-in-my-syntax",
        "title": "Observers? In *my* syntax?",
        "wordpress_id": 491,
        "categories": [
          "Technology"
        ],
        "tags": [
          "eventing",
          "livescript",
          "observers"
        ],
        "path": "/posts/2012/12/07/observers-in-my-syntax/index.md"
      },
      "body": "Modern graphical programming is dependent on the [observer pattern](http://en.wikipedia.org/wiki/Observer_pattern). Its use in Model-View-Controller architectures vaulted the pattern into widespread use. Its continues to find applicability in event and interrupt based systems. The underlying conceptual pattern is astounding. In traditional APIs, the user is allowed to call library code arbitrarily, but there is no mechanism for a library to call user space code. While this is somewhat obviated by extensive callback usage, having formally defined and documented locations where library code calls user code is a great boon in large-scale software architectures. The observer pattern provides such a mechanism. In short, observers are great. How can they be worked even tighter into a coding environment?\n\n<!-- more -->\n\nThis past year has seen an abundance of metamorphic languages targeting JavaScript. [LiveScript](http://gkz.github.com/LiveScript/) especially has added a glut of incredibly useful syntax to CoffeeScript, borrowing heavily from Haskell. These improvements capture, in concise syntax, a myriad of concepts that normally take many lines of code. Users of the LiveScript language have access to functional currying, piping, backcalls, and dozens of other operations resulting in less typing and more straightforward programs. The results of these symbols occur in a myriad of ways- some are converted into appropriate JavaScript, while others are handled by introducing hidden functions to introduce the new features. The two mechanisms both work well and in tandem, allowing nearly any combination of additional language features.\n\n\n\n\n\nI would like to add a series of operations for handling observers in a language's syntax. The operations I propose have been implemented in a [fork](http://gkz.github.com/LiveScript/) of LiveScript, and used to great effect in several programs compiled with the fork.\n\n\n\n\n\nThe three symbols are\n\n\n  * `:>` Observe\n  * `-:>` Unobserve\n  * `<:` Trigger\n\nEach is a binary operation, taking on its left hand side a reference to some event, and on its right hand side either a function reference (for observe and unobserve) or a value (for trigger). Events in this syntax are simply properties on an object. Specifically, the left hand side can be a reference to any object, with the right-most property being the property and its container being the scope of the event. In practice:\n\n\n\n\n    \n```\nsource = {}\npass = false\nsource :> !(e) -> pass := e\nsource <: true\nok pass\n```\n\n\n\n\n\nHere, `source` itself is the event. It has a single observer, which sets the global value of `pass` to the value that `source` was triggered with. Another example:\n\n\n\n\n    \n```\n/* \"Observers and Advisors trigger in correct deep context\" */\nsource = {}\nsource.child = new ->\n    @pass = 0\n    this\n\nadd = !-> @pass++\nsource.child.event :> add\nsource.child.event <: {}\nequal source.child.pass, 1\n```\n\nHere, the object `source` has a single `child` with some `event`. When `event` is triggered, the observers are called with `this` bound to `source.child`, one level up from the event property.\n\nHaving these operators is a huge boon in writing event-driven programs. Not only does the codified syntax mean less typing, it provides a clear visual symbol for the concept of observing and triggering a variable. The actual implementation of the eventing is abstracted behind whatever event library the compiler chooses to delegate to. In my original implementation, the event listeners are attached to an array on the event itself, but another library could make the event property a function, a la jQuery, or register it in a private list of event sources, a la string-keyed pub/sub libraries.\n\nMy branch is available at [github.com/DavidSouther/LiveScript](http://github.com/DavidSouther/LiveScript). I intend to rewrite the eventing library used in two places. First, it should compile to a known method signature, with options on whether to include the function definition in the compiled scope. This will allow the eventing implementation to decouple from the compiler. Second, I would like to rework the implementation to detect if the event source is a function. This will allow the syntax to handle jQuery events natively.\n\nI would ask [gkz](https://github.com/gkz) and other users of LiveScript to consider this approach to an eventing syntax.\n",
      "intro": ""
    },
    "/posts/2013/01/11/this-rationalists-world-view/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2013-01-11T05:32:51.000Z",
        "layout": "post",
        "slug": "this-rationalists-world-view",
        "title": "This Rationalist's World-View",
        "wordpress_id": 496,
        "categories": [
          "Philosophy",
          "Science"
        ],
        "tags": [
          "emergence",
          "evolution",
          "nucleosynthesis",
          "worldview"
        ],
        "path": "/posts/2013/01/11/this-rationalists-world-view/index.md"
      },
      "body": "The myriad parameters to support human life are nearly all emergent.\n\n\n\n\n\nLook out in the night sky. How many stars do you see? (In the suburbs, maybe 2000). How many of those are actually galaxies? About a dozen. How many planets can you see? 5. How many stars do our telescopes see, [in the Milky Way](https://www.google.com/search?q=stars%20in%20the%20milky%20way&aq=f&oq=stars%20in%20the%20&aqs=chrome.0.59j0j57j5j61j60.2058&sugexp=chrome,mod=0&sourceid=chrome&ie=UTF-8)? 300 billion. [Galaxies](https://www.google.com/search?q=galaxies%20in%20the%20universe&aq=0&oq=Galaxies%20in%20the%20uni&aqs=chrome.2.57j5j0l2j62l2.2777&sugexp=chrome,mod=0&sourceid=chrome&ie=UTF-8)? 170 billion. Planets? Nearly 1000 confirmed (ok, only a dozen or so extra solar have been directly imaged) and another 2,000 awaiting data analysis, and we are literally just getting started. The latest analysis estimates 100 billion planets in the milky way (one every three stars, but more like 3 - 5 every 10 stars, given the way planetary systems form). 17 billion or so of those are [probably Earth-like](http://www.slate.com/blogs/bad_astronomy/2013/01/07/alien_earths_new_study_indicates_there_are_billions_of_earth_sized_planets.html) (rocky, with masses between Mars and ~1.5x Earth).\n\n\n\n<!-- more -->\n\n\n\nHow many of those 17 billion orbit their star at a distance which would have surface temperatures between -10 and 110c? (Water freezing to boiling, because water does some really neat phase shifts in those ranges that make possible quite a bit of really interesting chemistry.) Probably quite a few. Let's be conservative, and say 7 billion. We're not considering moons, asteroids, extreme environments, or any exotic chemistry, just worlds where chemistry would behave about the way it's presented in undergrad classes. That's one planet potentially capable of harboring chemical reactions that we see in living organisms for every human being alive today. In one of a hundred billion galaxies. Think about that for a moment.\n\n\n\n\n\nLet's think about that organic chemistry for a moment. We don't really know how, exactly, life got started. We've got quite a few great experiments, but they depend on a bit of speculation of the Earth's environment over 3 billion years ago, so they are no where near \"theorum\" yet. (Thank you, Richard Dawkins, for that phrase.) There were some great experiments in the 70s that mixed water, basic chemicals (amonias and some carbon dioxide and whatnot), added sparks, and got amino acids. Pretty cool, but not life.\n\n\n\n\n\nWhat do we need to have life? I'm going with: (1) self-replicating and (2) produces energy. You can have one without the other, but you'll probably need both to meet the basic criteria for life. RNA as a molecule works surprisingly well, [because it can self replicate](http://www.amazon.com/gp/product/B008RYSKKS/ref=kinw_myk_ro_title), and with a couple other enzymes can start producing energy. Again, not sure on all the details, but the broad strokes are plausible with today's understanding of chemistry. Once you have a self-replicating bit of life (a cynaobacteria, on Earth), the very well understood mechanisms of evolution kick in.\n\n\n\n\n\nSpecifically, those are genetic recombination and natural selection. Genetic recombination creates viable varieties of living organisms, and natural selection culls those which are most suited to their (changing) environment. Over 3 and a half billion years, [those two forces end up creating a species](http://www.amazon.com/gp/product/B002LVVCQM/ref=kinw_myk_ro_title) capable of reasoning about its environment, of building telescopes that pick up light emitted 13.4 billion years ago, and deducing very accurately that the universe in which it lives is 13.75 billion years ago, and \"flat\" in the terminology of what many consider its greatest scientist.\n\n\n\n\n\nSo, that's how you get from a rock in space to sentience. How did you get that rock? The rock is made of elements that were fused together in shells of an exploding star. Stars the mass of our sun spend all their lives fusing single protons into light Helium. Stars a bit larger than the sun, however, have enough gravity and energy to smash that Helium-3 into Helium-4, and then (this is the fun part), that Helium-4 with more He and H to get Carbon-12. Once you have Carbon-12, it fuses to make Nitrogen, then more Carbon (13), then some Oxygen, a bit more Nitrogen, before fissing back to Carbon-12. If you turn around and look at those chemical processes in the second paragraph here, you notice a lot of, you guessed it, Carbon, Hydrogen, Oxygen, and Nitrogen. Other (heavier) stars break _way_ out of that cycle, burning Carbon into Neon into Silicon eventually into Nickle and Zinc (which decay back to Iron), before blowing up. In even heavier stars, they blow up so violently that so many neutrons get thrown around that that iron very quickly gets fused all the way up the chain of atomic elements until you get Uranium and other heavy stuff with names of universities attached to them.\n\n\n\n\n\nAll that, from three basic concepts: Some gravity, a bit of nuclear fusion, a touch of organic chemistry (electromagnetism), and the simple mechanisms of evolution. All that variety and beauty and wonder in the universe, emerging from a few basic processes.\n\n\n\n\n\nHow does it get started? We're really not 100% sure, but quantum mechanics has some answers. I'm not as familiar with the material, so this one is going to be very short: [Laurence Krauss](http://www.amazon.com/gp/product/B004T4KQJS/ref=kinw_myk_ro_title) describes some theories in quantum vacuum fluctuations that could give rise to new universes. This is not quack science, these are discussions of theories and results of data being gathered at the LHC and other colliders today. (Don't take that as me saying we'll have answers tomorrow, just saying we can confidently say we're probably asking the right questions.)\n\n\n\n\n\nSo, what does this all mean? I take it to mean this:\n\n\n\n\n\n\n\n  1. There is a natural world. \n\n\n  2. That natural world is consistent.\n\n\n  3. We are a part of the natural world.\n\n\n\n\n\nThere is a notion in physics (and science) called the anthropic principle. Naively, it says \"The universe must be this way because we are in a universe.\" More subtly, it says there are a myriad of potential, possible, or conceivable universes, and we happen to be in one arranged in such a way we can observe and reason about it. On the one hand, it's a sanity check on theories in the avant garde of physics. On the other, it is the basis for a worldview that recognizes the grandiosity of the universe, but depends on a rational exploration of that universe.\n\n\n\n\n\nIt's not easy being a rationalist, but it's taught us a tremendous deal about the world we live in. From a pragmatic policy point, if you truly believe Earth was created 10,000 years ago in 6 literal days (as some US senators have indicated they do), we must immediately disarm all nuclear warheads, because we haven't got a damned clue how they work, and they could mystically detonate at any moment.\n\n\n\n\n\nBack to the theology, we know enough about the universe that there is no need to invoke a god, or religion, to explain any aspect of life. There is no evidence for a soul or afterlife, you will neither be reincarnated nor go to heaven (or hell). There is no need for a violent deity who demands homage and the destruction of a tribe's enemy, nor is there a need for a loving deity to provide a reason to be compassionate to your fellow H. sapien, fellow animal, or the environment around you.\n\n\n\n\n\nDoes my worldview have faith? No. I have something much stronger than faith: evidence and reason.\n\n\n\n\n\nEvidence and reason are the birthright of the enlightenment. This tradition has improved society in innumerable ways, but chief among them is the [drastic plunge in violence](http://www.amazon.com/gp/product/B0052REUW0/ref=kinw_myk_ro_title) rates throughout the world (roughly commensurate to the level of accepting enlightenment philosophy into their societies).\n\n\n\n\n\n> \n  \n> \n> \"To each their own, by their greatest ability, with malice toward none.\" - David Souther\n> \n> \n\n\n\n\n",
      "intro": ""
    },
    "/posts/2013/02/26/readable-d3/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2013-02-26T03:26:58.000Z",
        "layout": "post",
        "slug": "readable-d3",
        "title": "Readable d3",
        "wordpress_id": 504,
        "categories": [
          "Technology"
        ],
        "path": "/posts/2013/02/26/readable-d3/index.md"
      },
      "body": "[d3 example code](https://github.com/mbostock/d3/wiki/Gallery) is horribly convoluted, depending on dozens of unstructured variables (and often some global magic) to achieve even the simplest effects. To improve the readability of my d3 projects, I've introduced a Canvas container, with the most commonly used properties conveniently encapsulated in a single object. Combined with mbostocks discussion in [Towards Reusable Charts](http://bost.ocks.org/mike/chart/), the canvas container can be used in nearly any project to greatly improve the structure and quality of d3 code.\n\n<!-- more -->\n\n```javascript \"Readable Canvas (canvas.js)\" https://gist.github.com/DavidSouther/5035560#file-canvas-js \n(function(){\n  /*\n    Get a new SVG canvas, with margins and scales. Pass an object as `options` to\n    set values. Defaults:\n  \n    {\n      size: # Size of SVG. Returned size will be smaller by the size of the margins.\n        width: 960\n        height: 500\n      margin: # Margins for the graphic.\n        top: 20\n        right: 20\n        bottom: 30\n        left: 40\n      scale: # d3.scales to scale against the canvas\n        x: linear\n        y: linear\n      domain: # Domain of scales for the canvas.\n        x: [0, 1]\n        y: [0, 1]\n    }\n \n    @param root String selector for finding the SVG element.\n    @param options Object matching the defaults to override.\n    @return Object with defaults, overriden by the options, and an additional two properties:\n      {\n        svg: SVG_Element # SVG root\n        defs: SVG_Defs_Element # <defs> to attach gradient and filter definitions to.\n      }\n  */\n  this.Canvas = function(root, options){\n    var margin, width, height, svg, scales, canvas;\n    root == null && (root = 'body');\n    options == null && (options = {});\n    options.size || (options.size = {});\n    options.margin || (options.margin = {});\n    options.scale || (options.scale = {});\n    margin = {\n      top: options.margin.top || 20,\n      right: options.margin.top || 20,\n      bottom: options.margin.top || 30,\n      left: options.margin.top || 40\n    };\n    margin.leftright = margin.left + margin.right;\n    margin.topbottom = margin.top + margin.bottom;\n    width = (options.size.width || 960) - margin.leftright;\n    height = (options.size.height || 500) - margin.topbottom;\n    svg = d3.select(root).attr({\n      'width': width + margin.left + margin.right,\n      'height': height + margin.top + margin.bottom\n    });\n    scales = {\n      x: d3.scale[options.scale.x || 'linear']().range([0, width]).domain(options.domain.x || [0, 1]).nice(),\n      y: d3.scale[options.scale.y || 'linear']().range([0, height]).domain(options.domain.y || [0, 1]).nice()\n    };\n    canvas = {\n      size: {\n        width: width,\n        height: height\n      },\n      margin: margin,\n      scale: scales,\n      svg: svg,\n      defs: svg.select('defs')\n    };\n    return canvas;\n  };\n}).call(this);\n```\n\nThis version binds the Canvas closure function to Window. Most of the code is to ensure the appropriate fields are set on the options object. The returned object has the final details of the drawing surface, including its size, the margins, and d3 scales calibrated to the canvas' coordinates. It also includes a refernce to the root SVG element, as well as the svg:defs element containing any filters or gradients defined for the image.\n\nThis object works exceptionally well as the config parameter for reusable charts.\n\n```javascript Herzsprung Russel Diagram (starmap.js) https://gist.github.com/DavidSouther/5035560#file-starmap-js\n(function(){\n  var spectrate, Starmap, prepare;\n\n  // Small helper to look up a string\n  spectrate = function(star){\n    return \"class\" + spectral['class'](+star.temp);\n  };\n\n  // Given a canvas, add gradient definitions to the svg:defs element.\n  prepare = function(canvas){\n    var defs, grads;\n    defs = canvas.defs;\n    grads = defs.selectAll('radialGradient')\n      // A list of spectral classes\n      .data(spectral.spectro)\n      .enter()\n      .append('svg:radialGradient')\n      .attr({\n        'id': function(it){ return spectrate(it); },\n        'cx': +0.5,\n        'cy': +0.5,\n        'r': +1\n      });\n    grads.append('stop')\n      .attr({\n        'stop-color': function(it){ return it.color.brighter(); },\n        'offset', '0%'\n      });\n    grads.append('stop')\n      .attr({\n        'stop-color': function(it){ return it.color; },\n        'offset': '100%'\n      });\n  };\n\n  this.Starmap = function(canvas){\n    var star;\n    prepare(canvas);\n \n    // Callable function to draw circles in a selection\n    // EG a stencil\n    star = function(selection){\n      var circles;\n      circles = selection.enter()\n        .append('svg:circle')\n        .attr({\n          \"r\": 20,\n          \"class\": \"star\"\n        })\n        .style({\n          \"opacity\": 0.9\n        });\n      circles.attr({\n        \"cx\": function(it){ return canvas.scale.x(+it.temp); },\n        \"cy\": function(it){ return canvas.scale.y(+it.mag); },\n        \"fill\": function(it){ return \"url(#\" + spectrate(it) + \")\"; }\n      });\n      selection.exit().remove();\n    };\n\n    // The main stencil. Takes an svg:g layer from inside canvas.svg\n    return function(layer){\n      // Load the spectrum data\n      d3.csv(\"hr.csv\", function(error, stars){\n        layer.attr({\n            'id': \"herzrus\",\n            'transform': \"translate(\" + canvas.margin.left + \", \" + canvas.margin.right + \")\"\n          })\n          .style('opacity', 0.9)\n          .selectAll('.star')\n          .data(stars)\n          // Chained call to the reusable star stencil.\n          .call(star);\n      });\n    };\n  });\n}).call(this);\n```\n\nIn this example, StarMap will draw a Herzsprung Russel diagram on the layer. An HR diagram is a log-linear scatterplot of stellar temperature to luminosity. This example takes a canvas to attach Gradient definitions to, and returns a function that will draw the HR diagram on a layer. The stencil function loads data from a CSV file, and uses an inner stencil funtion to draw the individual stars.\n\nUsing the two is similarly easy.\n\n```html Starmap https://gist.github.com/DavidSouther/5035560#file-starmap-html\n<!DOCTYPE html>\n<html>\n<head>\n    <title>HR in D3</title>\n    <script src=\"http://d3js.org/d3.v3.min.js\" />\n    <link rel=\"stylesheet\" href=\"styles/nucleosynth.css\">\n    <script src=\"canvas.js\" />\n    <script src=\"starmap.js\" />\n</head>\n<body>\n    <svg id=\"chart\">\n        <defs>\n            <filter id=\"oil\" filterUnits=\"objectBoundingBox\" x=\"0%\" y=\"0%\" width=\"100%\" height=\"100%\">\n                <femorphology in=\"SourceGraphic\" radius=\"2\" result=\"result_oil_morph\" />\n                <feturbulence type=\"turbulence\" baseFrequency=\"0.05\" numOctaves=\"2\" result=\"result_oil_turb\" />\n                <fedisplacementmap in=\"result_oil_morph\" in2=\"result_oil_turb\" scale=4 xChannelSelector=\"R\" yChannelSelector=\"G\" />\n            </filter>\n        </defs>\n    </svg>\n    <script type=\"text/javascript\">\n        var background;\n        canvas = Canvas('#chart', {\n            scale: {\n                x: 'log'\n            },\n            domain: {\n                x: [100000, 1000],\n                y: [-8, 7]\n            }\n        });\n        background = canvas.svg.append('svg:g')\n            .attr('style', 'filter:url(#oil);');\n        background.append('svg:image')\n            .attr({\n                'xlink:href': \"assets/dfb.png\",\n                'width': canvas.size.width + canvas.margin.leftright,\n                'height': canvas.size.height + canvas.margin.topbottom,\n                'x': 0,\n                'y': 0\n            });\n        Starmap(canvas)(background.append('svg:g'));\n    </script>\n</body>\n```\n\nIn this example, the SVG is preloaded in the HTML with a filter already defined. The script gets a canvas with a few custom properties, attaches a background image, then creates the Starmap and uses it immediately.\n\nThis pattern has been very helpful keeping my code clean.\n",
      "intro": ""
    },
    "/posts/2013/03/15/7th-ave-between-the-square-and-the-park/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2013-03-15T01:03:09.000Z",
        "layout": "post",
        "slug": "7th-ave-between-the-square-and-the-park",
        "title": "7th ave between the square and the park",
        "wordpress_id": 535,
        "categories": [
          "Poetry"
        ],
        "path": "/posts/2013/03/15/7th-ave-between-the-square-and-the-park/index.md"
      },
      "body": "<pre>\nI walk her streets alone, awake;\nI walk her streets with friends.\nAlive we feel some million folks\nenjoying her embrace.\n\nHer lights are bright,\nyet throw shadows\nenough in length to hide\nwhere sounds abound, yet lie.\n\nHer grids ensnare\nwhom drives across.\n\"Go below\" her whisper,\nstrong but soft.\n\nThen a whoosh and a rattle\ngoes her train!\nThe clank crescendo\nfrom her veins!\n\nA honk, a squeal! The rubber grips\nwhile I on foot move apace,\nHundreds, thousands, also walk\nfree from the bonds of oil to race.\n\nThe buildings are tall, her skin.\nSteel and concrete, for those within\nto sit above and look upon\nher lustrous fair visage.\n\nGreen still is found near every where.\nHer parks day and night for lovers wait.\nThe squirrels beg, the rats grow fat.\nAnd pigeons? Crap on your hat.\n\nHer shops will sell most anything.\n\"What Price\" you ask without a tag.\nHer people though surprise you so,\n\"It's my gift, you need it more.\"\n\nOf course with millions all around\nSome less savory can be found.\n\"What Price\" you ask without a fare-\nless pleasant a night you're not aware.\n\nShe is a bitch, when she wants to be.\nAbusive, yes, but then, so welcoming.\nKeep your wits, and love her too.\nShe will always be with you.\n</pre>\n"
    },
    "/posts/2013/03/18/national-gallery-west-building/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2013-03-18T15:51:56.000Z",
        "layout": "post",
        "slug": "national-gallery-west-building",
        "title": "National Gallery, West Building",
        "wordpress_id": 546,
        "categories": [
          "Poetry"
        ],
        "path": "/posts/2013/03/18/national-gallery-west-building/index.md"
      },
      "body": "<pre>\nArt in the halls art on the walls\nPaintings and sculpture oh my \nA Garden inside to read if you will\nGalleries filled for the eyes\n\nAn Ancient Pine forest with a mountain stream \nSerene to behold, even without green\nThat babbling Brook flows strong in winter \nThe beauty of Swiss caught with watercolor \n(Alexandre calame 1847)\n\nHippolyte Petitjean dimples so tight \nHer watercolors still capture light \nSedative scenes made of single points \nEach lovingly placed with a deft touch \n(promenade by a lake, a river landscape, etc)\n\nFishing boats tossed before a storm \nIsabey throws the paint ashore \nThe fishermen cower 'fore nature's roar \nYet ride it through in courageous form \n(1840)\n\nDegas, Rodin! Their sculptures show \nHumanity in all our throws \nRomantic: grotesque \nOr plump, yet true?\n\nHunting in the Pontine Marches \nMighty Oaks felled low as passing time\nThe moment captures rifle's aim\nThe Hound, faithful, pointing, leaves impression\n(Horace Vernet, 1833)\n\nPeople move through \nsome with opinions, Others thoughts \nOne in a few, even appreciation \nThe creations of peers moving them so\n\nToo much to see in a day or a life,\nso we pick and we choose\nwhat fancies delights;\nthen, at the end, the cherubs alight.\n</pre>\n"
    },
    "/posts/2013/04/26/sitting-at-home/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2013-04-26T02:37:22.000Z",
        "layout": "post",
        "slug": "sitting-at-home",
        "title": "Sitting at home, listening to Beethoven, thinking of Maenee",
        "wordpress_id": 553,
        "categories": [
          "Poetry"
        ],
        "tags": [
          "field",
          "fire",
          "flame",
          "garden",
          "love",
          "maenee",
          "passion"
        ],
        "path": "/posts/2013/04/26/sitting-at-home/index.md"
      },
      "body": "<pre>\nThe fire in your eyes sets my heart aflame\n\nthe spark that lights the tinder in my soul\nwhich, bereft of the waters of love, dried\nbut did not blow away. Waiting,\ninstead, to flame up, 'till, engulfed with passion,\nthe detritus burned away leaving\nfertile fields to sow the tears of your beauty.\n\nNurtured by the passions of our love,\ntended by the tender touch we share,\nblooming in a garden we share\nin my breast, my mind.\n</pre>\n"
    },
    "/posts/2013/10/30/testing-its-hard-just-do-it/index.md": {
      "front": {
        "author": "David Souther",
        "comments": true,
        "date": "2013-10-30T17:31:11.000Z",
        "layout": "post",
        "slug": "testing-its-hard-just-do-it",
        "title": "Testing. It's hard. Just Do It!",
        "wordpress_id": 560,
        "categories": [
          "Technology"
        ],
        "path": "/posts/2013/10/30/testing-its-hard-just-do-it/index.md"
      },
      "body": "[\"With enough eyeballs, all bugs are shallow.\"](http://en.wikipedia.org/wiki/Linus's_Law)\n\n\nThe bug might be shallow when it's first found, but how does it never happen again? Automated Testing. When a bug is found, prove it exists with a test. Then, that bug is guaranteed to never happen again - a little computer gremlin with eagle-eye focus will look at that bug every time your program runs, and the bug will NEVER HAPPEN AGAIN. It will never happen, because if you come close to making that bug, the gremlin will make your console bleed with the red of a failed test.\n\n\n> \"The three chief virtues of a programmer are: Laziness, Impatience and Hubris.\"\n> - Larry Wall (creator of Perl)\n\n<!-- more -->\n\n\nThat little gremlin I wrote to prove the (non)existence of a bug? That's me being lazy. I have absolutely zero desire to fix a bug a second time - that's time I could be playing ping pong, or writing a new operating system. That little gremlin better be fast, too, or I'm not going to wait around for him. The gremlin must be small and focused, with a family of small, focused gremlins that can run all my critical tests (the features I'm touching) in under 5 seconds, and my entire codebase quickly enough to not block anyone else on my team ([or they will not test, because it takes too long to be useful](http://codeascraft.com/2013/09/23/lxc-running-14000-tests-per-day-and-beyond-part-1/)). My code always works correctly, the first time. At least, it does every time I write a test before I write a feature. I know most developers aren't as egotistical as I am, but I don't know a single good developer who doesn't want to take pride in the code they've written. It's damned easy to take pride in code that Works Right.\n\n## Why don't I test more often?\n\n<span style=\"float:right\"><img src=\"https://lh3.googleusercontent.com/OkcCl_KVOvD6J7q4w_mWsgvj01mc_3jqS_fKcKIZbJDqq5HMCoPE0J2fnJld_XA9Zxs21XSH429Rnwk9V-T_MHB19-Wk090pYtvHD0pGOUdf_QKls6HXaX-dUA\" /></span>\n\nTesting is hard. It's not the way most programmers learned to program. The other side of the laziness sword? If it's easier to take a shortcut, to get code out the door, I probably will. Testing is in many cases as hard as writing production code, but for a completely different reason: testing requires discipline. Discipline is not, in my experience, something prided by the great hackers of our field. It is a completely different way to approach building software, and requires an equal level of commitment and experience to become comfortable for a developer or team. Without that discipline, shortcuts will happen, and developers won't write code.\n\nThree things need to happen when a team gets to that point. The tests need to be easier to write. This is half experience and half toolkit - the test suite must be fast to run and easy to add tests, and I personally need to be familiar enough with the testing library to write the tests. The test suite must run, and pass, before any code is allowed out the door (coverage testing will guarantee a level of certainty that tests have indeed been written). The third and equally critical piece is support from the project's leadership. If the leadership of the team allows developers to slide and be (bad) lazy, testing will slip.\n\n### Metaphorical Interlude\n\n<pre>\n           Drawing from a well,\n\n       Deep and full and crystal clear.\n\n         A ratchet won't slip.\n</pre>\n\n<span style=\"float:left\"><img src=\"https://lh4.googleusercontent.com/4dgJC56kg--PvW2NHWSTtKr6H0RbQHFAi4pKitQOyUhOBT0KgAyX_Yau1efUdBnI4USrPk63-KEBB9Twrd-yRK8nN_yevJLYOpOullHdpi0hmpdHQgblbjwQYw\" /></span>\n\nProgramming is like drawing water from a well. When the well is shallow, and the bucket small, it's not too difficult a task. When the bucket is big, and the well deep, it becomes harder to draw the bucket, and every mistake can be more disastrous. Automated testing is like installing a ratchet on the rope - every time you write tested code, that bit of rope will never slip. Embracing test driven development is installing a pulley to hoist the bucket with the program. The force and exertion to write a feature halves, because you only write the actual half of the feature the customer needs.\n\n\n## Excoriation of Excuses\n\nIf you're a programmer and you don't write tests, I'm going to assume you don't care enough about your code. I'm going to assume that the code you're working on, you're fine with it being 80%. I'm going to assume you are smarter than me, in a bad way. I am not smart enough to know whether I did or did not break the code you wrote, if I don't have a test suite that tells me if I broke it or not. I am probably not going to want to work on your project or component. I say this not because I think less of you, or want to belittle you, but because this is as much a wake-up call to myself. I say this to myself when I visit old code of my own, that I wrote without tests. It is disgusting and reprehensible to visit those code bases, and I have no desire to return to those projects, no matter how well intentioned they were.\n\nIf you're a manager and don't demand your team writes tests, I'm going to assume you're penny-wise and pound-foolish. If your project is doing well now, I will put money on it collapsing with a bit of churn in your team. After about a quarter of your team has moved on or been replaced, your codebase will collapse into a mess of hard to find bugs, weird edge cases, and increasingly continued pressure to deliver new features when your team is simply unable to write a line of code that doesn't unexpectedly change behavior elsewhere in the application. I will not volunteer for your team. Similarly, if I ever find myself leading a team in such a position, I would be incredibly reticent to hire a developer willing to work in my environment. (Unless, of course, I am being hired or hiring a [Software Engineer in Test](https://www.google.com/about/jobs/search/#!t=jo&jid=35182&) specifically to fix these testing deficiencies.)\n\n## Prototypes, Too!\n\n<span style=\"float:right\"><img alt=\"Evils of the Refactoring Cat\" src=\"http://davidsouther.com/assets/images/Code-Refactoring-Cat-in-Bathtub.gif\" /></span>\n\nI reject the concept of one-off code. If you're at a hackathon, there is that point, about three hours before demo, where your project is AWESOME, and going to win best of show, but you have three hours so you might as well implement a new feature. Without tests, your demo will fail. You will accidentally, in the heat of the moment, break the old, MVP feature with that whiz-bang animation, and have no idea how to get back. At best, you will have a commit to roll back to. At worst, your hackathon time was ruined. With a prototype, you are trying to convince someone to go out of their way to do you a favor. Don't play the lottery - write tests.\n\n## Call to Action\n\nAt this point, it should be pretty clear I care, very deeply, about code and code quality. I want to use good software, and I want to write good software. Help me! If you write code, find a way to test! Challenge me! Don't let me off the hook when testing gets hard, and I won't let you! Together we can craft better software!\n\n### Some resources for getting on the testing train:\n\n  * [I Pity the Fool](http://www.codinghorror.com/blog/2006/07/i-pity-the-fool-who-doesnt-write-unit-tests.html)\n  * [Working Effectively with Legacy Code](http://www.amazon.com/exec/obidos/ISBN=0131177052/portlandpatternrA/) - [Intro PDF](http://www.objectmentor.com/resources/articles/WorkingEffectivelyWithLegacyCode.pdf)\n  * [Unit Testing 101: Are you testing your javascript?](http://msdn.microsoft.com/en-us/magazine/gg655487.aspx)\n  * [Obey the Testing Goat](http://www.obeythetestinggoat.com/)\n",
      "intro": ""
    },
    "/posts/2014/01/04/angularjs-mock-render/index.md": {
      "front": {
        "layout": "post",
        "title": "AngularJS Mock Render",
        "date": "2014-01-05 11:30:00 -0500",
        "categories": [
          "Technology"
        ],
        "tags": [
          "angularjs",
          "testing",
          "mocks"
        ],
        "path": "/posts/2014/01/04/angularjs-mock-render/index.md",
        "author": "David Souther"
      },
      "body": "We test. A lot. We have quite a few directives. We're using this mock render\nfunction to quickly test those directives. It takes the simple html name of the\ndirective, an object with any parent scope properties, an object with any DOM\nattributes to set, and a string to use for transclusion: `render(directive,\ndata = {}, attributes = {}, transclude = \"\")`\n\n<!-- more -->\n\n```coffeescript render.coffee\ntoKeyVal = (attributes, separator = ' ')->\n    (\"#{key} = \\\"#{val}\\\"\" for key, val of attributes)\n        .join separator\n\nif angular.mock\n    window.render = angular.mock.render =\n    (directive, data = {}, attributes = {}, transclude = \"\")->\n        $element = null\n        inject ($compile, $rootScope)->\n            $scope = $rootScope.$new()\n            $scope[key] = val for key, val of data\n            attributes = toKeyVal attributes\n\n            template = $compile(\n                \"<div #{directive} #{attributes}>#{transclude}</div>\"\n            )\n            $element = template($scope)\n\n            try $scope.$digest()\n        $element\n```\n\nIts usage is pretty straight forward. Here, we are testing a directive that\nemits some event when it has finished rendering data received from the\n$httpBackend (configued elsewhere). We render the element, listen for the render\nevent when we'll run our test assertions, and flush the http backend to force\nAngular to digest all the changes in the app. In this way, our test setup and\naction phases are drastically simplified. Our test code shows the assertions our\nbusiness demands, not the setup our platform happens to use.\n\n```coffeescript\nshould = chai.should()\ndescribe 'Performance Overview', ->\n\n    describe 'directive', ->\n\n        beforeEach module 'nv-waves'\n\n        it 'has some chart stuff.', -> inject ($rootScope, $httpBackend)->\n            $element = render 'performance-summary'\n\n            $rootScope.$on 'Wave Rendered', ->\n                $element.find('svg').length.should.equal 2\n                $element[0].querySelectorAll('.chart').length.should.equal 2\n                $element[0].querySelectorAll('.grid').length.should.equal 2\n                $element.scope().data.header.sortable.should.equal true\n\n            $httpBackend.flush()\n```\n",
      "intro": ""
    },
    "/posts/2014/01/27/cucumber-selenium-mappings-model/index.md": {
      "front": {
        "layout": "post",
        "title": "Cucumber Selenium Mappings Model",
        "date": "2014-01-27 10:52:00 -0500",
        "published": true,
        "categories": [
          "Technology"
        ],
        "tags": [
          "cucumber",
          "cucmberjs",
          "selenium",
          "webdriver",
          "cuke"
        ],
        "path": "/posts/2014/01/27/cucumber-selenium-mappings-model/index.md",
        "author": "David Souther"
      },
      "body": "To create a ubiquitous language for a project's interface, I recommend creating\na semantic mapping. This is an in-code key/value object defining words and\nphrases in a [ubiquitous language][fowler_ul] that maps to a specific CSS\nselector for use in code. This has many advantages, with a couple draw backs.\nThe benefits of having a ubiquitous language are documented in various sources,\nbut in sum, mean less time wasted in a team discussing which piece of the\nsolution is under discussion. This exact solution has some specific drawbacks,\nthat I'll mention later.\n\n<!-- more -->\n\nA Cuke mapping, here, is a set of nouns and noun phrases that describe some part\nof a DOM interface. In one example, the application has a main content area. The\nmapping is relatively simple: `'main content': '#main'` (coffeescript key/value\nbare object). The same application has two distinct menu areas, which are mapped\nwith `'main menu': 'main [tab-nav=\"tab-nav\"]'` and `'page menu': 'main div\n[tab-nav=\"tab-nav\"]'`. The subtleties in DOM structure are hidden behind this\nmappings concept. If the DOM changes, the tests can be fixed by eding the\nselector in a single place.\n\n\n## Given/When/Then\n\nShort aside to cover the basics of Cuke best practices. As is recommended in\nautomated testing scenarios, each test has five phases. Two of those phases are\nhidden in the test harness, the before and after test setup phases. The test\nitself is broken into application state setup, taking an action, and asserting\naspects of the final state. Yes, testing is exercising the big old state\nmachine of your application - put the program in some state, take an action,\nmake sure it's in the expected next state.\n\nIn Cucumber, these phases are described with the phrases `Given`, `When`, and\n`Then`. The `Given` assertions are grouped at the beginning of the test, where\nthey include things specific to the test that the `Before` steps haven't\ncovered. For a large application I work on, `Before` guarantees the browser will\nbe open, and on the root page of the application (`http://localhost:1024/`).\nBecause of this, we sometimes drop the `Given` state, or use a dummy noop step,\n`Given the user is on the home page`. However, when verifying some action on a\nspecific page, we will use `Given` to navigate to the page under test. `Given\nthe user navigates to \"Performance\" \"Summary\"`.\n\nThe `When` and `Then` tests are pretty straightforward, and for this application\ngenerally click some DOM node, then check some other DOM status, often for the\npresence of a string in text, or the presence or absence of a node. Some of our\ntests, however, assert rendered properties, especially dimension constraints.\nFor instance, we have asserts to check if elements of the page are on the top,\nleft, or center of a page, or meet certain minimum and maximum size constraints.\nFinally, we have tests that assert look and feel by comparing screenshot image\ndifferences.\n\nThere is some discretion in choosing when to use `Given` vs when to use\n`When` - are the values filled in a form part of the given condition, or part of\nthe test action? I find this depends on what state transition is under test. If\nthe test is verifying the form shows validation rules for invalid input, the\nform filling should be a `When` statement. On the other hand, if the test is\nverifying a \"Thanks for shopping!\" page, the form should be filled in `Given`\nsteps. Cucumber itself relaxes constraints, and doesn't actually enforce only\nsteps only run in their defined phase, so in reality any step can match\nanywhere.\n\n## Mappings\n\nWhen writing steps, cucumber uses regular expression matching groups to pass\narguments to the step body. Generally, these the form `/\"([^\"]+)\"/`, matching\nany non-zero length of string inside double quotation marks. That value then is\npassed to the step definition function, in argument order. For cuke mappings, we\nconstrain the valid items within quotes, to either be a key in the mappings\ntable, or a string literal to assert in some test.\n\nHere's a line from our tests.\n\n```\nThen the \"header nav\" should have links to\n    \"\"\"\n    Dashboard\n    Portfolios\n    \"\"\"\n```\n\nThe step definition matches the first quote group against the mappings object,\nhere finding the expression `\"#header nav\"` as the CSS to select with. It can\nthen look for links to each of the titles in the list of expected links. The\nfull step is defined as\n\n```coffeescript\n    @Then /\"([^\"]+)\" should have links to/, (selector, list)->\n        selector = mappings[selector] + ' a'\n        @world.text(selector)\n        .then (text)->\n            for link in list.split '\\n'\n                text.indexOf(link).should.be.greaterThan -1\n```\n\nThis test creates a selector by looking for any `a` children of the selector\nfor `\"header nav\"`, asking the world to return the joined text for all those\nelements, and asserting that each link text is in that joined string. Also, this\ntest is using the [qcumber][qcumber] cucumberjs library, which makes steps\nbehave with promises - a step can return a value, throw an exception, or return\na promise. It will pass if a value is returned or a returned promise resolves,\nand will fail if an exception is thrown, or a returned promise rejects.\n\n## World\n\nThe world object abstracts the details of working with a browser backend. This\nallows an abstraction between the steps' browser interaction, and the actual\nbrowser backend. Most commonly, `selenium-webdriver` serves as the browser\nbackend, but that could be replaced with `browserstack-webdriver` for\n[browserstack][browserstack] testing in CI or [Zombie][zombie], for headless,\npure-js testing. This extra abstraction provides a minimal jquery-esque API for\nretrieving DOM content, across possible browser backends.\n\n```coffeescript\nmodule.exports = class World\n    constructor: (capabilities = {browserName: \"firefox\"})->\n        @driver = new webdriver.Builder().\n            usingServer(process.env.SELENIUM_HUB).\n            withCapabilities(capabilities).build()\n\n        @driver.manage().timeouts().setScriptTimeout(10000)\n\n    #...\n\n    find: (selector)->\n        @driver.findElement By.css selector\n\n    #...\n\n    text: (where)->\n        @find(where).getText()\n```\n\nThis world is an object instance that configures itself using some webdriver,\nand has a method to do CSS lookup. It's taken from [qcumberbatch][qcumberbatch],\na library I have that implements the concepts here.\n\n## Limitations & Benefits\n\nThe largest intrinsic drawback in this approach is the lack of flexibility in\nconstructing selectors on the fly. While nothing in the code prevents it, it is\ndiscouraged to build such selectors, because anything you'd need to select in\nthe DOM should have its own name, listed in the mappings. Those names must be\npart of the project as a whole, and known and agreed to (at least in\nconversation) by not only the product team, but the entire product stakeholder\ngroup. When dicussing the application, stakeholders must take care to use these\nphrases from the ubiquitous language.\n\nThis, while taking discipline, becomes one benefit of this ubiquitous language\nand mapping approach. Because there is a very limited subset of language to use\nfor the project, conversations spend less time mucking over meaning of words.\nThe meaning has already been defined and agreed to, and any mention of a phrase\nis immediately understood. The tradeoff of extra work and discipline pays for\nitseld in improved communication.\n\n[fowler_ul]: http://martinfowler.com/bliki/UbiquitousLanguage.html\n[qcumber]: https://github.com/DavidSouther/qcumber\n[qcumberbatch]: https://github.com/DavidSouther/qcumberbatch\n[browserstack]: http://www.browserstack.com/\n[zombie]: http://zombie.labnotes.org/\n",
      "intro": ""
    },
    "/posts/2014/02/17/5-surprisingly-not-that-painful-things-about-client-side-js/index.md": {
      "front": {
        "layout": "post",
        "title": "5 surprisingly not that painful things about client-side JS",
        "date": "2014-02-17 22:33:25 -0500",
        "comments": true,
        "categories": [
          "Technology"
        ],
        "tags": [
          "angularjs",
          "angular",
          "front end",
          "client side"
        ],
        "path": "/posts/2014/02/17/5-surprisingly-not-that-painful-things-about-client-side-js/index.md",
        "author": "David Souther"
      },
      "body": "I'm a huge fan of [AngularJS][angularjs]. Over at [Sourcegraph][sourcegraph],\nthey seem to be [having some problems][switching]. Never one to back down from a\nholy war, I'll post a rebuttal for how we're using Angular to great effect at\n[Novus][novus], and how we've gotten around the problems they mention.\n\n<!--more-->\n\n1. **Bad search ranking and Twitter/Facebook previews**\n\n    Sourcegraph thinks it's hard to present a reasonable SPA (Single-Page web Application) to crawlers, and\n    they're absolutely correct. Especially for a site like theirs, which is creating\n    large amounts of dynamic content with few caching opportunities, rendering a\n    page for a crawler is expensive and will probably only be used a single time.\n    Their analysis of the solutions, either rewriting all your pages server side or\n    handling a farm of headless browsers to pre-render for the server are about the\n    only ways to handle the situation.\n\n    This is a problem, and something that is being actively pursued by the\n    community. For Novus, however, we sidestep this. The places we need search\n    rankings, we publish a static site. Our primary application is for our customers\n    only, and even if you did crawl it, you'd get a bunch of nvd3 graphs and charts.\n    Actually, I'll go even further for this. In the places you need SEO, you are\n    probably better using a static site generator - the SPA architecture is for\n    long-lived, data heavy, dynamic pages. I love angular, but this site is run on\n    [Jekyll][jekyll].\n\n1. **Flaky stats and monitoring**\n\n    Sourcegraph argues that it's hard to integrate a third-party analytics provider\n    with an SPA. There are tricky issues with the HTML5 history api, and what about\n    the replaceState events? When you found out you tracked it wrong, it's nigh\n    impossible to recover those stats.\n\n    This argument is dubious to me, at best. I can see that tacking tracking on\n    after the fact can get tricky. At Novus, we've got very clear eventing seams,\n    which make obvious where to attach tracking hooks. We test our tracking hooks\n    during our regression tests (that's a blog post for itself). I wouldn't say it's\n    been easy, but with clear architecture up front, we're doing pretty well.\n\n1. **Slow, complex build tools**\n\n    Sourcegraph doesn't like [ng-boilerplate][ngbp]. They find Grunt configurations\n    complex, and FE build tools too slow. I guess they've never compiled a QT C++\n    application. JS build times are teh slowz! they say. And ngmin takes forever!\n\n    I agree, ngbp has a mediocre Gruntfile at best. At Novus, we have IMHO a much\n    better setup. Currently, we can run our entire build suite, including feature\n    tests, in about a minute; that's six projects, three of which can be run\n    parallel, and 30 seconds of feature testing (more in 4). Each project,\n    individually, takes about a half second to lint & build, and another 2 to 5\n    seconds to run their full suite of tests (between a dozen and half-a-hundred,\n    but growing). We have several mechanisms in place to pare down the test run, to\n    only run the tests of the component under active development.\n\n    Don't get me wrong, the last project I was on had single-module build times of\n    over a minute (on the lead devs machine; another guy was getting three-plus minute build\n    times for CSS changes). You can write bad build configurations. We haven't.\n\n    Oh, if you want to see parts of our kick-ass build process, check out my\n    [TDD AngularJS tutorial][tdd-angular].\n\n1. **Slow, flaky tests**\n\n    Sourcegraph seems to have problems with browser-based feature tests. It took us\n    all of 8 lines in 3 config files to set up and run headless Firefox on our CI\n    server. Running the entire Browserstack matrix is going to be a different beast,\n    but that's because of our IT department's (justified) security concerns. As for\n    the \"flakiness\" of the tests, every time we've had a feature test fail, it's\n    been because of a real regression we introduced into the codebase.\n\n    We've taken an approach to feature testing that I've outlined as the\n    [Cucumber Selenium Mapping Model][csmm]. It's served us fantastically well, and I'd\n    encourage others to take a look at it.\n\n1. **Slowness is swept under the rug, not addressed**\n\n    Sourcegraph claims SPAs make it easier to ignore performance issues. This is not\n    an argument about SPAs, this is an argument against lazy programmers.\n\n    I'm about 4 hours in to re-architecting our page load/event flow because our\n    page has been loading too slowly. I have test harness code designed specifically\n    to introduce slowness into our system, to emulate long/hung/failed/exceptional\n    asynch requests, to see how well they're handled. I am doing this, because our\n    UX lead has been complaining (and I've been noticing) stutterings in the UI,\n    which our metrics show are happening on requests that are, get this, over ~200\n    milliseconds.\n\n    Angular does not make a page laggy, bad programmers make a page laggy.\n\n## Choose the right tool\n\nSourcegraph's closing line is a fine token gesture, \"[Angular wasn't] the right\ntool for our site.\" Looking at their site agnd team, I'd tend to agree. I don't\nknow how I'd have architected it up front, but Angular (and indeed, SPAs) are\nnot the best option for a small to medium traffic volume static on demand site.\nThat is not a reason to decry all front end build tools as an immense web of\nproblems.\n\nI don't know why they published their piece - they must be having (or have had)\nsome frustrations. I am here to tell you that none of these needed to be\nproblems. If you have a site that you think needs Angular, these problems have\nsolutions. Better than that, many will not be problems, if you take a bit of\npride and architecture in your projects.\n\nHappy hacking!\n\n[angularjs]: http://angularjs.org/\n[sourcegraph]: https://sourcegraph.com/\n[switching]: https://sourcegraph.com/blog/switching-from-angularjs-to-server-side-html\n[novus]: http://novus.com\n[jekyll]: http://jekyllrb.com/\n[csmm]: http://davidsouther.com/2014/01/cucumber-selenium-mappings-model/\n[tdd-angular]: http://davidsouther.com/tdd-angular/\n[ngbp]: http://joshdmiller.github.io/ng-boilerplate/#/home\n\n"
    }
  }
}